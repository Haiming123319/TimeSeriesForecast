{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# Colabå¯åŠ¨ - å¥å£®ç‰ˆï¼ˆå¤„ç†ç›®å½•é—®é¢˜ï¼‰\n",
        "# =============================================================================\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# 1. å…ˆåˆ‡æ¢åˆ°/contentç›®å½•ï¼ˆç¡®ä¿åœ¨æ­£ç¡®çš„ä½ç½®ï¼‰\n",
        "try:\n",
        "    os.chdir('/content')\n",
        "    print(f\"âœ… å½“å‰ç›®å½•: {os.getcwd()}\")\n",
        "except:\n",
        "    print(\"âš ï¸  /content ç›®å½•ä¸å¯ç”¨ï¼Œä½¿ç”¨ /tmp\")\n",
        "    os.chdir('/tmp')\n",
        "\n",
        "# 2. æ¸…ç†æ—§ç›®å½•\n",
        "print(\"\\nðŸ§¹ æ¸…ç†æ—§æ–‡ä»¶...\")\n",
        "!rm -rf TimeSeriesForecast\n",
        "\n",
        "# 3. å…‹éš†ä»£ç \n",
        "print(\"\\nðŸ“¥ å…‹éš†ä»£ç ...\")\n",
        "!git clone https://github.com/Haiming123319/TimeSeriesForecast.git\n",
        "\n",
        "# 4. åˆ‡æ¢åˆ°é¡¹ç›®ç›®å½•\n",
        "os.chdir('TimeSeriesForecast')\n",
        "print(f\"âœ… é¡¹ç›®ç›®å½•: {os.getcwd()}\")\n",
        "\n",
        "# 5. éªŒè¯æ–‡ä»¶\n",
        "print(\"\\nðŸ“ éªŒè¯æ–‡ä»¶:\")\n",
        "key_files = ['generate_optimized_aemo_data.py', 'three_stage_training.py', 'run.py']\n",
        "for f in key_files:\n",
        "    exists = os.path.exists(f)\n",
        "    print(f\"  {'âœ…' if exists else 'âŒ'} {f}\")\n",
        "\n",
        "# 6. å®‰è£…ä¾èµ–\n",
        "print(\"\\nðŸ“¦ å®‰è£…ä¾èµ–...\")\n",
        "!pip install -q torch numpy pandas scikit-learn matplotlib einops transformers statsmodels scipy\n",
        "\n",
        "# 7. ä¿®å¤ä»£ç \n",
        "print(\"\\nðŸ”§ ä¿®å¤å¯¼å…¥é—®é¢˜...\")\n",
        "\n",
        "# ä¿®å¤ sktime\n",
        "try:\n",
        "    with open('data_provider/data_loader.py', 'r') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    if 'from sktime.datasets import load_from_tsfile_to_dataframe' in content and 'try:' not in content[:content.find('from sktime')]:\n",
        "        content = content.replace(\n",
        "            'from sktime.datasets import load_from_tsfile_to_dataframe',\n",
        "            'try:\\n    from sktime.datasets import load_from_tsfile_to_dataframe\\nexcept ImportError:\\n    load_from_tsfile_to_dataframe = None'\n",
        "        )\n",
        "        with open('data_provider/data_loader.py', 'w') as f:\n",
        "            f.write(content)\n",
        "        print(\"  âœ… ä¿®å¤ data_loader.py\")\n",
        "except Exception as e:\n",
        "    print(f\"  âš ï¸  data_loader.py: {e}\")\n",
        "\n",
        "# ä¿®å¤ patoolib\n",
        "try:\n",
        "    with open('data_provider/m4.py', 'r') as f:\n",
        "        content = f.read()\n",
        "\n",
        "    if 'import patoolib' in content and 'try:' not in content[:content.find('import patoolib')]:\n",
        "        content = content.replace(\n",
        "            'import patoolib',\n",
        "            'try:\\n    import patoolib\\nexcept ImportError:\\n    patoolib = None'\n",
        "        )\n",
        "        with open('data_provider/m4.py', 'w') as f:\n",
        "            f.write(content)\n",
        "        print(\"  âœ… ä¿®å¤ m4.py\")\n",
        "except Exception as e:\n",
        "    print(f\"  âš ï¸  m4.py: {e}\")\n",
        "\n",
        "# 8. éªŒè¯çŽ¯å¢ƒ\n",
        "print(\"\\nâœ… çŽ¯å¢ƒéªŒè¯:\")\n",
        "import torch\n",
        "print(f\"  PyTorch: {torch.__version__}\")\n",
        "print(f\"  CUDA: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"  è®¾å¤‡: CPU/MPS\")\n",
        "\n",
        "print(\"\\nðŸŽ‰ çŽ¯å¢ƒè®¾ç½®å®Œæˆï¼å¯ä»¥ç»§ç»­ä¸‹ä¸€æ­¥\")"
      ],
      "metadata": {
        "id": "NRP6Vpu8kV7K",
        "outputId": "b3bda54d-5323-4214-fc15-4503df5fb0c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… å½“å‰ç›®å½•: /content\n",
            "\n",
            "ðŸ§¹ æ¸…ç†æ—§æ–‡ä»¶...\n",
            "\n",
            "ðŸ“¥ å…‹éš†ä»£ç ...\n",
            "Cloning into 'TimeSeriesForecast'...\n",
            "remote: Enumerating objects: 2168, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (47/47), done.\u001b[K\n",
            "remote: Total 2168 (delta 39), reused 60 (delta 27), pack-reused 2093 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2168/2168), 78.47 MiB | 14.24 MiB/s, done.\n",
            "Resolving deltas: 100% (1484/1484), done.\n",
            "âœ… é¡¹ç›®ç›®å½•: /content/TimeSeriesForecast\n",
            "\n",
            "ðŸ“ éªŒè¯æ–‡ä»¶:\n",
            "  âœ… generate_optimized_aemo_data.py\n",
            "  âœ… three_stage_training.py\n",
            "  âœ… run.py\n",
            "\n",
            "ðŸ“¦ å®‰è£…ä¾èµ–...\n",
            "\n",
            "ðŸ”§ ä¿®å¤å¯¼å…¥é—®é¢˜...\n",
            "  âœ… ä¿®å¤ data_loader.py\n",
            "  âœ… ä¿®å¤ m4.py\n",
            "\n",
            "âœ… çŽ¯å¢ƒéªŒè¯:\n",
            "  PyTorch: 2.8.0+cu126\n",
            "  CUDA: True\n",
            "  GPU: Tesla T4\n",
            "\n",
            "ðŸŽ‰ çŽ¯å¢ƒè®¾ç½®å®Œæˆï¼å¯ä»¥ç»§ç»­ä¸‹ä¸€æ­¥\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ä»£ç å—2: ç”Ÿæˆæ•°æ®\n",
        "import os\n",
        "\n",
        "# ç¡®ä¿åœ¨æ­£ç¡®ç›®å½•\n",
        "if not os.getcwd().endswith('TimeSeriesForecast'):\n",
        "    os.chdir('/content/TimeSeriesForecast')\n",
        "\n",
        "print(f\"å½“å‰ç›®å½•: {os.getcwd()}\")\n",
        "print(\"\\nðŸ”§ ç”Ÿæˆä¼˜åŒ–æ•°æ®...\")\n",
        "\n",
        "!python3 generate_optimized_aemo_data.py\n",
        "\n",
        "# éªŒè¯\n",
        "import pandas as pd\n",
        "data_dir = './data/AEMO_optimized'\n",
        "\n",
        "if os.path.exists(data_dir):\n",
        "    files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
        "    print(f\"\\nâœ… ç”Ÿæˆäº† {len(files)} ä¸ªæ–‡ä»¶:\")\n",
        "\n",
        "    for freq in ['30min', '15min', '5min']:\n",
        "        freq_files = [f for f in files if freq in f]\n",
        "        if freq_files:\n",
        "            print(f\"\\n  {freq}: {len(freq_files)} ä¸ª\")\n",
        "            sample = freq_files[0]\n",
        "            df = pd.read_csv(f'{data_dir}/{sample}')\n",
        "            print(f\"    æ ·ä¾‹: {sample} ({len(df)} è¡Œ)\")\n",
        "else:\n",
        "    print(\"âŒ æ•°æ®ç›®å½•æœªåˆ›å»º\")"
      ],
      "metadata": {
        "id": "PbgcXeOQkc26",
        "outputId": "9002e4d9-f558-477e-d83a-376e0fb7ae14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "å½“å‰ç›®å½•: /content/TimeSeriesForecast\n",
            "\n",
            "ðŸ”§ ç”Ÿæˆä¼˜åŒ–æ•°æ®...\n",
            "================================================================================\n",
            "ðŸ”§ ç”Ÿæˆä¼˜åŒ–çš„AEMOæ•°æ®\n",
            "================================================================================\n",
            "ç­–ç•¥ï¼š\n",
            "  - 30åˆ†é’Ÿæ•°æ®ï¼š15ä¸ªæœˆï¼ˆè¶³å¤Ÿè¦†ç›–å­£èŠ‚æ€§ï¼‰\n",
            "  - 5åˆ†é’Ÿæ•°æ®ï¼š6ä¸ªæœˆï¼ˆé«˜é¢‘ï¼Œé¿å…è¿‡æ—§æ•°æ®ï¼‰\n",
            "  - 15åˆ†é’Ÿæ•°æ®ï¼šä»Ž5åˆ†é’Ÿé™é‡‡æ ·\n",
            "================================================================================\n",
            "\n",
            "[1/5] å¤„ç† NSW...\n",
            "  ç”Ÿæˆ NSW 30min æ•°æ®: 15ä¸ªæœˆ = 457å¤© = 21936æ¡è®°å½•\n",
            "  âœ… ä¿å­˜ ./data/AEMO_optimized/NSW_30min.csv\n",
            "  ç”Ÿæˆ NSW 5min æ•°æ®: 6ä¸ªæœˆ = 183å¤© = 52704æ¡è®°å½•\n",
            "  âœ… ä¿å­˜ ./data/AEMO_optimized/NSW_5min.csv\n",
            "  âœ… ä¿å­˜ ./data/AEMO_optimized/NSW_15min.csv (ä»Ž5miné™é‡‡æ ·)\n",
            "\n",
            "[2/5] å¤„ç† QLD...\n",
            "  ç”Ÿæˆ QLD 30min æ•°æ®: 15ä¸ªæœˆ = 457å¤© = 21936æ¡è®°å½•\n",
            "  âœ… ä¿å­˜ ./data/AEMO_optimized/QLD_30min.csv\n",
            "  ç”Ÿæˆ QLD 5min æ•°æ®: 6ä¸ªæœˆ = 183å¤© = 52704æ¡è®°å½•\n",
            "  âœ… ä¿å­˜ ./data/AEMO_optimized/QLD_5min.csv\n",
            "  âœ… ä¿å­˜ ./data/AEMO_optimized/QLD_15min.csv (ä»Ž5miné™é‡‡æ ·)\n",
            "\n",
            "[3/5] å¤„ç† VIC...\n",
            "  ç”Ÿæˆ VIC 30min æ•°æ®: 15ä¸ªæœˆ = 457å¤© = 21936æ¡è®°å½•\n",
            "  âœ… ä¿å­˜ ./data/AEMO_optimized/VIC_30min.csv\n",
            "  ç”Ÿæˆ VIC 5min æ•°æ®: 6ä¸ªæœˆ = 183å¤© = 52704æ¡è®°å½•\n",
            "  âœ… ä¿å­˜ ./data/AEMO_optimized/VIC_5min.csv\n",
            "  âœ… ä¿å­˜ ./data/AEMO_optimized/VIC_15min.csv (ä»Ž5miné™é‡‡æ ·)\n",
            "\n",
            "[4/5] å¤„ç† SA...\n",
            "  ç”Ÿæˆ SA 30min æ•°æ®: 15ä¸ªæœˆ = 457å¤© = 21936æ¡è®°å½•\n",
            "  âœ… ä¿å­˜ ./data/AEMO_optimized/SA_30min.csv\n",
            "  ç”Ÿæˆ SA 5min æ•°æ®: 6ä¸ªæœˆ = 183å¤© = 52704æ¡è®°å½•\n",
            "  âœ… ä¿å­˜ ./data/AEMO_optimized/SA_5min.csv\n",
            "  âœ… ä¿å­˜ ./data/AEMO_optimized/SA_15min.csv (ä»Ž5miné™é‡‡æ ·)\n",
            "\n",
            "[5/5] å¤„ç† TAS...\n",
            "  ç”Ÿæˆ TAS 30min æ•°æ®: 15ä¸ªæœˆ = 457å¤© = 21936æ¡è®°å½•\n",
            "  âœ… ä¿å­˜ ./data/AEMO_optimized/TAS_30min.csv\n",
            "  ç”Ÿæˆ TAS 5min æ•°æ®: 6ä¸ªæœˆ = 183å¤© = 52704æ¡è®°å½•\n",
            "  âœ… ä¿å­˜ ./data/AEMO_optimized/TAS_5min.csv\n",
            "  âœ… ä¿å­˜ ./data/AEMO_optimized/TAS_15min.csv (ä»Ž5miné™é‡‡æ ·)\n",
            "\n",
            "================================================================================\n",
            "âœ… æ‰€æœ‰æ•°æ®ç”Ÿæˆå®Œæˆï¼\n",
            "================================================================================\n",
            "\n",
            "ðŸ“Š æ•°æ®ç»Ÿè®¡:\n",
            "\n",
            "ç”Ÿæˆäº† 15 ä¸ªæ–‡ä»¶:\n",
            "\n",
            "30min æ•°æ®:\n",
            "  - SA_30min.csv             :   21936 è¡Œ,   2.34 MB\n",
            "  - TAS_30min.csv            :   21936 è¡Œ,   2.34 MB\n",
            "  - QLD_30min.csv            :   21936 è¡Œ,   2.34 MB\n",
            "  - VIC_30min.csv            :   21936 è¡Œ,   2.34 MB\n",
            "  - NSW_30min.csv            :   21936 è¡Œ,   2.34 MB\n",
            "\n",
            "15min æ•°æ®:\n",
            "  - NSW_15min.csv            :   17568 è¡Œ,   1.88 MB\n",
            "  - QLD_15min.csv            :   17568 è¡Œ,   1.88 MB\n",
            "  - VIC_15min.csv            :   17568 è¡Œ,   1.88 MB\n",
            "  - TAS_15min.csv            :   17568 è¡Œ,   1.88 MB\n",
            "  - SA_15min.csv             :   17568 è¡Œ,   1.88 MB\n",
            "\n",
            "5min æ•°æ®:\n",
            "  - SA_5min.csv              :   52704 è¡Œ,   5.63 MB\n",
            "  - VIC_5min.csv             :   52704 è¡Œ,   5.63 MB\n",
            "  - QLD_5min.csv             :   52704 è¡Œ,   5.63 MB\n",
            "  - NSW_5min.csv             :   52704 è¡Œ,   5.63 MB\n",
            "  - NSW_15min.csv            :   17568 è¡Œ,   1.88 MB\n",
            "  - QLD_15min.csv            :   17568 è¡Œ,   1.88 MB\n",
            "  - VIC_15min.csv            :   17568 è¡Œ,   1.88 MB\n",
            "  - TAS_5min.csv             :   52704 è¡Œ,   5.63 MB\n",
            "  - TAS_15min.csv            :   17568 è¡Œ,   1.88 MB\n",
            "  - SA_15min.csv             :   17568 è¡Œ,   1.88 MB\n",
            "\n",
            "æ€»å¤§å°: 58.67 MB\n",
            "\n",
            "ðŸ’¡ ç›¸æ¯”åŽŸ22ä¸ªæœˆæ–¹æ¡ˆï¼Œæ•°æ®é‡å‡å°‘çº¦ 60-70%\n",
            "ðŸ’¡ è®­ç»ƒé€Ÿåº¦é¢„è®¡æå‡ 3-5å€ï¼Œä¸”æ•ˆæžœæ›´å¥½ï¼ˆé¿å…è¿‡æ—§æ•°æ®å™ªå£°ï¼‰\n",
            "\n",
            "âœ… ç”Ÿæˆäº† 15 ä¸ªæ–‡ä»¶:\n",
            "\n",
            "  30min: 5 ä¸ª\n",
            "    æ ·ä¾‹: SA_30min.csv (21936 è¡Œ)\n",
            "\n",
            "  15min: 5 ä¸ª\n",
            "    æ ·ä¾‹: NSW_15min.csv (17568 è¡Œ)\n",
            "\n",
            "  5min: 10 ä¸ª\n",
            "    æ ·ä¾‹: SA_5min.csv (52704 è¡Œ)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å®‰è£…ç¼ºå¤±çš„ reformer_pytorch\n",
        "!pip install -q reformer_pytorch\n",
        "\n",
        "print(\"âœ… reformer_pytorch å®‰è£…å®Œæˆï¼\")\n",
        "\n",
        "# éªŒè¯\n",
        "try:\n",
        "    from reformer_pytorch import LSHSelfAttention\n",
        "    print(\"âœ… reformer_pytorch å¯¼å…¥æˆåŠŸ\")\n",
        "except:\n",
        "    print(\"âŒ å¯¼å…¥å¤±è´¥ï¼Œè¯·é‡å¯Runtime\")"
      ],
      "metadata": {
        "id": "rdhiTss8IS9q",
        "outputId": "1cbbbc30-65e5-4156-8c43-731549c36854",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… reformer_pytorch å®‰è£…å®Œæˆï¼\n",
            "âœ… reformer_pytorch å¯¼å…¥æˆåŠŸ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, platform\n",
        "print(\"cuda?\", torch.cuda.is_available())\n",
        "print(\"device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"torch:\", torch.__version__, \"python:\", platform.python_version())\n"
      ],
      "metadata": {
        "id": "GrjpaPJGK_Fy",
        "outputId": "026d6c18-2adc-467c-c14d-a0d029c28edd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda? True\n",
            "device: Tesla T4\n",
            "torch: 2.8.0+cu126 python: 3.12.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/TimeSeriesForecast')\n",
        "\n",
        "print(\"ðŸš€ å¼€å§‹ä¸‰é˜¶æ®µè®­ç»ƒ...\")\n",
        "!python3 three_stage_training.py"
      ],
      "metadata": {
        "id": "s0a_4T3Hyese",
        "outputId": "2a6ee51e-354c-461e-a546-b9648c9c2e13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ å¼€å§‹ä¸‰é˜¶æ®µè®­ç»ƒ...\n",
            "================================================================================\n",
            "ðŸš€ AEMOæ—¶åºé¢„æµ‹ - ä¸‰é˜¶æ®µä¼˜åŒ–è®­ç»ƒ\n",
            "================================================================================\n",
            "ç­–ç•¥è¯´æ˜Ž:\n",
            "  é˜¶æ®µ1: æ¨¡åž‹ç­›é€‰ï¼ˆ2å·ž Ã— 4æ¨¡åž‹ = 8ä¸ªå®žéªŒï¼Œçº¦1-2å°æ—¶ï¼‰\n",
            "  é˜¶æ®µ2: æ‰©å±•éªŒè¯ï¼ˆ5å·ž Ã— 2é¢‘çŽ‡ Ã— 2æ¨¡åž‹ = 20ä¸ªå®žéªŒï¼Œçº¦3-4å°æ—¶ï¼‰\n",
            "  é˜¶æ®µ3: æ­¥é•¿æ‰©å±•ï¼ˆ5å·ž Ã— 3æ­¥é•¿ Ã— 1æ¨¡åž‹ = 15ä¸ªå®žéªŒï¼Œçº¦2-3å°æ—¶ï¼‰\n",
            "  æ€»è®¡: çº¦43ä¸ªå®žéªŒï¼Œç›¸æ¯”åŽŸæ–¹æ¡ˆï¼ˆ120ä¸ªï¼‰å‡å°‘64%\n",
            "================================================================================\n",
            "âœ… cuDNN benchmark å·²å¯ç”¨\n",
            "\n",
            "ðŸ–¥ï¸  è®¾å¤‡: GPU (CUDA: Tesla T4)\n",
            "ðŸ’¾ æ˜¾å­˜: 14.7 GB\n",
            "âš¡ AMP: å·²å¯ç”¨ (FP16æ··åˆç²¾åº¦)\n",
            "ðŸ‘· Workers: 2 (ä¼˜åŒ–Colabæ€§èƒ½)\n",
            "\n",
            "================================================================================\n",
            "ðŸŽ¯ é˜¶æ®µ1: æ¨¡åž‹ç­›é€‰ï¼ˆå¿«é€Ÿå¯¹æ¯”4ä¸ªæ¨¡åž‹ï¼‰\n",
            "================================================================================\n",
            "é…ç½®:\n",
            "  - å·ž: NSW (ä½“é‡å¤§), SA (æ³¢åŠ¨å¤§)\n",
            "  - é¢‘çŽ‡: 30min\n",
            "  - é¢„æµ‹æ­¥é•¿: 24 (12å°æ—¶)\n",
            "  - è®­ç»ƒè½®æ•°: 8 epochs, æ—©åœpatience=2\n",
            "  - ç›®æ ‡: é€‰å‡ºå‰2ä¸ªæœ€ä¼˜æ¨¡åž‹\n",
            "================================================================================\n",
            "\n",
            "[1/8] ðŸš€ NSW | DLinear\n",
            "--------------------------------------------------------------------------------\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage1_NSW_DLinear  Model:              DLinear             \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          NSW_30min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              5                   Num Kernels:        6                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            512                 \n",
            "  n heads:            8                   e layers:           2                   \n",
            "  d layers:           1                   d FF:               2048                \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       8                   Batch Size:         64                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            1                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage1_NSW_DLinear_DLinear_custom_ftM_sl192_ll96_pl24_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15140\n",
            "val 2171\n",
            "test 4364\n",
            "\titers: 100, epoch: 1 | loss: 0.7178215\n",
            "\tspeed: 0.0117s/iter; left time: 20.9961s\n",
            "\titers: 200, epoch: 1 | loss: 0.7866386\n",
            "\tspeed: 0.0053s/iter; left time: 9.0509s\n",
            "Epoch: 1 cost time: 1.9131181240081787\n",
            "Epoch: 1, Steps: 237 | Train Loss: 0.7147119 Vali Loss: 0.4745118 Test Loss: 0.8142124\n",
            "Validation loss decreased (inf --> 0.474512).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.7258112\n",
            "\tspeed: 0.0130s/iter; left time: 20.3419s\n",
            "\titers: 200, epoch: 2 | loss: 0.5756701\n",
            "\tspeed: 0.0051s/iter; left time: 7.5077s\n",
            "Epoch: 2 cost time: 1.3076364994049072\n",
            "Epoch: 2, Steps: 237 | Train Loss: 0.7049056 Vali Loss: 0.4743737 Test Loss: 0.8153746\n",
            "Validation loss decreased (0.474512 --> 0.474374).  Saving model ...\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.9450234\n",
            "\tspeed: 0.0133s/iter; left time: 17.5647s\n",
            "\titers: 200, epoch: 3 | loss: 0.8783904\n",
            "\tspeed: 0.0049s/iter; left time: 6.0522s\n",
            "Epoch: 3 cost time: 1.2684054374694824\n",
            "Epoch: 3, Steps: 237 | Train Loss: 0.6993966 Vali Loss: 0.4733980 Test Loss: 0.8117242\n",
            "Validation loss decreased (0.474374 --> 0.473398).  Saving model ...\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.5416840\n",
            "\tspeed: 0.0128s/iter; left time: 13.8923s\n",
            "\titers: 200, epoch: 4 | loss: 0.4755448\n",
            "\tspeed: 0.0052s/iter; left time: 5.0785s\n",
            "Epoch: 4 cost time: 1.2580089569091797\n",
            "Epoch: 4, Steps: 237 | Train Loss: 0.6948257 Vali Loss: 0.4717223 Test Loss: 0.8101575\n",
            "Validation loss decreased (0.473398 --> 0.471722).  Saving model ...\n",
            "Updating learning rate to 0.000125\n",
            "\titers: 100, epoch: 5 | loss: 0.6096365\n",
            "\tspeed: 0.0128s/iter; left time: 10.8293s\n",
            "\titers: 200, epoch: 5 | loss: 0.6517738\n",
            "\tspeed: 0.0064s/iter; left time: 4.8044s\n",
            "Epoch: 5 cost time: 1.52960205078125\n",
            "Epoch: 5, Steps: 237 | Train Loss: 0.6930536 Vali Loss: 0.4710012 Test Loss: 0.8098711\n",
            "Validation loss decreased (0.471722 --> 0.471001).  Saving model ...\n",
            "Updating learning rate to 6.25e-05\n",
            "\titers: 100, epoch: 6 | loss: 0.8365398\n",
            "\tspeed: 0.0210s/iter; left time: 12.8504s\n",
            "\titers: 200, epoch: 6 | loss: 0.6520218\n",
            "\tspeed: 0.0050s/iter; left time: 2.5461s\n",
            "Epoch: 6 cost time: 1.576164960861206\n",
            "Epoch: 6, Steps: 237 | Train Loss: 0.6925393 Vali Loss: 0.4708634 Test Loss: 0.8096005\n",
            "Validation loss decreased (0.471001 --> 0.470863).  Saving model ...\n",
            "Updating learning rate to 3.125e-05\n",
            "\titers: 100, epoch: 7 | loss: 0.8841298\n",
            "\tspeed: 0.0131s/iter; left time: 4.9172s\n",
            "\titers: 200, epoch: 7 | loss: 0.8451791\n",
            "\tspeed: 0.0052s/iter; left time: 1.4200s\n",
            "Epoch: 7 cost time: 1.288041591644287\n",
            "Epoch: 7, Steps: 237 | Train Loss: 0.6917560 Vali Loss: 0.4710366 Test Loss: 0.8095667\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 1.5625e-05\n",
            "\titers: 100, epoch: 8 | loss: 0.4351327\n",
            "\tspeed: 0.0168s/iter; left time: 2.3151s\n",
            "\titers: 200, epoch: 8 | loss: 0.7451381\n",
            "\tspeed: 0.0051s/iter; left time: 0.1949s\n",
            "Epoch: 8 cost time: 1.5527923107147217\n",
            "Epoch: 8, Steps: 237 | Train Loss: 0.6909254 Vali Loss: 0.4709265 Test Loss: 0.8095363\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage1_NSW_DLinear_DLinear_custom_ftM_sl192_ll96_pl24_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4364\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "mse:0.816300630569458, mae:0.48880884051322937, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage1_NSW_DLinear_DLinear_custom_ftM_sl192_ll96_pl24_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage1_NSW_DLinear_DLinear_custom_ftM_sl192_ll96_pl24_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.8163, MAE=0.4888\n",
            "âœ… å®Œæˆ | MAE: 0.4888 | ç”¨æ—¶: 0.4åˆ†é’Ÿ\n",
            "\n",
            "[2/8] ðŸš€ NSW | PatchTST\n",
            "--------------------------------------------------------------------------------\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage1_NSW_PatchTST Model:              PatchTST            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          NSW_30min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              5                   Num Kernels:        6                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            4                   e layers:           2                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       8                   Batch Size:         32                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            1                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage1_NSW_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15140\n",
            "val 2171\n",
            "test 4364\n",
            "\titers: 100, epoch: 1 | loss: 0.5871094\n",
            "\tspeed: 0.0213s/iter; left time: 78.5814s\n",
            "\titers: 200, epoch: 1 | loss: 0.6734711\n",
            "\tspeed: 0.0121s/iter; left time: 43.3945s\n",
            "\titers: 300, epoch: 1 | loss: 1.3234851\n",
            "\tspeed: 0.0124s/iter; left time: 43.1718s\n",
            "\titers: 400, epoch: 1 | loss: 0.8406035\n",
            "\tspeed: 0.0123s/iter; left time: 41.7421s\n",
            "Epoch: 1 cost time: 7.388626575469971\n",
            "Epoch: 1, Steps: 474 | Train Loss: 0.8463010 Vali Loss: 0.5565882 Test Loss: 0.8492749\n",
            "Validation loss decreased (inf --> 0.556588).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.8339768\n",
            "\tspeed: 0.0784s/iter; left time: 252.2264s\n",
            "\titers: 200, epoch: 2 | loss: 0.8004039\n",
            "\tspeed: 0.0161s/iter; left time: 50.2697s\n",
            "\titers: 300, epoch: 2 | loss: 0.6369314\n",
            "\tspeed: 0.0125s/iter; left time: 37.6708s\n",
            "\titers: 400, epoch: 2 | loss: 0.5105742\n",
            "\tspeed: 0.0127s/iter; left time: 37.0936s\n",
            "Epoch: 2 cost time: 8.652560234069824\n",
            "Epoch: 2, Steps: 474 | Train Loss: 0.7593065 Vali Loss: 0.5022579 Test Loss: 0.8486041\n",
            "Validation loss decreased (0.556588 --> 0.502258).  Saving model ...\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.9392463\n",
            "\tspeed: 0.0356s/iter; left time: 97.5991s\n",
            "\titers: 200, epoch: 3 | loss: 1.1061459\n",
            "\tspeed: 0.0146s/iter; left time: 38.6805s\n",
            "\titers: 300, epoch: 3 | loss: 0.6822463\n",
            "\tspeed: 0.0176s/iter; left time: 44.9187s\n",
            "\titers: 400, epoch: 3 | loss: 0.9406034\n",
            "\tspeed: 0.0123s/iter; left time: 30.1003s\n",
            "Epoch: 3 cost time: 6.686107873916626\n",
            "Epoch: 3, Steps: 474 | Train Loss: 0.7195713 Vali Loss: 0.4698417 Test Loss: 0.8005403\n",
            "Validation loss decreased (0.502258 --> 0.469842).  Saving model ...\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.5284713\n",
            "\tspeed: 0.0351s/iter; left time: 79.7567s\n",
            "\titers: 200, epoch: 4 | loss: 0.7219290\n",
            "\tspeed: 0.0122s/iter; left time: 26.5408s\n",
            "\titers: 300, epoch: 4 | loss: 0.7009895\n",
            "\tspeed: 0.0122s/iter; left time: 25.2524s\n",
            "\titers: 400, epoch: 4 | loss: 0.5659485\n",
            "\tspeed: 0.0122s/iter; left time: 24.0863s\n",
            "Epoch: 4 cost time: 5.881607294082642\n",
            "Epoch: 4, Steps: 474 | Train Loss: 0.7131681 Vali Loss: 0.4685408 Test Loss: 0.7989963\n",
            "Validation loss decreased (0.469842 --> 0.468541).  Saving model ...\n",
            "Updating learning rate to 0.000125\n",
            "\titers: 100, epoch: 5 | loss: 0.7788509\n",
            "\tspeed: 0.0429s/iter; left time: 77.0145s\n",
            "\titers: 200, epoch: 5 | loss: 0.9871598\n",
            "\tspeed: 0.0121s/iter; left time: 20.5394s\n",
            "\titers: 300, epoch: 5 | loss: 0.8183316\n",
            "\tspeed: 0.0122s/iter; left time: 19.4974s\n",
            "\titers: 400, epoch: 5 | loss: 0.5766878\n",
            "\tspeed: 0.0124s/iter; left time: 18.5615s\n",
            "Epoch: 5 cost time: 6.274471044540405\n",
            "Epoch: 5, Steps: 474 | Train Loss: 0.7090309 Vali Loss: 0.4666933 Test Loss: 0.7992383\n",
            "Validation loss decreased (0.468541 --> 0.466693).  Saving model ...\n",
            "Updating learning rate to 6.25e-05\n",
            "\titers: 100, epoch: 6 | loss: 0.4989475\n",
            "\tspeed: 0.0354s/iter; left time: 46.8113s\n",
            "\titers: 200, epoch: 6 | loss: 0.7446793\n",
            "\tspeed: 0.0121s/iter; left time: 14.8384s\n",
            "\titers: 300, epoch: 6 | loss: 0.6154320\n",
            "\tspeed: 0.0137s/iter; left time: 15.3652s\n",
            "\titers: 400, epoch: 6 | loss: 0.6324663\n",
            "\tspeed: 0.0177s/iter; left time: 18.1448s\n",
            "Epoch: 6 cost time: 6.587680339813232\n",
            "Epoch: 6, Steps: 474 | Train Loss: 0.7086236 Vali Loss: 0.4649153 Test Loss: 0.7989375\n",
            "Validation loss decreased (0.466693 --> 0.464915).  Saving model ...\n",
            "Updating learning rate to 3.125e-05\n",
            "\titers: 100, epoch: 7 | loss: 0.7410985\n",
            "\tspeed: 0.0363s/iter; left time: 30.7825s\n",
            "\titers: 200, epoch: 7 | loss: 0.6388761\n",
            "\tspeed: 0.0122s/iter; left time: 9.1259s\n",
            "\titers: 300, epoch: 7 | loss: 0.6672288\n",
            "\tspeed: 0.0120s/iter; left time: 7.7862s\n",
            "\titers: 400, epoch: 7 | loss: 0.8353620\n",
            "\tspeed: 0.0121s/iter; left time: 6.6617s\n",
            "Epoch: 7 cost time: 5.910359144210815\n",
            "Epoch: 7, Steps: 474 | Train Loss: 0.7072555 Vali Loss: 0.4667050 Test Loss: 0.7992153\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 1.5625e-05\n",
            "\titers: 100, epoch: 8 | loss: 0.5547704\n",
            "\tspeed: 0.0385s/iter; left time: 14.4526s\n",
            "\titers: 200, epoch: 8 | loss: 0.7705086\n",
            "\tspeed: 0.0163s/iter; left time: 4.4839s\n",
            "\titers: 300, epoch: 8 | loss: 0.8417432\n",
            "\tspeed: 0.0121s/iter; left time: 2.1102s\n",
            "\titers: 400, epoch: 8 | loss: 0.6679263\n",
            "\tspeed: 0.0163s/iter; left time: 1.2247s\n",
            "Epoch: 8 cost time: 7.222299575805664\n",
            "Epoch: 8, Steps: 474 | Train Loss: 0.7053721 Vali Loss: 0.4660468 Test Loss: 0.7991739\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage1_NSW_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4364\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "mse:0.8016588687896729, mae:0.4726355969905853, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage1_NSW_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage1_NSW_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.8017, MAE=0.4726\n",
            "âœ… å®Œæˆ | MAE: 0.4726 | ç”¨æ—¶: 1.3åˆ†é’Ÿ\n",
            "\n",
            "[3/8] ðŸš€ NSW | TimesNet\n",
            "--------------------------------------------------------------------------------\n",
            "  âš ï¸  TimesNetå…³é—­AMP (é¿å…cuFFT FP16é”™è¯¯)ï¼Œä½¿ç”¨FP32è®­ç»ƒ\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage1_NSW_TimesNet Model:              TimesNet            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          NSW_30min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              3                   Num Kernels:        4                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            8                   e layers:           1                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       8                   Batch Size:         16                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            0                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage1_NSW_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15140\n",
            "val 2171\n",
            "test 4364\n",
            "\titers: 100, epoch: 1 | loss: 1.2049650\n",
            "\tspeed: 0.0838s/iter; left time: 626.8420s\n",
            "\titers: 200, epoch: 1 | loss: 1.0872614\n",
            "\tspeed: 0.0779s/iter; left time: 574.9313s\n",
            "\titers: 300, epoch: 1 | loss: 0.5841711\n",
            "\tspeed: 0.0820s/iter; left time: 596.9618s\n",
            "\titers: 400, epoch: 1 | loss: 0.6028912\n",
            "\tspeed: 0.0833s/iter; left time: 597.8535s\n",
            "\titers: 500, epoch: 1 | loss: 0.7055544\n",
            "\tspeed: 0.0860s/iter; left time: 608.3245s\n",
            "\titers: 600, epoch: 1 | loss: 0.5016915\n",
            "\tspeed: 0.0888s/iter; left time: 619.6417s\n",
            "\titers: 700, epoch: 1 | loss: 0.6204432\n",
            "\tspeed: 0.0903s/iter; left time: 621.0427s\n",
            "\titers: 800, epoch: 1 | loss: 0.6798943\n",
            "\tspeed: 0.1014s/iter; left time: 687.0953s\n",
            "\titers: 900, epoch: 1 | loss: 0.5601316\n",
            "\tspeed: 0.1024s/iter; left time: 683.3947s\n",
            "Epoch: 1 cost time: 84.64199113845825\n",
            "Epoch: 1, Steps: 947 | Train Loss: 0.6991678 Vali Loss: 0.4614226 Test Loss: 0.8001683\n",
            "Validation loss decreased (inf --> 0.461423).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.6436666\n",
            "\tspeed: 0.3654s/iter; left time: 2385.7753s\n",
            "\titers: 200, epoch: 2 | loss: 0.6987650\n",
            "\tspeed: 0.1013s/iter; left time: 651.1101s\n",
            "\titers: 300, epoch: 2 | loss: 0.7901579\n",
            "\tspeed: 0.1012s/iter; left time: 640.4620s\n",
            "\titers: 400, epoch: 2 | loss: 0.6495169\n",
            "\tspeed: 0.1012s/iter; left time: 630.6800s\n",
            "\titers: 500, epoch: 2 | loss: 0.7476221\n",
            "\tspeed: 0.1015s/iter; left time: 622.0322s\n",
            "\titers: 600, epoch: 2 | loss: 0.5140497\n",
            "\tspeed: 0.1013s/iter; left time: 610.5589s\n",
            "\titers: 700, epoch: 2 | loss: 1.2347962\n",
            "\tspeed: 0.1013s/iter; left time: 600.4980s\n",
            "\titers: 800, epoch: 2 | loss: 0.4556444\n",
            "\tspeed: 0.0980s/iter; left time: 571.5712s\n",
            "\titers: 900, epoch: 2 | loss: 0.7682180\n",
            "\tspeed: 0.0987s/iter; left time: 565.2730s\n",
            "Epoch: 2 cost time: 95.2532434463501\n",
            "Epoch: 2, Steps: 947 | Train Loss: 0.6799119 Vali Loss: 0.4548430 Test Loss: 0.7917399\n",
            "Validation loss decreased (0.461423 --> 0.454843).  Saving model ...\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.3623137\n",
            "\tspeed: 0.3156s/iter; left time: 1762.2176s\n",
            "\titers: 200, epoch: 3 | loss: 0.8821052\n",
            "\tspeed: 0.0963s/iter; left time: 528.1394s\n",
            "\titers: 300, epoch: 3 | loss: 0.6855571\n",
            "\tspeed: 0.0958s/iter; left time: 515.4651s\n",
            "\titers: 400, epoch: 3 | loss: 0.5663545\n",
            "\tspeed: 0.0952s/iter; left time: 502.6850s\n",
            "\titers: 500, epoch: 3 | loss: 0.3999397\n",
            "\tspeed: 0.0871s/iter; left time: 451.5421s\n",
            "\titers: 600, epoch: 3 | loss: 0.7674098\n",
            "\tspeed: 0.0873s/iter; left time: 443.8424s\n",
            "\titers: 700, epoch: 3 | loss: 1.0093987\n",
            "\tspeed: 0.0873s/iter; left time: 435.0489s\n",
            "\titers: 800, epoch: 3 | loss: 0.8258812\n",
            "\tspeed: 0.0977s/iter; left time: 477.2121s\n",
            "\titers: 900, epoch: 3 | loss: 0.3768440\n",
            "\tspeed: 0.0971s/iter; left time: 464.3652s\n",
            "Epoch: 3 cost time: 88.93292784690857\n",
            "Epoch: 3, Steps: 947 | Train Loss: 0.6723105 Vali Loss: 0.4570430 Test Loss: 0.7901386\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.6311005\n",
            "\tspeed: 0.3218s/iter; left time: 1491.7646s\n",
            "\titers: 200, epoch: 4 | loss: 0.8399162\n",
            "\tspeed: 0.0955s/iter; left time: 433.3640s\n",
            "\titers: 300, epoch: 4 | loss: 0.7337498\n",
            "\tspeed: 0.0950s/iter; left time: 421.3803s\n",
            "\titers: 400, epoch: 4 | loss: 0.4869330\n",
            "\tspeed: 0.0961s/iter; left time: 416.7249s\n",
            "\titers: 500, epoch: 4 | loss: 0.8546726\n",
            "\tspeed: 0.0960s/iter; left time: 406.6766s\n",
            "\titers: 600, epoch: 4 | loss: 0.5377926\n",
            "\tspeed: 0.0971s/iter; left time: 401.4059s\n",
            "\titers: 700, epoch: 4 | loss: 0.4278202\n",
            "\tspeed: 0.0946s/iter; left time: 381.9410s\n",
            "\titers: 800, epoch: 4 | loss: 0.3876715\n",
            "\tspeed: 0.0963s/iter; left time: 379.1110s\n",
            "\titers: 900, epoch: 4 | loss: 0.3531045\n",
            "\tspeed: 0.0979s/iter; left time: 375.6336s\n",
            "Epoch: 4 cost time: 91.53467631340027\n",
            "Epoch: 4, Steps: 947 | Train Loss: 0.6679568 Vali Loss: 0.4630101 Test Loss: 0.7930627\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage1_NSW_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4364\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "mse:0.7922492623329163, mae:0.47537922859191895, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage1_NSW_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage1_NSW_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.7922, MAE=0.4754\n",
            "âœ… å®Œæˆ | MAE: 0.4754 | ç”¨æ—¶: 7.6åˆ†é’Ÿ\n",
            "\n",
            "[4/8] ðŸš€ NSW | iTransformer\n",
            "--------------------------------------------------------------------------------\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage1_NSW_iTransformerModel:              iTransformer        \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          NSW_30min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              5                   Num Kernels:        6                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            4                   e layers:           2                   \n",
            "  d layers:           1                   d FF:               256                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       8                   Batch Size:         16                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            1                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage1_NSW_iTransformer_iTransformer_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15140\n",
            "val 2171\n",
            "test 4364\n",
            "\titers: 100, epoch: 1 | loss: 0.5440978\n",
            "\tspeed: 0.0203s/iter; left time: 151.5747s\n",
            "\titers: 200, epoch: 1 | loss: 0.7685055\n",
            "\tspeed: 0.0117s/iter; left time: 86.4098s\n",
            "\titers: 300, epoch: 1 | loss: 0.9587489\n",
            "\tspeed: 0.0142s/iter; left time: 103.4479s\n",
            "\titers: 400, epoch: 1 | loss: 1.2359101\n",
            "\tspeed: 0.0156s/iter; left time: 112.1822s\n",
            "\titers: 500, epoch: 1 | loss: 0.7535371\n",
            "\tspeed: 0.0117s/iter; left time: 83.0226s\n",
            "\titers: 600, epoch: 1 | loss: 0.8644498\n",
            "\tspeed: 0.0121s/iter; left time: 84.1376s\n",
            "\titers: 700, epoch: 1 | loss: 0.8483755\n",
            "\tspeed: 0.0119s/iter; left time: 82.0215s\n",
            "\titers: 800, epoch: 1 | loss: 0.7529474\n",
            "\tspeed: 0.0117s/iter; left time: 79.0432s\n",
            "\titers: 900, epoch: 1 | loss: 0.5982798\n",
            "\tspeed: 0.0116s/iter; left time: 77.5998s\n",
            "Epoch: 1 cost time: 12.681246995925903\n",
            "Epoch: 1, Steps: 947 | Train Loss: 0.7309989 Vali Loss: 0.4776286 Test Loss: 0.8255384\n",
            "Validation loss decreased (inf --> 0.477629).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.6701894\n",
            "\tspeed: 0.0423s/iter; left time: 276.1590s\n",
            "\titers: 200, epoch: 2 | loss: 0.9739708\n",
            "\tspeed: 0.0165s/iter; left time: 106.1114s\n",
            "\titers: 300, epoch: 2 | loss: 0.7011319\n",
            "\tspeed: 0.0125s/iter; left time: 79.0059s\n",
            "\titers: 400, epoch: 2 | loss: 1.0474463\n",
            "\tspeed: 0.0115s/iter; left time: 71.4295s\n",
            "\titers: 500, epoch: 2 | loss: 0.7099320\n",
            "\tspeed: 0.0117s/iter; left time: 71.8804s\n",
            "\titers: 600, epoch: 2 | loss: 1.0089077\n",
            "\tspeed: 0.0116s/iter; left time: 70.0593s\n",
            "\titers: 700, epoch: 2 | loss: 1.6043139\n",
            "\tspeed: 0.0118s/iter; left time: 69.8751s\n",
            "\titers: 800, epoch: 2 | loss: 0.6129552\n",
            "\tspeed: 0.0118s/iter; left time: 68.9305s\n",
            "\titers: 900, epoch: 2 | loss: 0.5513051\n",
            "\tspeed: 0.0117s/iter; left time: 66.9456s\n",
            "Epoch: 2 cost time: 11.84057903289795\n",
            "Epoch: 2, Steps: 947 | Train Loss: 0.7076371 Vali Loss: 0.4743979 Test Loss: 0.8178754\n",
            "Validation loss decreased (0.477629 --> 0.474398).  Saving model ...\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.6273578\n",
            "\tspeed: 0.0477s/iter; left time: 266.4446s\n",
            "\titers: 200, epoch: 3 | loss: 0.6240294\n",
            "\tspeed: 0.0118s/iter; left time: 64.7715s\n",
            "\titers: 300, epoch: 3 | loss: 0.4198156\n",
            "\tspeed: 0.0118s/iter; left time: 63.7103s\n",
            "\titers: 400, epoch: 3 | loss: 0.7781575\n",
            "\tspeed: 0.0116s/iter; left time: 61.2472s\n",
            "\titers: 500, epoch: 3 | loss: 0.8624738\n",
            "\tspeed: 0.0117s/iter; left time: 60.5938s\n",
            "\titers: 600, epoch: 3 | loss: 0.5600619\n",
            "\tspeed: 0.0116s/iter; left time: 58.8426s\n",
            "\titers: 700, epoch: 3 | loss: 0.4097565\n",
            "\tspeed: 0.0115s/iter; left time: 57.3594s\n",
            "\titers: 800, epoch: 3 | loss: 0.5347944\n",
            "\tspeed: 0.0123s/iter; left time: 60.1222s\n",
            "\titers: 900, epoch: 3 | loss: 0.3790432\n",
            "\tspeed: 0.0122s/iter; left time: 58.4269s\n",
            "Epoch: 3 cost time: 11.795775651931763\n",
            "Epoch: 3, Steps: 947 | Train Loss: 0.6932821 Vali Loss: 0.4667854 Test Loss: 0.8123392\n",
            "Validation loss decreased (0.474398 --> 0.466785).  Saving model ...\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.4988786\n",
            "\tspeed: 0.0476s/iter; left time: 220.8349s\n",
            "\titers: 200, epoch: 4 | loss: 0.6487396\n",
            "\tspeed: 0.0116s/iter; left time: 52.7803s\n",
            "\titers: 300, epoch: 4 | loss: 0.5909176\n",
            "\tspeed: 0.0116s/iter; left time: 51.5754s\n",
            "\titers: 400, epoch: 4 | loss: 0.8692869\n",
            "\tspeed: 0.0116s/iter; left time: 50.4664s\n",
            "\titers: 500, epoch: 4 | loss: 0.5841914\n",
            "\tspeed: 0.0118s/iter; left time: 49.8151s\n",
            "\titers: 600, epoch: 4 | loss: 0.5678442\n",
            "\tspeed: 0.0119s/iter; left time: 49.1982s\n",
            "\titers: 700, epoch: 4 | loss: 0.4809649\n",
            "\tspeed: 0.0121s/iter; left time: 48.8554s\n",
            "\titers: 800, epoch: 4 | loss: 0.4638705\n",
            "\tspeed: 0.0148s/iter; left time: 58.0989s\n",
            "\titers: 900, epoch: 4 | loss: 0.8605887\n",
            "\tspeed: 0.0156s/iter; left time: 59.9401s\n",
            "Epoch: 4 cost time: 11.897996664047241\n",
            "Epoch: 4, Steps: 947 | Train Loss: 0.6836489 Vali Loss: 0.4634717 Test Loss: 0.8083690\n",
            "Validation loss decreased (0.466785 --> 0.463472).  Saving model ...\n",
            "Updating learning rate to 0.000125\n",
            "\titers: 100, epoch: 5 | loss: 0.4968644\n",
            "\tspeed: 0.0409s/iter; left time: 150.8912s\n",
            "\titers: 200, epoch: 5 | loss: 0.5287998\n",
            "\tspeed: 0.0116s/iter; left time: 41.6092s\n",
            "\titers: 300, epoch: 5 | loss: 0.6909498\n",
            "\tspeed: 0.0116s/iter; left time: 40.5766s\n",
            "\titers: 400, epoch: 5 | loss: 0.9108251\n",
            "\tspeed: 0.0120s/iter; left time: 40.6602s\n",
            "\titers: 500, epoch: 5 | loss: 1.5312569\n",
            "\tspeed: 0.0116s/iter; left time: 38.2518s\n",
            "\titers: 600, epoch: 5 | loss: 0.7407039\n",
            "\tspeed: 0.0132s/iter; left time: 42.2479s\n",
            "\titers: 700, epoch: 5 | loss: 0.6925440\n",
            "\tspeed: 0.0168s/iter; left time: 51.8860s\n",
            "\titers: 800, epoch: 5 | loss: 0.2849710\n",
            "\tspeed: 0.0120s/iter; left time: 35.9953s\n",
            "\titers: 900, epoch: 5 | loss: 0.8098249\n",
            "\tspeed: 0.0122s/iter; left time: 35.2699s\n",
            "Epoch: 5 cost time: 11.945984840393066\n",
            "Epoch: 5, Steps: 947 | Train Loss: 0.6757730 Vali Loss: 0.4634300 Test Loss: 0.8128134\n",
            "Validation loss decreased (0.463472 --> 0.463430).  Saving model ...\n",
            "Updating learning rate to 6.25e-05\n",
            "\titers: 100, epoch: 6 | loss: 0.8744853\n",
            "\tspeed: 0.0409s/iter; left time: 112.0978s\n",
            "\titers: 200, epoch: 6 | loss: 0.9707835\n",
            "\tspeed: 0.0119s/iter; left time: 31.3917s\n",
            "\titers: 300, epoch: 6 | loss: 0.5761208\n",
            "\tspeed: 0.0119s/iter; left time: 30.1244s\n",
            "\titers: 400, epoch: 6 | loss: 0.5025176\n",
            "\tspeed: 0.0117s/iter; left time: 28.5461s\n",
            "\titers: 500, epoch: 6 | loss: 0.6119869\n",
            "\tspeed: 0.0158s/iter; left time: 36.9589s\n",
            "\titers: 600, epoch: 6 | loss: 0.7725500\n",
            "\tspeed: 0.0142s/iter; left time: 31.9359s\n",
            "\titers: 700, epoch: 6 | loss: 0.4933314\n",
            "\tspeed: 0.0116s/iter; left time: 24.9446s\n",
            "\titers: 800, epoch: 6 | loss: 0.4869741\n",
            "\tspeed: 0.0117s/iter; left time: 23.8257s\n",
            "\titers: 900, epoch: 6 | loss: 0.7363669\n",
            "\tspeed: 0.0119s/iter; left time: 23.0139s\n",
            "Epoch: 6 cost time: 11.892877101898193\n",
            "Epoch: 6, Steps: 947 | Train Loss: 0.6707172 Vali Loss: 0.4633101 Test Loss: 0.8085482\n",
            "Validation loss decreased (0.463430 --> 0.463310).  Saving model ...\n",
            "Updating learning rate to 3.125e-05\n",
            "\titers: 100, epoch: 7 | loss: 1.0017089\n",
            "\tspeed: 0.0411s/iter; left time: 73.7261s\n",
            "\titers: 200, epoch: 7 | loss: 0.7482005\n",
            "\tspeed: 0.0117s/iter; left time: 19.7651s\n",
            "\titers: 300, epoch: 7 | loss: 0.4070398\n",
            "\tspeed: 0.0143s/iter; left time: 22.8724s\n",
            "\titers: 400, epoch: 7 | loss: 0.8077227\n",
            "\tspeed: 0.0155s/iter; left time: 23.1388s\n",
            "\titers: 500, epoch: 7 | loss: 0.7586445\n",
            "\tspeed: 0.0116s/iter; left time: 16.2307s\n",
            "\titers: 600, epoch: 7 | loss: 0.6280691\n",
            "\tspeed: 0.0119s/iter; left time: 15.4747s\n",
            "\titers: 700, epoch: 7 | loss: 0.3489614\n",
            "\tspeed: 0.0119s/iter; left time: 14.1640s\n",
            "\titers: 800, epoch: 7 | loss: 0.6400056\n",
            "\tspeed: 0.0120s/iter; left time: 13.1877s\n",
            "\titers: 900, epoch: 7 | loss: 0.5799990\n",
            "\tspeed: 0.0119s/iter; left time: 11.8258s\n",
            "Epoch: 7 cost time: 11.890618562698364\n",
            "Epoch: 7, Steps: 947 | Train Loss: 0.6677953 Vali Loss: 0.4625026 Test Loss: 0.8084704\n",
            "Validation loss decreased (0.463310 --> 0.462503).  Saving model ...\n",
            "Updating learning rate to 1.5625e-05\n",
            "\titers: 100, epoch: 8 | loss: 0.7917004\n",
            "\tspeed: 0.0432s/iter; left time: 36.6086s\n",
            "\titers: 200, epoch: 8 | loss: 1.4553366\n",
            "\tspeed: 0.0168s/iter; left time: 12.5326s\n",
            "\titers: 300, epoch: 8 | loss: 0.4833288\n",
            "\tspeed: 0.0118s/iter; left time: 7.6717s\n",
            "\titers: 400, epoch: 8 | loss: 0.6161389\n",
            "\tspeed: 0.0116s/iter; left time: 6.3678s\n",
            "\titers: 500, epoch: 8 | loss: 0.6393830\n",
            "\tspeed: 0.0117s/iter; left time: 5.2510s\n",
            "\titers: 600, epoch: 8 | loss: 0.4802241\n",
            "\tspeed: 0.0117s/iter; left time: 4.0781s\n",
            "\titers: 700, epoch: 8 | loss: 0.7915859\n",
            "\tspeed: 0.0116s/iter; left time: 2.8872s\n",
            "\titers: 800, epoch: 8 | loss: 0.4641670\n",
            "\tspeed: 0.0115s/iter; left time: 1.7013s\n",
            "\titers: 900, epoch: 8 | loss: 0.7023110\n",
            "\tspeed: 0.0113s/iter; left time: 0.5447s\n",
            "Epoch: 8 cost time: 11.773008108139038\n",
            "Epoch: 8, Steps: 947 | Train Loss: 0.6664486 Vali Loss: 0.4624039 Test Loss: 0.8089927\n",
            "Validation loss decreased (0.462503 --> 0.462404).  Saving model ...\n",
            "Updating learning rate to 7.8125e-06\n",
            ">>>>>>>testing : long_term_forecast_stage1_NSW_iTransformer_iTransformer_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4364\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "mse:0.8095274567604065, mae:0.48408377170562744, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage1_NSW_iTransformer_iTransformer_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage1_NSW_iTransformer_iTransformer_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.8095, MAE=0.4841\n",
            "âœ… å®Œæˆ | MAE: 0.4841 | ç”¨æ—¶: 2.1åˆ†é’Ÿ\n",
            "\n",
            "[5/8] ðŸš€ SA | DLinear\n",
            "--------------------------------------------------------------------------------\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage1_SA_DLinear   Model:              DLinear             \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          SA_30min.csv        Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              5                   Num Kernels:        6                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            512                 \n",
            "  n heads:            8                   e layers:           2                   \n",
            "  d layers:           1                   d FF:               2048                \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       8                   Batch Size:         64                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            1                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage1_SA_DLinear_DLinear_custom_ftM_sl192_ll96_pl24_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15140\n",
            "val 2171\n",
            "test 4364\n",
            "\titers: 100, epoch: 1 | loss: 0.6904636\n",
            "\tspeed: 0.0120s/iter; left time: 21.6341s\n",
            "\titers: 200, epoch: 1 | loss: 0.8554484\n",
            "\tspeed: 0.0058s/iter; left time: 9.7689s\n",
            "Epoch: 1 cost time: 2.101208448410034\n",
            "Epoch: 1, Steps: 237 | Train Loss: 0.6991244 Vali Loss: 0.5124349 Test Loss: 0.7084657\n",
            "Validation loss decreased (inf --> 0.512435).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.5916675\n",
            "\tspeed: 0.0218s/iter; left time: 34.0627s\n",
            "\titers: 200, epoch: 2 | loss: 0.5998609\n",
            "\tspeed: 0.0058s/iter; left time: 8.4067s\n",
            "Epoch: 2 cost time: 1.7492494583129883\n",
            "Epoch: 2, Steps: 237 | Train Loss: 0.6885819 Vali Loss: 0.5129504 Test Loss: 0.7102076\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.8206164\n",
            "\tspeed: 0.0144s/iter; left time: 19.0641s\n",
            "\titers: 200, epoch: 3 | loss: 0.6312072\n",
            "\tspeed: 0.0050s/iter; left time: 6.1032s\n",
            "Epoch: 3 cost time: 1.4217884540557861\n",
            "Epoch: 3, Steps: 237 | Train Loss: 0.6830656 Vali Loss: 0.5098382 Test Loss: 0.7070794\n",
            "Validation loss decreased (0.512435 --> 0.509838).  Saving model ...\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.6825373\n",
            "\tspeed: 0.0136s/iter; left time: 14.8227s\n",
            "\titers: 200, epoch: 4 | loss: 0.6184080\n",
            "\tspeed: 0.0051s/iter; left time: 5.0361s\n",
            "Epoch: 4 cost time: 1.3040330410003662\n",
            "Epoch: 4, Steps: 237 | Train Loss: 0.6787722 Vali Loss: 0.5093754 Test Loss: 0.7063318\n",
            "Validation loss decreased (0.509838 --> 0.509375).  Saving model ...\n",
            "Updating learning rate to 0.000125\n",
            "\titers: 100, epoch: 5 | loss: 0.7621230\n",
            "\tspeed: 0.0140s/iter; left time: 11.8526s\n",
            "\titers: 200, epoch: 5 | loss: 0.6501247\n",
            "\tspeed: 0.0051s/iter; left time: 3.8048s\n",
            "Epoch: 5 cost time: 1.3519458770751953\n",
            "Epoch: 5, Steps: 237 | Train Loss: 0.6769580 Vali Loss: 0.5086137 Test Loss: 0.7050611\n",
            "Validation loss decreased (0.509375 --> 0.508614).  Saving model ...\n",
            "Updating learning rate to 6.25e-05\n",
            "\titers: 100, epoch: 6 | loss: 0.4818832\n",
            "\tspeed: 0.0132s/iter; left time: 8.0863s\n",
            "\titers: 200, epoch: 6 | loss: 0.5682137\n",
            "\tspeed: 0.0054s/iter; left time: 2.7794s\n",
            "Epoch: 6 cost time: 1.309203863143921\n",
            "Epoch: 6, Steps: 237 | Train Loss: 0.6751160 Vali Loss: 0.5081823 Test Loss: 0.7049835\n",
            "Validation loss decreased (0.508614 --> 0.508182).  Saving model ...\n",
            "Updating learning rate to 3.125e-05\n",
            "\titers: 100, epoch: 7 | loss: 0.6269525\n",
            "\tspeed: 0.0130s/iter; left time: 4.8918s\n",
            "\titers: 200, epoch: 7 | loss: 0.6566398\n",
            "\tspeed: 0.0052s/iter; left time: 1.4169s\n",
            "Epoch: 7 cost time: 1.3365130424499512\n",
            "Epoch: 7, Steps: 237 | Train Loss: 0.6744423 Vali Loss: 0.5083545 Test Loss: 0.7049387\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 1.5625e-05\n",
            "\titers: 100, epoch: 8 | loss: 0.6376265\n",
            "\tspeed: 0.0211s/iter; left time: 2.9080s\n",
            "\titers: 200, epoch: 8 | loss: 0.6879696\n",
            "\tspeed: 0.0066s/iter; left time: 0.2502s\n",
            "Epoch: 8 cost time: 1.8064892292022705\n",
            "Epoch: 8, Steps: 237 | Train Loss: 0.6744395 Vali Loss: 0.5079657 Test Loss: 0.7048275\n",
            "Validation loss decreased (0.508182 --> 0.507966).  Saving model ...\n",
            "Updating learning rate to 7.8125e-06\n",
            ">>>>>>>testing : long_term_forecast_stage1_SA_DLinear_DLinear_custom_ftM_sl192_ll96_pl24_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4364\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "mse:0.7088339924812317, mae:0.46528273820877075, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage1_SA_DLinear_DLinear_custom_ftM_sl192_ll96_pl24_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage1_SA_DLinear_DLinear_custom_ftM_sl192_ll96_pl24_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.7088, MAE=0.4653\n",
            "âœ… å®Œæˆ | MAE: 0.4653 | ç”¨æ—¶: 0.4åˆ†é’Ÿ\n",
            "\n",
            "[6/8] ðŸš€ SA | PatchTST\n",
            "--------------------------------------------------------------------------------\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage1_SA_PatchTST  Model:              PatchTST            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          SA_30min.csv        Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              5                   Num Kernels:        6                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            4                   e layers:           2                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       8                   Batch Size:         32                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            1                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage1_SA_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15140\n",
            "val 2171\n",
            "test 4364\n",
            "\titers: 100, epoch: 1 | loss: 0.8938267\n",
            "\tspeed: 0.0216s/iter; left time: 79.9324s\n",
            "\titers: 200, epoch: 1 | loss: 0.7484723\n",
            "\tspeed: 0.0173s/iter; left time: 62.0647s\n",
            "\titers: 300, epoch: 1 | loss: 0.9847490\n",
            "\tspeed: 0.0145s/iter; left time: 50.6512s\n",
            "\titers: 400, epoch: 1 | loss: 1.0398964\n",
            "\tspeed: 0.0124s/iter; left time: 42.1922s\n",
            "Epoch: 1 cost time: 7.53800368309021\n",
            "Epoch: 1, Steps: 474 | Train Loss: 0.8327862 Vali Loss: 0.5191633 Test Loss: 0.7192679\n",
            "Validation loss decreased (inf --> 0.519163).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.6260517\n",
            "\tspeed: 0.0357s/iter; left time: 115.0380s\n",
            "\titers: 200, epoch: 2 | loss: 0.6577675\n",
            "\tspeed: 0.0124s/iter; left time: 38.7150s\n",
            "\titers: 300, epoch: 2 | loss: 0.8811281\n",
            "\tspeed: 0.0133s/iter; left time: 40.0823s\n",
            "\titers: 400, epoch: 2 | loss: 0.8279282\n",
            "\tspeed: 0.0124s/iter; left time: 36.0861s\n",
            "Epoch: 2 cost time: 6.277080535888672\n",
            "Epoch: 2, Steps: 474 | Train Loss: 0.7357711 Vali Loss: 0.5605809 Test Loss: 0.7711073\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.9451919\n",
            "\tspeed: 0.0431s/iter; left time: 118.2661s\n",
            "\titers: 200, epoch: 3 | loss: 0.5743068\n",
            "\tspeed: 0.0124s/iter; left time: 32.9166s\n",
            "\titers: 300, epoch: 3 | loss: 0.5472028\n",
            "\tspeed: 0.0123s/iter; left time: 31.4282s\n",
            "\titers: 400, epoch: 3 | loss: 0.6357971\n",
            "\tspeed: 0.0126s/iter; left time: 30.9285s\n",
            "Epoch: 3 cost time: 5.996971130371094\n",
            "Epoch: 3, Steps: 474 | Train Loss: 0.6984938 Vali Loss: 0.5035692 Test Loss: 0.7007008\n",
            "Validation loss decreased (0.519163 --> 0.503569).  Saving model ...\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.5373618\n",
            "\tspeed: 0.0359s/iter; left time: 81.5272s\n",
            "\titers: 200, epoch: 4 | loss: 0.8106908\n",
            "\tspeed: 0.0134s/iter; left time: 29.0392s\n",
            "\titers: 300, epoch: 4 | loss: 0.5769361\n",
            "\tspeed: 0.0175s/iter; left time: 36.3324s\n",
            "\titers: 400, epoch: 4 | loss: 0.4161735\n",
            "\tspeed: 0.0129s/iter; left time: 25.3292s\n",
            "Epoch: 4 cost time: 6.615951061248779\n",
            "Epoch: 4, Steps: 474 | Train Loss: 0.6942594 Vali Loss: 0.5013273 Test Loss: 0.6973082\n",
            "Validation loss decreased (0.503569 --> 0.501327).  Saving model ...\n",
            "Updating learning rate to 0.000125\n",
            "\titers: 100, epoch: 5 | loss: 0.9721665\n",
            "\tspeed: 0.0360s/iter; left time: 64.7133s\n",
            "\titers: 200, epoch: 5 | loss: 0.8132781\n",
            "\tspeed: 0.0122s/iter; left time: 20.7879s\n",
            "\titers: 300, epoch: 5 | loss: 0.4869266\n",
            "\tspeed: 0.0122s/iter; left time: 19.4513s\n",
            "\titers: 400, epoch: 5 | loss: 0.6385915\n",
            "\tspeed: 0.0123s/iter; left time: 18.3562s\n",
            "Epoch: 5 cost time: 5.918489694595337\n",
            "Epoch: 5, Steps: 474 | Train Loss: 0.6917379 Vali Loss: 0.4985974 Test Loss: 0.6950191\n",
            "Validation loss decreased (0.501327 --> 0.498597).  Saving model ...\n",
            "Updating learning rate to 6.25e-05\n",
            "\titers: 100, epoch: 6 | loss: 0.5195424\n",
            "\tspeed: 0.0431s/iter; left time: 56.9746s\n",
            "\titers: 200, epoch: 6 | loss: 0.6928685\n",
            "\tspeed: 0.0130s/iter; left time: 15.8896s\n",
            "\titers: 300, epoch: 6 | loss: 0.8221325\n",
            "\tspeed: 0.0124s/iter; left time: 13.8917s\n",
            "\titers: 400, epoch: 6 | loss: 0.7350601\n",
            "\tspeed: 0.0123s/iter; left time: 12.5331s\n",
            "Epoch: 6 cost time: 6.425487041473389\n",
            "Epoch: 6, Steps: 474 | Train Loss: 0.6877620 Vali Loss: 0.4997698 Test Loss: 0.6956680\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 3.125e-05\n",
            "\titers: 100, epoch: 7 | loss: 0.7625011\n",
            "\tspeed: 0.0363s/iter; left time: 30.7947s\n",
            "\titers: 200, epoch: 7 | loss: 0.3894763\n",
            "\tspeed: 0.0127s/iter; left time: 9.4901s\n",
            "\titers: 300, epoch: 7 | loss: 0.5293640\n",
            "\tspeed: 0.0139s/iter; left time: 9.0390s\n",
            "\titers: 400, epoch: 7 | loss: 0.6427903\n",
            "\tspeed: 0.0172s/iter; left time: 9.4450s\n",
            "Epoch: 7 cost time: 6.638532876968384\n",
            "Epoch: 7, Steps: 474 | Train Loss: 0.6870089 Vali Loss: 0.4993586 Test Loss: 0.6962607\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage1_SA_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4364\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "mse:0.6964569091796875, mae:0.4583885967731476, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage1_SA_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage1_SA_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.6965, MAE=0.4584\n",
            "âœ… å®Œæˆ | MAE: 0.4584 | ç”¨æ—¶: 1.1åˆ†é’Ÿ\n",
            "\n",
            "[7/8] ðŸš€ SA | TimesNet\n",
            "--------------------------------------------------------------------------------\n",
            "  âš ï¸  TimesNetå…³é—­AMP (é¿å…cuFFT FP16é”™è¯¯)ï¼Œä½¿ç”¨FP32è®­ç»ƒ\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage1_SA_TimesNet  Model:              TimesNet            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          SA_30min.csv        Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              3                   Num Kernels:        4                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            8                   e layers:           1                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       8                   Batch Size:         16                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            0                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage1_SA_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15140\n",
            "val 2171\n",
            "test 4364\n",
            "\titers: 100, epoch: 1 | loss: 1.0431864\n",
            "\tspeed: 0.0997s/iter; left time: 745.7203s\n",
            "\titers: 200, epoch: 1 | loss: 0.7745156\n",
            "\tspeed: 0.0948s/iter; left time: 699.2788s\n",
            "\titers: 300, epoch: 1 | loss: 0.4386519\n",
            "\tspeed: 0.1026s/iter; left time: 746.8485s\n",
            "\titers: 400, epoch: 1 | loss: 0.7087762\n",
            "\tspeed: 0.1019s/iter; left time: 731.5098s\n",
            "\titers: 500, epoch: 1 | loss: 0.5234836\n",
            "\tspeed: 0.1000s/iter; left time: 707.7172s\n",
            "\titers: 600, epoch: 1 | loss: 0.4918543\n",
            "\tspeed: 0.0972s/iter; left time: 678.3370s\n",
            "\titers: 700, epoch: 1 | loss: 0.8966285\n",
            "\tspeed: 0.0939s/iter; left time: 645.6813s\n",
            "\titers: 800, epoch: 1 | loss: 0.4119679\n",
            "\tspeed: 0.0939s/iter; left time: 636.0551s\n",
            "\titers: 900, epoch: 1 | loss: 0.6376809\n",
            "\tspeed: 0.0973s/iter; left time: 649.7879s\n",
            "Epoch: 1 cost time: 92.86197996139526\n",
            "Epoch: 1, Steps: 947 | Train Loss: 0.6836668 Vali Loss: 0.4975100 Test Loss: 0.6978220\n",
            "Validation loss decreased (inf --> 0.497510).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.4136992\n",
            "\tspeed: 0.3337s/iter; left time: 2179.3071s\n",
            "\titers: 200, epoch: 2 | loss: 0.4916623\n",
            "\tspeed: 0.0982s/iter; left time: 631.7124s\n",
            "\titers: 300, epoch: 2 | loss: 0.5760079\n",
            "\tspeed: 0.0951s/iter; left time: 601.8160s\n",
            "\titers: 400, epoch: 2 | loss: 0.3250237\n",
            "\tspeed: 0.0962s/iter; left time: 599.0648s\n",
            "\titers: 500, epoch: 2 | loss: 0.5090315\n",
            "\tspeed: 0.0936s/iter; left time: 574.0730s\n",
            "\titers: 600, epoch: 2 | loss: 1.0517524\n",
            "\tspeed: 0.0921s/iter; left time: 555.5328s\n",
            "\titers: 700, epoch: 2 | loss: 0.5828225\n",
            "\tspeed: 0.0955s/iter; left time: 566.0537s\n",
            "\titers: 800, epoch: 2 | loss: 0.8705141\n",
            "\tspeed: 0.0959s/iter; left time: 559.1045s\n",
            "\titers: 900, epoch: 2 | loss: 0.4255064\n",
            "\tspeed: 0.0950s/iter; left time: 544.1032s\n",
            "Epoch: 2 cost time: 90.49298477172852\n",
            "Epoch: 2, Steps: 947 | Train Loss: 0.6616474 Vali Loss: 0.4878538 Test Loss: 0.6858045\n",
            "Validation loss decreased (0.497510 --> 0.487854).  Saving model ...\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.5154748\n",
            "\tspeed: 0.3316s/iter; left time: 1851.2378s\n",
            "\titers: 200, epoch: 3 | loss: 0.6464947\n",
            "\tspeed: 0.0980s/iter; left time: 537.4035s\n",
            "\titers: 300, epoch: 3 | loss: 0.3808083\n",
            "\tspeed: 0.0975s/iter; left time: 524.8572s\n",
            "\titers: 400, epoch: 3 | loss: 0.4958663\n",
            "\tspeed: 0.0976s/iter; left time: 515.6069s\n",
            "\titers: 500, epoch: 3 | loss: 0.7045412\n",
            "\tspeed: 0.0960s/iter; left time: 497.5066s\n",
            "\titers: 600, epoch: 3 | loss: 0.5517120\n",
            "\tspeed: 0.0962s/iter; left time: 489.1994s\n",
            "\titers: 700, epoch: 3 | loss: 0.7336394\n",
            "\tspeed: 0.0954s/iter; left time: 475.3967s\n",
            "\titers: 800, epoch: 3 | loss: 0.4222617\n",
            "\tspeed: 0.0968s/iter; left time: 472.6994s\n",
            "\titers: 900, epoch: 3 | loss: 0.5554518\n",
            "\tspeed: 0.0984s/iter; left time: 470.8488s\n",
            "Epoch: 3 cost time: 92.11629033088684\n",
            "Epoch: 3, Steps: 947 | Train Loss: 0.6542250 Vali Loss: 0.4922757 Test Loss: 0.6852803\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.8564156\n",
            "\tspeed: 0.3359s/iter; left time: 1557.0610s\n",
            "\titers: 200, epoch: 4 | loss: 1.0306144\n",
            "\tspeed: 0.0975s/iter; left time: 442.4498s\n",
            "\titers: 300, epoch: 4 | loss: 0.8783736\n",
            "\tspeed: 0.0975s/iter; left time: 432.6813s\n",
            "\titers: 400, epoch: 4 | loss: 0.6452796\n",
            "\tspeed: 0.0971s/iter; left time: 421.1614s\n",
            "\titers: 500, epoch: 4 | loss: 0.6532432\n",
            "\tspeed: 0.0985s/iter; left time: 417.3089s\n",
            "\titers: 600, epoch: 4 | loss: 0.7221109\n",
            "\tspeed: 0.0981s/iter; left time: 405.5841s\n",
            "\titers: 700, epoch: 4 | loss: 0.7243238\n",
            "\tspeed: 0.0980s/iter; left time: 395.3452s\n",
            "\titers: 800, epoch: 4 | loss: 0.7156147\n",
            "\tspeed: 0.0985s/iter; left time: 387.5016s\n",
            "\titers: 900, epoch: 4 | loss: 0.5917341\n",
            "\tspeed: 0.0992s/iter; left time: 380.6485s\n",
            "Epoch: 4 cost time: 93.27962875366211\n",
            "Epoch: 4, Steps: 947 | Train Loss: 0.6487117 Vali Loss: 0.4934538 Test Loss: 0.6852765\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage1_SA_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4364\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "mse:0.6860359907150269, mae:0.44816163182258606, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage1_SA_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage1_SA_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.6860, MAE=0.4482\n",
            "âœ… å®Œæˆ | MAE: 0.4482 | ç”¨æ—¶: 7.7åˆ†é’Ÿ\n",
            "\n",
            "[8/8] ðŸš€ SA | iTransformer\n",
            "--------------------------------------------------------------------------------\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage1_SA_iTransformerModel:              iTransformer        \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          SA_30min.csv        Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              5                   Num Kernels:        6                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            4                   e layers:           2                   \n",
            "  d layers:           1                   d FF:               256                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       8                   Batch Size:         16                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            1                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage1_SA_iTransformer_iTransformer_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15140\n",
            "val 2171\n",
            "test 4364\n",
            "\titers: 100, epoch: 1 | loss: 0.5325925\n",
            "\tspeed: 0.0202s/iter; left time: 151.2820s\n",
            "\titers: 200, epoch: 1 | loss: 0.3959250\n",
            "\tspeed: 0.0116s/iter; left time: 85.7120s\n",
            "\titers: 300, epoch: 1 | loss: 0.6399741\n",
            "\tspeed: 0.0115s/iter; left time: 83.5763s\n",
            "\titers: 400, epoch: 1 | loss: 1.1630973\n",
            "\tspeed: 0.0116s/iter; left time: 82.9035s\n",
            "\titers: 500, epoch: 1 | loss: 0.5349374\n",
            "\tspeed: 0.0120s/iter; left time: 84.6834s\n",
            "\titers: 600, epoch: 1 | loss: 0.6029783\n",
            "\tspeed: 0.0116s/iter; left time: 80.6877s\n",
            "\titers: 700, epoch: 1 | loss: 0.5151466\n",
            "\tspeed: 0.0115s/iter; left time: 78.9714s\n",
            "\titers: 800, epoch: 1 | loss: 0.5564364\n",
            "\tspeed: 0.0142s/iter; left time: 96.1165s\n",
            "\titers: 900, epoch: 1 | loss: 0.7914100\n",
            "\tspeed: 0.0161s/iter; left time: 107.4308s\n",
            "Epoch: 1 cost time: 12.59956669807434\n",
            "Epoch: 1, Steps: 947 | Train Loss: 0.7148779 Vali Loss: 0.5143429 Test Loss: 0.7199287\n",
            "Validation loss decreased (inf --> 0.514343).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.4453285\n",
            "\tspeed: 0.0410s/iter; left time: 267.7265s\n",
            "\titers: 200, epoch: 2 | loss: 0.3688819\n",
            "\tspeed: 0.0117s/iter; left time: 75.3692s\n",
            "\titers: 300, epoch: 2 | loss: 0.5643181\n",
            "\tspeed: 0.0117s/iter; left time: 74.2169s\n",
            "\titers: 400, epoch: 2 | loss: 0.6566316\n",
            "\tspeed: 0.0117s/iter; left time: 72.6495s\n",
            "\titers: 500, epoch: 2 | loss: 0.6788657\n",
            "\tspeed: 0.0119s/iter; left time: 72.8822s\n",
            "\titers: 600, epoch: 2 | loss: 0.6375899\n",
            "\tspeed: 0.0130s/iter; left time: 78.1747s\n",
            "\titers: 700, epoch: 2 | loss: 1.4514395\n",
            "\tspeed: 0.0163s/iter; left time: 96.9448s\n",
            "\titers: 800, epoch: 2 | loss: 0.6646503\n",
            "\tspeed: 0.0127s/iter; left time: 73.9039s\n",
            "\titers: 900, epoch: 2 | loss: 0.3690826\n",
            "\tspeed: 0.0117s/iter; left time: 66.9409s\n",
            "Epoch: 2 cost time: 11.880644083023071\n",
            "Epoch: 2, Steps: 947 | Train Loss: 0.6876717 Vali Loss: 0.5130494 Test Loss: 0.7147923\n",
            "Validation loss decreased (0.514343 --> 0.513049).  Saving model ...\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.4909351\n",
            "\tspeed: 0.0418s/iter; left time: 233.5304s\n",
            "\titers: 200, epoch: 3 | loss: 0.7423369\n",
            "\tspeed: 0.0114s/iter; left time: 62.7758s\n",
            "\titers: 300, epoch: 3 | loss: 0.6065471\n",
            "\tspeed: 0.0120s/iter; left time: 64.4244s\n",
            "\titers: 400, epoch: 3 | loss: 0.7180156\n",
            "\tspeed: 0.0118s/iter; left time: 62.4712s\n",
            "\titers: 500, epoch: 3 | loss: 0.8364236\n",
            "\tspeed: 0.0155s/iter; left time: 80.5290s\n",
            "\titers: 600, epoch: 3 | loss: 0.3851238\n",
            "\tspeed: 0.0148s/iter; left time: 75.3101s\n",
            "\titers: 700, epoch: 3 | loss: 0.5582868\n",
            "\tspeed: 0.0117s/iter; left time: 58.4959s\n",
            "\titers: 800, epoch: 3 | loss: 1.0653023\n",
            "\tspeed: 0.0115s/iter; left time: 56.3330s\n",
            "\titers: 900, epoch: 3 | loss: 1.0288979\n",
            "\tspeed: 0.0115s/iter; left time: 54.8448s\n",
            "Epoch: 3 cost time: 11.901830911636353\n",
            "Epoch: 3, Steps: 947 | Train Loss: 0.6709336 Vali Loss: 0.5007699 Test Loss: 0.7003096\n",
            "Validation loss decreased (0.513049 --> 0.500770).  Saving model ...\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.6046292\n",
            "\tspeed: 0.0407s/iter; left time: 188.5445s\n",
            "\titers: 200, epoch: 4 | loss: 0.8391595\n",
            "\tspeed: 0.0116s/iter; left time: 52.4695s\n",
            "\titers: 300, epoch: 4 | loss: 0.5499299\n",
            "\tspeed: 0.0138s/iter; left time: 61.2392s\n",
            "\titers: 400, epoch: 4 | loss: 0.8020607\n",
            "\tspeed: 0.0167s/iter; left time: 72.5991s\n",
            "\titers: 500, epoch: 4 | loss: 1.1452135\n",
            "\tspeed: 0.0117s/iter; left time: 49.4497s\n",
            "\titers: 600, epoch: 4 | loss: 0.4531657\n",
            "\tspeed: 0.0116s/iter; left time: 48.1833s\n",
            "\titers: 700, epoch: 4 | loss: 0.5859880\n",
            "\tspeed: 0.0116s/iter; left time: 46.8969s\n",
            "\titers: 800, epoch: 4 | loss: 0.6404341\n",
            "\tspeed: 0.0116s/iter; left time: 45.7672s\n",
            "\titers: 900, epoch: 4 | loss: 0.5723891\n",
            "\tspeed: 0.0117s/iter; left time: 45.0053s\n",
            "Epoch: 4 cost time: 11.860373497009277\n",
            "Epoch: 4, Steps: 947 | Train Loss: 0.6605532 Vali Loss: 0.5004003 Test Loss: 0.6994946\n",
            "Validation loss decreased (0.500770 --> 0.500400).  Saving model ...\n",
            "Updating learning rate to 0.000125\n",
            "\titers: 100, epoch: 5 | loss: 0.9490741\n",
            "\tspeed: 0.0420s/iter; left time: 154.9301s\n",
            "\titers: 200, epoch: 5 | loss: 0.6306710\n",
            "\tspeed: 0.0168s/iter; left time: 60.4442s\n",
            "\titers: 300, epoch: 5 | loss: 0.5058363\n",
            "\tspeed: 0.0135s/iter; left time: 47.0586s\n",
            "\titers: 400, epoch: 5 | loss: 0.3989546\n",
            "\tspeed: 0.0117s/iter; left time: 39.4901s\n",
            "\titers: 500, epoch: 5 | loss: 0.7144383\n",
            "\tspeed: 0.0117s/iter; left time: 38.5337s\n",
            "\titers: 600, epoch: 5 | loss: 1.0138932\n",
            "\tspeed: 0.0115s/iter; left time: 36.5898s\n",
            "\titers: 700, epoch: 5 | loss: 0.4660200\n",
            "\tspeed: 0.0116s/iter; left time: 35.8100s\n",
            "\titers: 800, epoch: 5 | loss: 0.3002778\n",
            "\tspeed: 0.0118s/iter; left time: 35.2385s\n",
            "\titers: 900, epoch: 5 | loss: 0.4920391\n",
            "\tspeed: 0.0118s/iter; left time: 33.9573s\n",
            "Epoch: 5 cost time: 11.93397569656372\n",
            "Epoch: 5, Steps: 947 | Train Loss: 0.6539555 Vali Loss: 0.4982488 Test Loss: 0.6979574\n",
            "Validation loss decreased (0.500400 --> 0.498249).  Saving model ...\n",
            "Updating learning rate to 6.25e-05\n",
            "\titers: 100, epoch: 6 | loss: 0.7838830\n",
            "\tspeed: 0.0477s/iter; left time: 130.8672s\n",
            "\titers: 200, epoch: 6 | loss: 0.5666353\n",
            "\tspeed: 0.0116s/iter; left time: 30.7052s\n",
            "\titers: 300, epoch: 6 | loss: 0.4772153\n",
            "\tspeed: 0.0116s/iter; left time: 29.4930s\n",
            "\titers: 400, epoch: 6 | loss: 0.5687144\n",
            "\tspeed: 0.0118s/iter; left time: 28.8744s\n",
            "\titers: 500, epoch: 6 | loss: 0.4382182\n",
            "\tspeed: 0.0118s/iter; left time: 27.7146s\n",
            "\titers: 600, epoch: 6 | loss: 0.8335443\n",
            "\tspeed: 0.0118s/iter; left time: 26.4910s\n",
            "\titers: 700, epoch: 6 | loss: 0.7843320\n",
            "\tspeed: 0.0118s/iter; left time: 25.3382s\n",
            "\titers: 800, epoch: 6 | loss: 0.5188252\n",
            "\tspeed: 0.0117s/iter; left time: 23.7896s\n",
            "\titers: 900, epoch: 6 | loss: 0.5127541\n",
            "\tspeed: 0.0116s/iter; left time: 22.4429s\n",
            "Epoch: 6 cost time: 11.715821743011475\n",
            "Epoch: 6, Steps: 947 | Train Loss: 0.6484389 Vali Loss: 0.4982488 Test Loss: 0.6980470\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 3.125e-05\n",
            "\titers: 100, epoch: 7 | loss: 0.9970818\n",
            "\tspeed: 0.0473s/iter; left time: 84.9306s\n",
            "\titers: 200, epoch: 7 | loss: 0.3368131\n",
            "\tspeed: 0.0117s/iter; left time: 19.8609s\n",
            "\titers: 300, epoch: 7 | loss: 0.5263519\n",
            "\tspeed: 0.0116s/iter; left time: 18.5138s\n",
            "\titers: 400, epoch: 7 | loss: 0.4545366\n",
            "\tspeed: 0.0122s/iter; left time: 18.2401s\n",
            "\titers: 500, epoch: 7 | loss: 0.5261806\n",
            "\tspeed: 0.0117s/iter; left time: 16.2679s\n",
            "\titers: 600, epoch: 7 | loss: 0.6155951\n",
            "\tspeed: 0.0117s/iter; left time: 15.1787s\n",
            "\titers: 700, epoch: 7 | loss: 0.5669690\n",
            "\tspeed: 0.0116s/iter; left time: 13.8431s\n",
            "\titers: 800, epoch: 7 | loss: 0.5898110\n",
            "\tspeed: 0.0134s/iter; left time: 14.7004s\n",
            "\titers: 900, epoch: 7 | loss: 0.3413246\n",
            "\tspeed: 0.0167s/iter; left time: 16.6078s\n",
            "Epoch: 7 cost time: 11.859221696853638\n",
            "Epoch: 7, Steps: 947 | Train Loss: 0.6461328 Vali Loss: 0.4997716 Test Loss: 0.6984752\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage1_SA_iTransformer_iTransformer_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4364\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "mse:0.6981717944145203, mae:0.4622576832771301, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage1_SA_iTransformer_iTransformer_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage1_SA_iTransformer_iTransformer_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df256_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.6982, MAE=0.4623\n",
            "âœ… å®Œæˆ | MAE: 0.4623 | ç”¨æ—¶: 1.8åˆ†é’Ÿ\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ðŸ” é˜¶æ®µ1è¯Šæ–­ä¿¡æ¯\n",
            "================================================================================\n",
            "æ€»å®žéªŒæ•°: 8\n",
            "æˆåŠŸå®Œæˆ: 8\n",
            "æœ‰æŒ‡æ ‡çš„: 8\n",
            "\n",
            "================================================================================\n",
            "ðŸ“Š é˜¶æ®µ1ç»“æžœæ±‡æ€»\n",
            "================================================================================\n",
            "state        model      mae      mse  time_minutes\n",
            "   SA     TimesNet 0.448162 0.686036      7.742640\n",
            "   SA     PatchTST 0.458389 0.696457      1.055287\n",
            "   SA iTransformer 0.462258 0.698172      1.838317\n",
            "   SA      DLinear 0.465283 0.708834      0.403722\n",
            "  NSW     PatchTST 0.472636 0.801659      1.251485\n",
            "  NSW     TimesNet 0.475379 0.792249      7.578305\n",
            "  NSW iTransformer 0.484084 0.809527      2.073588\n",
            "  NSW      DLinear 0.488809 0.816301      0.394472\n",
            "\n",
            "âœ¨ é€‰ä¸­çš„å‰2ä¸ªæ¨¡åž‹:\n",
            "  1. TimesNet        - å¹³å‡MAE: 0.4618\n",
            "  2. PatchTST        - å¹³å‡MAE: 0.4655\n",
            "\n",
            "================================================================================\n",
            "ðŸŽ¯ é˜¶æ®µ2: æ‰©å±•éªŒè¯ï¼ˆæ‰€æœ‰å·ž+ä¸¤ä¸ªé¢‘çŽ‡ï¼‰\n",
            "================================================================================\n",
            "é…ç½®:\n",
            "  - æ¨¡åž‹: TimesNet, PatchTST\n",
            "  - å·ž: å…¨éƒ¨5ä¸ª (NSW, QLD, VIC, SA, TAS)\n",
            "  - é¢‘çŽ‡: 30min, 15min\n",
            "  - é¢„æµ‹æ­¥é•¿: 24\n",
            "  - è®­ç»ƒè½®æ•°: 10 epochs, æ—©åœpatience=2\n",
            "================================================================================\n",
            "\n",
            "[1/20] ðŸš€ NSW | 30min | TimesNet\n",
            "--------------------------------------------------------------------------------\n",
            "  âš ï¸  TimesNetå…³é—­AMP (é¿å…cuFFT FP16é”™è¯¯)ï¼Œä½¿ç”¨FP32è®­ç»ƒ\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_NSW_30min_TimesNetModel:              TimesNet            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          NSW_30min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              3                   Num Kernels:        4                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            8                   e layers:           1                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         16                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            0                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_NSW_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15140\n",
            "val 2171\n",
            "test 4364\n",
            "\titers: 100, epoch: 1 | loss: 1.2049650\n",
            "\tspeed: 0.0879s/iter; left time: 824.0719s\n",
            "\titers: 200, epoch: 1 | loss: 1.0872614\n",
            "\tspeed: 0.0826s/iter; left time: 766.1813s\n",
            "\titers: 300, epoch: 1 | loss: 0.5841712\n",
            "\tspeed: 0.0875s/iter; left time: 802.2656s\n",
            "\titers: 400, epoch: 1 | loss: 0.6028912\n",
            "\tspeed: 0.0890s/iter; left time: 807.2785s\n",
            "\titers: 500, epoch: 1 | loss: 0.7055544\n",
            "\tspeed: 0.0904s/iter; left time: 810.5443s\n",
            "\titers: 600, epoch: 1 | loss: 0.5016915\n",
            "\tspeed: 0.0913s/iter; left time: 809.5645s\n",
            "\titers: 700, epoch: 1 | loss: 0.6204432\n",
            "\tspeed: 0.0909s/iter; left time: 797.5645s\n",
            "\titers: 800, epoch: 1 | loss: 0.6798943\n",
            "\tspeed: 0.1013s/iter; left time: 878.3422s\n",
            "\titers: 900, epoch: 1 | loss: 0.5601316\n",
            "\tspeed: 0.1014s/iter; left time: 868.7690s\n",
            "Epoch: 1 cost time: 87.18391680717468\n",
            "Epoch: 1, Steps: 947 | Train Loss: 0.6991678 Vali Loss: 0.4614227 Test Loss: 0.8001683\n",
            "Validation loss decreased (inf --> 0.461423).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.6436665\n",
            "\tspeed: 0.3622s/iter; left time: 3051.5446s\n",
            "\titers: 200, epoch: 2 | loss: 0.6987650\n",
            "\tspeed: 0.1020s/iter; left time: 848.9818s\n",
            "\titers: 300, epoch: 2 | loss: 0.7901581\n",
            "\tspeed: 0.1015s/iter; left time: 834.4097s\n",
            "\titers: 400, epoch: 2 | loss: 0.6495169\n",
            "\tspeed: 0.1013s/iter; left time: 823.3016s\n",
            "\titers: 500, epoch: 2 | loss: 0.7476225\n",
            "\tspeed: 0.1013s/iter; left time: 813.1659s\n",
            "\titers: 600, epoch: 2 | loss: 0.5140497\n",
            "\tspeed: 0.1012s/iter; left time: 802.1987s\n",
            "\titers: 700, epoch: 2 | loss: 1.2347982\n",
            "\tspeed: 0.1012s/iter; left time: 792.0141s\n",
            "\titers: 800, epoch: 2 | loss: 0.4556449\n",
            "\tspeed: 0.0980s/iter; left time: 756.7668s\n",
            "\titers: 900, epoch: 2 | loss: 0.7682184\n",
            "\tspeed: 0.0984s/iter; left time: 750.0169s\n",
            "Epoch: 2 cost time: 95.36021995544434\n",
            "Epoch: 2, Steps: 947 | Train Loss: 0.6799119 Vali Loss: 0.4548426 Test Loss: 0.7917398\n",
            "Validation loss decreased (0.461423 --> 0.454843).  Saving model ...\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.3623149\n",
            "\tspeed: 0.3144s/iter; left time: 2351.0571s\n",
            "\titers: 200, epoch: 3 | loss: 0.8821036\n",
            "\tspeed: 0.0963s/iter; left time: 710.1584s\n",
            "\titers: 300, epoch: 3 | loss: 0.6855565\n",
            "\tspeed: 0.0958s/iter; left time: 697.4034s\n",
            "\titers: 400, epoch: 3 | loss: 0.5663615\n",
            "\tspeed: 0.0952s/iter; left time: 683.0418s\n",
            "\titers: 500, epoch: 3 | loss: 0.3999395\n",
            "\tspeed: 0.0869s/iter; left time: 614.7568s\n",
            "\titers: 600, epoch: 3 | loss: 0.7674094\n",
            "\tspeed: 0.0873s/iter; left time: 609.2455s\n",
            "\titers: 700, epoch: 3 | loss: 1.0094010\n",
            "\tspeed: 0.0872s/iter; left time: 599.4023s\n",
            "\titers: 800, epoch: 3 | loss: 0.8258833\n",
            "\tspeed: 0.0978s/iter; left time: 662.7647s\n",
            "\titers: 900, epoch: 3 | loss: 0.3768349\n",
            "\tspeed: 0.0970s/iter; left time: 647.7969s\n",
            "Epoch: 3 cost time: 88.89800333976746\n",
            "Epoch: 3, Steps: 947 | Train Loss: 0.6723099 Vali Loss: 0.4570449 Test Loss: 0.7901405\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.6311424\n",
            "\tspeed: 0.3212s/iter; left time: 2097.3614s\n",
            "\titers: 200, epoch: 4 | loss: 0.8398778\n",
            "\tspeed: 0.0956s/iter; left time: 614.5669s\n",
            "\titers: 300, epoch: 4 | loss: 0.7337592\n",
            "\tspeed: 0.0947s/iter; left time: 599.7200s\n",
            "\titers: 400, epoch: 4 | loss: 0.4869446\n",
            "\tspeed: 0.0959s/iter; left time: 597.5706s\n",
            "\titers: 500, epoch: 4 | loss: 0.8546107\n",
            "\tspeed: 0.0960s/iter; left time: 588.2819s\n",
            "\titers: 600, epoch: 4 | loss: 0.5377794\n",
            "\tspeed: 0.0970s/iter; left time: 584.8402s\n",
            "\titers: 700, epoch: 4 | loss: 0.4278225\n",
            "\tspeed: 0.0944s/iter; left time: 559.6604s\n",
            "\titers: 800, epoch: 4 | loss: 0.3876322\n",
            "\tspeed: 0.0963s/iter; left time: 561.3679s\n",
            "\titers: 900, epoch: 4 | loss: 0.3531409\n",
            "\tspeed: 0.0980s/iter; left time: 561.7096s\n",
            "Epoch: 4 cost time: 91.45781993865967\n",
            "Epoch: 4, Steps: 947 | Train Loss: 0.6679528 Vali Loss: 0.4629969 Test Loss: 0.7930505\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_NSW_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4364\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "mse:0.7922492623329163, mae:0.4753793179988861, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_NSW_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_NSW_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.7922, MAE=0.4754\n",
            "âœ… å®Œæˆ | MAE: 0.4754 | ç”¨æ—¶: 7.6åˆ†é’Ÿ\n",
            "\n",
            "[2/20] ðŸš€ NSW | 30min | PatchTST\n",
            "--------------------------------------------------------------------------------\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_NSW_30min_PatchTSTModel:              PatchTST            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          NSW_30min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              5                   Num Kernels:        6                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            4                   e layers:           2                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         32                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            1                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_NSW_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15140\n",
            "val 2171\n",
            "test 4364\n",
            "\titers: 100, epoch: 1 | loss: 0.5871094\n",
            "\tspeed: 0.0210s/iter; left time: 97.3146s\n",
            "\titers: 200, epoch: 1 | loss: 0.6734711\n",
            "\tspeed: 0.0119s/iter; left time: 53.8664s\n",
            "\titers: 300, epoch: 1 | loss: 1.3234851\n",
            "\tspeed: 0.0133s/iter; left time: 59.1492s\n",
            "\titers: 400, epoch: 1 | loss: 0.8406035\n",
            "\tspeed: 0.0168s/iter; left time: 72.8270s\n",
            "Epoch: 1 cost time: 7.3221306800842285\n",
            "Epoch: 1, Steps: 474 | Train Loss: 0.8463010 Vali Loss: 0.5565882 Test Loss: 0.8492749\n",
            "Validation loss decreased (inf --> 0.556588).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.8339768\n",
            "\tspeed: 0.0361s/iter; left time: 150.5599s\n",
            "\titers: 200, epoch: 2 | loss: 0.8004039\n",
            "\tspeed: 0.0131s/iter; left time: 53.4671s\n",
            "\titers: 300, epoch: 2 | loss: 0.6369314\n",
            "\tspeed: 0.0119s/iter; left time: 47.1463s\n",
            "\titers: 400, epoch: 2 | loss: 0.5105742\n",
            "\tspeed: 0.0119s/iter; left time: 45.9711s\n",
            "Epoch: 2 cost time: 5.895181655883789\n",
            "Epoch: 2, Steps: 474 | Train Loss: 0.7593065 Vali Loss: 0.5022579 Test Loss: 0.8486041\n",
            "Validation loss decreased (0.556588 --> 0.502258).  Saving model ...\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.9392463\n",
            "\tspeed: 0.0372s/iter; left time: 137.2023s\n",
            "\titers: 200, epoch: 3 | loss: 1.1061459\n",
            "\tspeed: 0.0163s/iter; left time: 58.7450s\n",
            "\titers: 300, epoch: 3 | loss: 0.6822463\n",
            "\tspeed: 0.0121s/iter; left time: 42.1110s\n",
            "\titers: 400, epoch: 3 | loss: 0.9406034\n",
            "\tspeed: 0.0120s/iter; left time: 40.7908s\n",
            "Epoch: 3 cost time: 6.482804775238037\n",
            "Epoch: 3, Steps: 474 | Train Loss: 0.7195713 Vali Loss: 0.4698417 Test Loss: 0.8005403\n",
            "Validation loss decreased (0.502258 --> 0.469842).  Saving model ...\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.5284713\n",
            "\tspeed: 0.0353s/iter; left time: 113.6022s\n",
            "\titers: 200, epoch: 4 | loss: 0.7219290\n",
            "\tspeed: 0.0119s/iter; left time: 37.1356s\n",
            "\titers: 300, epoch: 4 | loss: 0.7009895\n",
            "\tspeed: 0.0119s/iter; left time: 35.9133s\n",
            "\titers: 400, epoch: 4 | loss: 0.5659485\n",
            "\tspeed: 0.0119s/iter; left time: 34.8606s\n",
            "Epoch: 4 cost time: 6.049616575241089\n",
            "Epoch: 4, Steps: 474 | Train Loss: 0.7131681 Vali Loss: 0.4685408 Test Loss: 0.7989963\n",
            "Validation loss decreased (0.469842 --> 0.468541).  Saving model ...\n",
            "Updating learning rate to 0.000125\n",
            "\titers: 100, epoch: 5 | loss: 0.7788509\n",
            "\tspeed: 0.0425s/iter; left time: 116.7540s\n",
            "\titers: 200, epoch: 5 | loss: 0.9871598\n",
            "\tspeed: 0.0121s/iter; left time: 31.9433s\n",
            "\titers: 300, epoch: 5 | loss: 0.8183316\n",
            "\tspeed: 0.0116s/iter; left time: 29.5440s\n",
            "\titers: 400, epoch: 5 | loss: 0.5766878\n",
            "\tspeed: 0.0118s/iter; left time: 28.7797s\n",
            "Epoch: 5 cost time: 5.739078998565674\n",
            "Epoch: 5, Steps: 474 | Train Loss: 0.7090309 Vali Loss: 0.4666933 Test Loss: 0.7992383\n",
            "Validation loss decreased (0.468541 --> 0.466693).  Saving model ...\n",
            "Updating learning rate to 6.25e-05\n",
            "\titers: 100, epoch: 6 | loss: 0.4989475\n",
            "\tspeed: 0.0343s/iter; left time: 77.8227s\n",
            "\titers: 200, epoch: 6 | loss: 0.7446793\n",
            "\tspeed: 0.0118s/iter; left time: 25.7132s\n",
            "\titers: 300, epoch: 6 | loss: 0.6154320\n",
            "\tspeed: 0.0167s/iter; left time: 34.5893s\n",
            "\titers: 400, epoch: 6 | loss: 0.6324663\n",
            "\tspeed: 0.0149s/iter; left time: 29.3498s\n",
            "Epoch: 6 cost time: 6.4953227043151855\n",
            "Epoch: 6, Steps: 474 | Train Loss: 0.7086236 Vali Loss: 0.4649153 Test Loss: 0.7989375\n",
            "Validation loss decreased (0.466693 --> 0.464915).  Saving model ...\n",
            "Updating learning rate to 3.125e-05\n",
            "\titers: 100, epoch: 7 | loss: 0.7410985\n",
            "\tspeed: 0.0346s/iter; left time: 62.1713s\n",
            "\titers: 200, epoch: 7 | loss: 0.6388761\n",
            "\tspeed: 0.0122s/iter; left time: 20.6688s\n",
            "\titers: 300, epoch: 7 | loss: 0.6672288\n",
            "\tspeed: 0.0123s/iter; left time: 19.6913s\n",
            "\titers: 400, epoch: 7 | loss: 0.8353620\n",
            "\tspeed: 0.0125s/iter; left time: 18.6513s\n",
            "Epoch: 7 cost time: 5.928077220916748\n",
            "Epoch: 7, Steps: 474 | Train Loss: 0.7072555 Vali Loss: 0.4667050 Test Loss: 0.7992153\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 1.5625e-05\n",
            "\titers: 100, epoch: 8 | loss: 0.5547704\n",
            "\tspeed: 0.0425s/iter; left time: 56.2897s\n",
            "\titers: 200, epoch: 8 | loss: 0.7705086\n",
            "\tspeed: 0.0131s/iter; left time: 15.9759s\n",
            "\titers: 300, epoch: 8 | loss: 0.8417432\n",
            "\tspeed: 0.0125s/iter; left time: 14.0066s\n",
            "\titers: 400, epoch: 8 | loss: 0.6679263\n",
            "\tspeed: 0.0122s/iter; left time: 12.4377s\n",
            "Epoch: 8 cost time: 6.627547264099121\n",
            "Epoch: 8, Steps: 474 | Train Loss: 0.7053721 Vali Loss: 0.4660468 Test Loss: 0.7991739\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_NSW_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4364\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "mse:0.8016588687896729, mae:0.4726355969905853, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_NSW_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_NSW_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.8017, MAE=0.4726\n",
            "âœ… å®Œæˆ | MAE: 0.4726 | ç”¨æ—¶: 1.2åˆ†é’Ÿ\n",
            "\n",
            "[3/20] ðŸš€ NSW | 15min | TimesNet\n",
            "--------------------------------------------------------------------------------\n",
            "  âš ï¸  TimesNetå…³é—­AMP (é¿å…cuFFT FP16é”™è¯¯)ï¼Œä½¿ç”¨FP32è®­ç»ƒ\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_NSW_15min_TimesNetModel:              TimesNet            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          NSW_15min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            384                 Label Len:          192                 \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              3                   Num Kernels:        4                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            8                   e layers:           1                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         16                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            0                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_NSW_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 11890\n",
            "val 1735\n",
            "test 3490\n",
            "\titers: 100, epoch: 1 | loss: 0.5055867\n",
            "\tspeed: 0.1361s/iter; left time: 998.8351s\n",
            "\titers: 200, epoch: 1 | loss: 0.3244815\n",
            "\tspeed: 0.1471s/iter; left time: 1065.3427s\n",
            "\titers: 300, epoch: 1 | loss: 0.6382010\n",
            "\tspeed: 0.1592s/iter; left time: 1136.6098s\n",
            "\titers: 400, epoch: 1 | loss: 0.5225552\n",
            "\tspeed: 0.1591s/iter; left time: 1120.0643s\n",
            "\titers: 500, epoch: 1 | loss: 0.5012869\n",
            "\tspeed: 0.1611s/iter; left time: 1118.4622s\n",
            "\titers: 600, epoch: 1 | loss: 0.5057857\n",
            "\tspeed: 0.1620s/iter; left time: 1108.5666s\n",
            "\titers: 700, epoch: 1 | loss: 0.5411602\n",
            "\tspeed: 0.1629s/iter; left time: 1098.4429s\n",
            "Epoch: 1 cost time: 117.24647188186646\n",
            "Epoch: 1, Steps: 744 | Train Loss: 0.5259815 Vali Loss: 0.5768513 Test Loss: 0.4543441\n",
            "Validation loss decreased (inf --> 0.576851).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.5880666\n",
            "\tspeed: 0.4882s/iter; left time: 3220.9009s\n",
            "\titers: 200, epoch: 2 | loss: 0.6065392\n",
            "\tspeed: 0.1633s/iter; left time: 1061.2030s\n",
            "\titers: 300, epoch: 2 | loss: 0.5621692\n",
            "\tspeed: 0.1624s/iter; left time: 1039.1554s\n",
            "\titers: 400, epoch: 2 | loss: 0.6491116\n",
            "\tspeed: 0.1618s/iter; left time: 1018.7057s\n",
            "\titers: 500, epoch: 2 | loss: 0.4588631\n",
            "\tspeed: 0.1628s/iter; left time: 1008.9188s\n",
            "\titers: 600, epoch: 2 | loss: 0.4314232\n",
            "\tspeed: 0.1641s/iter; left time: 1000.2134s\n",
            "\titers: 700, epoch: 2 | loss: 0.8007158\n",
            "\tspeed: 0.1686s/iter; left time: 1010.8978s\n",
            "Epoch: 2 cost time: 123.29520201683044\n",
            "Epoch: 2, Steps: 744 | Train Loss: 0.5079655 Vali Loss: 0.5713752 Test Loss: 0.4532640\n",
            "Validation loss decreased (0.576851 --> 0.571375).  Saving model ...\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.5189079\n",
            "\tspeed: 0.5282s/iter; left time: 3091.4607s\n",
            "\titers: 200, epoch: 3 | loss: 0.4399290\n",
            "\tspeed: 0.1709s/iter; left time: 982.9543s\n",
            "\titers: 300, epoch: 3 | loss: 0.3483372\n",
            "\tspeed: 0.1702s/iter; left time: 961.9567s\n",
            "\titers: 400, epoch: 3 | loss: 0.4734854\n",
            "\tspeed: 0.1627s/iter; left time: 903.6202s\n",
            "\titers: 500, epoch: 3 | loss: 0.4831954\n",
            "\tspeed: 0.1603s/iter; left time: 873.8758s\n",
            "\titers: 600, epoch: 3 | loss: 0.4095494\n",
            "\tspeed: 0.1601s/iter; left time: 857.2147s\n",
            "\titers: 700, epoch: 3 | loss: 0.3023750\n",
            "\tspeed: 0.1588s/iter; left time: 834.1583s\n",
            "Epoch: 3 cost time: 123.16995859146118\n",
            "Epoch: 3, Steps: 744 | Train Loss: 0.5012917 Vali Loss: 0.5681520 Test Loss: 0.4506404\n",
            "Validation loss decreased (0.571375 --> 0.568152).  Saving model ...\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.5710438\n",
            "\tspeed: 0.4913s/iter; left time: 2510.2608s\n",
            "\titers: 200, epoch: 4 | loss: 0.4628386\n",
            "\tspeed: 0.1635s/iter; left time: 818.7843s\n",
            "\titers: 300, epoch: 4 | loss: 0.5896336\n",
            "\tspeed: 0.1693s/iter; left time: 831.3183s\n",
            "\titers: 400, epoch: 4 | loss: 0.3905061\n",
            "\tspeed: 0.1685s/iter; left time: 810.2960s\n",
            "\titers: 500, epoch: 4 | loss: 0.7497078\n",
            "\tspeed: 0.1644s/iter; left time: 774.3537s\n",
            "\titers: 600, epoch: 4 | loss: 0.4919170\n",
            "\tspeed: 0.1637s/iter; left time: 754.3414s\n",
            "\titers: 700, epoch: 4 | loss: 0.5224243\n",
            "\tspeed: 0.1678s/iter; left time: 756.6026s\n",
            "Epoch: 4 cost time: 124.85442805290222\n",
            "Epoch: 4, Steps: 744 | Train Loss: 0.4982539 Vali Loss: 0.5661807 Test Loss: 0.4513689\n",
            "Validation loss decreased (0.568152 --> 0.566181).  Saving model ...\n",
            "Updating learning rate to 0.000125\n",
            "\titers: 100, epoch: 5 | loss: 0.5738658\n",
            "\tspeed: 0.5049s/iter; left time: 2203.9849s\n",
            "\titers: 200, epoch: 5 | loss: 0.6220711\n",
            "\tspeed: 0.1691s/iter; left time: 721.0910s\n",
            "\titers: 300, epoch: 5 | loss: 0.6495577\n",
            "\tspeed: 0.1646s/iter; left time: 685.7032s\n",
            "\titers: 400, epoch: 5 | loss: 0.3451814\n",
            "\tspeed: 0.1649s/iter; left time: 670.4512s\n",
            "\titers: 500, epoch: 5 | loss: 0.4856961\n",
            "\tspeed: 0.1634s/iter; left time: 647.9587s\n",
            "\titers: 600, epoch: 5 | loss: 0.4590913\n",
            "\tspeed: 0.1643s/iter; left time: 635.1533s\n",
            "\titers: 700, epoch: 5 | loss: 0.4183383\n",
            "\tspeed: 0.1654s/iter; left time: 622.8836s\n",
            "Epoch: 5 cost time: 124.03162741661072\n",
            "Epoch: 5, Steps: 744 | Train Loss: 0.4952868 Vali Loss: 0.5649227 Test Loss: 0.4510854\n",
            "Validation loss decreased (0.566181 --> 0.564923).  Saving model ...\n",
            "Updating learning rate to 6.25e-05\n",
            "\titers: 100, epoch: 6 | loss: 0.3608981\n",
            "\tspeed: 0.4888s/iter; left time: 1769.8947s\n",
            "\titers: 200, epoch: 6 | loss: 0.6102763\n",
            "\tspeed: 0.1652s/iter; left time: 581.7935s\n",
            "\titers: 300, epoch: 6 | loss: 0.3912843\n",
            "\tspeed: 0.1689s/iter; left time: 577.6558s\n",
            "\titers: 400, epoch: 6 | loss: 0.5100098\n",
            "\tspeed: 0.1677s/iter; left time: 556.8354s\n",
            "\titers: 500, epoch: 6 | loss: 0.4409488\n",
            "\tspeed: 0.1669s/iter; left time: 537.5239s\n",
            "\titers: 600, epoch: 6 | loss: 0.5016761\n",
            "\tspeed: 0.1650s/iter; left time: 514.9862s\n",
            "\titers: 700, epoch: 6 | loss: 0.4632666\n",
            "\tspeed: 0.1668s/iter; left time: 503.9701s\n",
            "Epoch: 6 cost time: 124.56371212005615\n",
            "Epoch: 6, Steps: 744 | Train Loss: 0.4942934 Vali Loss: 0.5634980 Test Loss: 0.4515560\n",
            "Validation loss decreased (0.564923 --> 0.563498).  Saving model ...\n",
            "Updating learning rate to 3.125e-05\n",
            "\titers: 100, epoch: 7 | loss: 0.4027457\n",
            "\tspeed: 0.4922s/iter; left time: 1416.1082s\n",
            "\titers: 200, epoch: 7 | loss: 0.4118512\n",
            "\tspeed: 0.1671s/iter; left time: 463.9812s\n",
            "\titers: 300, epoch: 7 | loss: 0.3486215\n",
            "\tspeed: 0.1686s/iter; left time: 451.4414s\n",
            "\titers: 400, epoch: 7 | loss: 0.4372340\n",
            "\tspeed: 0.1656s/iter; left time: 426.6982s\n",
            "\titers: 500, epoch: 7 | loss: 0.3479234\n",
            "\tspeed: 0.1650s/iter; left time: 408.6021s\n",
            "\titers: 600, epoch: 7 | loss: 0.4329846\n",
            "\tspeed: 0.1649s/iter; left time: 392.0148s\n",
            "\titers: 700, epoch: 7 | loss: 0.5853140\n",
            "\tspeed: 0.1653s/iter; left time: 376.3194s\n",
            "Epoch: 7 cost time: 124.23100876808167\n",
            "Epoch: 7, Steps: 744 | Train Loss: 0.4925540 Vali Loss: 0.5652488 Test Loss: 0.4522414\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 1.5625e-05\n",
            "\titers: 100, epoch: 8 | loss: 0.4772547\n",
            "\tspeed: 0.4901s/iter; left time: 1045.3667s\n",
            "\titers: 200, epoch: 8 | loss: 0.5468082\n",
            "\tspeed: 0.1671s/iter; left time: 339.7109s\n",
            "\titers: 300, epoch: 8 | loss: 0.5765954\n",
            "\tspeed: 0.1663s/iter; left time: 321.4130s\n",
            "\titers: 400, epoch: 8 | loss: 0.4260331\n",
            "\tspeed: 0.1652s/iter; left time: 302.7806s\n",
            "\titers: 500, epoch: 8 | loss: 0.4691660\n",
            "\tspeed: 0.1667s/iter; left time: 288.9774s\n",
            "\titers: 600, epoch: 8 | loss: 0.4654180\n",
            "\tspeed: 0.1647s/iter; left time: 269.0331s\n",
            "\titers: 700, epoch: 8 | loss: 0.6752231\n",
            "\tspeed: 0.1621s/iter; left time: 248.5688s\n",
            "Epoch: 8 cost time: 123.78122854232788\n",
            "Epoch: 8, Steps: 744 | Train Loss: 0.4920750 Vali Loss: 0.5635748 Test Loss: 0.4513029\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_NSW_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 3490\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "mse:0.45190638303756714, mae:0.42821401357650757, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_NSW_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_NSW_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.4519, MAE=0.4282\n",
            "âœ… å®Œæˆ | MAE: 0.4282 | ç”¨æ—¶: 20.1åˆ†é’Ÿ\n",
            "\n",
            "[4/20] ðŸš€ NSW | 15min | PatchTST\n",
            "--------------------------------------------------------------------------------\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_NSW_15min_PatchTSTModel:              PatchTST            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          NSW_15min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            384                 Label Len:          192                 \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              5                   Num Kernels:        6                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            4                   e layers:           2                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         32                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            1                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_NSW_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 11890\n",
            "val 1735\n",
            "test 3490\n",
            "\titers: 100, epoch: 1 | loss: 0.7062405\n",
            "\tspeed: 0.0225s/iter; left time: 81.3090s\n",
            "\titers: 200, epoch: 1 | loss: 0.7586551\n",
            "\tspeed: 0.0140s/iter; left time: 49.4346s\n",
            "\titers: 300, epoch: 1 | loss: 0.6958560\n",
            "\tspeed: 0.0142s/iter; left time: 48.7077s\n",
            "Epoch: 1 cost time: 6.487157106399536\n",
            "Epoch: 1, Steps: 372 | Train Loss: 0.7584854 Vali Loss: 0.5828126 Test Loss: 0.4615676\n",
            "Validation loss decreased (inf --> 0.582813).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.6027521\n",
            "\tspeed: 0.0445s/iter; left time: 144.4683s\n",
            "\titers: 200, epoch: 2 | loss: 0.7184129\n",
            "\tspeed: 0.0128s/iter; left time: 40.1791s\n",
            "\titers: 300, epoch: 2 | loss: 0.7513047\n",
            "\tspeed: 0.0129s/iter; left time: 39.2397s\n",
            "Epoch: 2 cost time: 4.850118160247803\n",
            "Epoch: 2, Steps: 372 | Train Loss: 0.6544717 Vali Loss: 0.6546532 Test Loss: 0.5308034\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.4482380\n",
            "\tspeed: 0.0346s/iter; left time: 99.6659s\n",
            "\titers: 200, epoch: 3 | loss: 0.6569759\n",
            "\tspeed: 0.0132s/iter; left time: 36.6225s\n",
            "\titers: 300, epoch: 3 | loss: 0.5836440\n",
            "\tspeed: 0.0152s/iter; left time: 40.5999s\n",
            "Epoch: 3 cost time: 5.568351745605469\n",
            "Epoch: 3, Steps: 372 | Train Loss: 0.5778412 Vali Loss: 0.5935460 Test Loss: 0.4715260\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_NSW_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 3490\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "mse:0.4624001681804657, mae:0.43028098344802856, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_NSW_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_NSW_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.4624, MAE=0.4303\n",
            "âœ… å®Œæˆ | MAE: 0.4303 | ç”¨æ—¶: 0.5åˆ†é’Ÿ\n",
            "\n",
            "[5/20] ðŸš€ QLD | 30min | TimesNet\n",
            "--------------------------------------------------------------------------------\n",
            "  âš ï¸  TimesNetå…³é—­AMP (é¿å…cuFFT FP16é”™è¯¯)ï¼Œä½¿ç”¨FP32è®­ç»ƒ\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_QLD_30min_TimesNetModel:              TimesNet            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          QLD_30min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              3                   Num Kernels:        4                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            8                   e layers:           1                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         16                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            0                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_QLD_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15140\n",
            "val 2171\n",
            "test 4364\n",
            "\titers: 100, epoch: 1 | loss: 0.7612901\n",
            "\tspeed: 0.1014s/iter; left time: 950.1156s\n",
            "\titers: 200, epoch: 1 | loss: 0.5182765\n",
            "\tspeed: 0.1031s/iter; left time: 956.0547s\n",
            "\titers: 300, epoch: 1 | loss: 0.5114921\n",
            "\tspeed: 0.1036s/iter; left time: 949.6923s\n",
            "\titers: 400, epoch: 1 | loss: 0.5457685\n",
            "\tspeed: 0.1018s/iter; left time: 923.0908s\n",
            "\titers: 500, epoch: 1 | loss: 0.4202854\n",
            "\tspeed: 0.0983s/iter; left time: 881.5469s\n",
            "\titers: 600, epoch: 1 | loss: 0.9926603\n",
            "\tspeed: 0.0940s/iter; left time: 833.4404s\n",
            "\titers: 700, epoch: 1 | loss: 0.4519310\n",
            "\tspeed: 0.0920s/iter; left time: 806.7700s\n",
            "\titers: 800, epoch: 1 | loss: 0.6037439\n",
            "\tspeed: 0.0912s/iter; left time: 790.5462s\n",
            "\titers: 900, epoch: 1 | loss: 0.9499231\n",
            "\tspeed: 0.0882s/iter; left time: 756.3478s\n",
            "Epoch: 1 cost time: 91.480393409729\n",
            "Epoch: 1, Steps: 947 | Train Loss: 0.6946990 Vali Loss: 0.5532406 Test Loss: 0.8044801\n",
            "Validation loss decreased (inf --> 0.553241).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.6774220\n",
            "\tspeed: 0.2717s/iter; left time: 2289.1264s\n",
            "\titers: 200, epoch: 2 | loss: 1.3274671\n",
            "\tspeed: 0.0803s/iter; left time: 668.0242s\n",
            "\titers: 300, epoch: 2 | loss: 0.7330807\n",
            "\tspeed: 0.0803s/iter; left time: 660.2618s\n",
            "\titers: 400, epoch: 2 | loss: 0.5133690\n",
            "\tspeed: 0.0786s/iter; left time: 638.9144s\n",
            "\titers: 500, epoch: 2 | loss: 0.7440048\n",
            "\tspeed: 0.0794s/iter; left time: 637.2119s\n",
            "\titers: 600, epoch: 2 | loss: 1.1486062\n",
            "\tspeed: 0.0785s/iter; left time: 622.0798s\n",
            "\titers: 700, epoch: 2 | loss: 0.7791416\n",
            "\tspeed: 0.0780s/iter; left time: 610.3899s\n",
            "\titers: 800, epoch: 2 | loss: 0.7181996\n",
            "\tspeed: 0.0778s/iter; left time: 601.2845s\n",
            "\titers: 900, epoch: 2 | loss: 0.7956743\n",
            "\tspeed: 0.0779s/iter; left time: 593.8502s\n",
            "Epoch: 2 cost time: 75.70519423484802\n",
            "Epoch: 2, Steps: 947 | Train Loss: 0.6686861 Vali Loss: 0.5486664 Test Loss: 0.8018267\n",
            "Validation loss decreased (0.553241 --> 0.548666).  Saving model ...\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.7920682\n",
            "\tspeed: 0.2536s/iter; left time: 1895.9146s\n",
            "\titers: 200, epoch: 3 | loss: 0.5677240\n",
            "\tspeed: 0.0779s/iter; left time: 574.3420s\n",
            "\titers: 300, epoch: 3 | loss: 0.3971394\n",
            "\tspeed: 0.0777s/iter; left time: 565.6481s\n",
            "\titers: 400, epoch: 3 | loss: 0.7810617\n",
            "\tspeed: 0.0780s/iter; left time: 560.1273s\n",
            "\titers: 500, epoch: 3 | loss: 0.8514484\n",
            "\tspeed: 0.0777s/iter; left time: 549.8161s\n",
            "\titers: 600, epoch: 3 | loss: 0.4408756\n",
            "\tspeed: 0.0779s/iter; left time: 543.5446s\n",
            "\titers: 700, epoch: 3 | loss: 0.7181720\n",
            "\tspeed: 0.0780s/iter; left time: 536.4790s\n",
            "\titers: 800, epoch: 3 | loss: 0.7097688\n",
            "\tspeed: 0.0779s/iter; left time: 527.7524s\n",
            "\titers: 900, epoch: 3 | loss: 0.4218008\n",
            "\tspeed: 0.0779s/iter; left time: 519.9491s\n",
            "Epoch: 3 cost time: 74.23031997680664\n",
            "Epoch: 3, Steps: 947 | Train Loss: 0.6580087 Vali Loss: 0.5538589 Test Loss: 0.8091851\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.7956782\n",
            "\tspeed: 0.2521s/iter; left time: 1645.9243s\n",
            "\titers: 200, epoch: 4 | loss: 0.5629836\n",
            "\tspeed: 0.0778s/iter; left time: 500.2617s\n",
            "\titers: 300, epoch: 4 | loss: 0.7658183\n",
            "\tspeed: 0.0779s/iter; left time: 493.3366s\n",
            "\titers: 400, epoch: 4 | loss: 0.8129699\n",
            "\tspeed: 0.0783s/iter; left time: 488.1119s\n",
            "\titers: 500, epoch: 4 | loss: 0.7414203\n",
            "\tspeed: 0.0784s/iter; left time: 480.5934s\n",
            "\titers: 600, epoch: 4 | loss: 0.9072328\n",
            "\tspeed: 0.0782s/iter; left time: 471.4991s\n",
            "\titers: 700, epoch: 4 | loss: 0.5738281\n",
            "\tspeed: 0.0781s/iter; left time: 463.3695s\n",
            "\titers: 800, epoch: 4 | loss: 0.5190862\n",
            "\tspeed: 0.0782s/iter; left time: 455.7174s\n",
            "\titers: 900, epoch: 4 | loss: 0.3652096\n",
            "\tspeed: 0.0779s/iter; left time: 446.3586s\n",
            "Epoch: 4 cost time: 74.47984290122986\n",
            "Epoch: 4, Steps: 947 | Train Loss: 0.6485152 Vali Loss: 0.5588063 Test Loss: 0.8134449\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_QLD_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4364\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "mse:0.802304208278656, mae:0.4700831472873688, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_QLD_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_QLD_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.8023, MAE=0.4701\n",
            "âœ… å®Œæˆ | MAE: 0.4701 | ç”¨æ—¶: 6.4åˆ†é’Ÿ\n",
            "\n",
            "[6/20] ðŸš€ QLD | 30min | PatchTST\n",
            "--------------------------------------------------------------------------------\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_QLD_30min_PatchTSTModel:              PatchTST            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          QLD_30min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              5                   Num Kernels:        6                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            4                   e layers:           2                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         32                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            1                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_QLD_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15140\n",
            "val 2171\n",
            "test 4364\n",
            "\titers: 100, epoch: 1 | loss: 0.8025588\n",
            "\tspeed: 0.0216s/iter; left time: 100.0646s\n",
            "\titers: 200, epoch: 1 | loss: 0.7434075\n",
            "\tspeed: 0.0125s/iter; left time: 56.9300s\n",
            "\titers: 300, epoch: 1 | loss: 0.8097419\n",
            "\tspeed: 0.0122s/iter; left time: 54.2589s\n",
            "\titers: 400, epoch: 1 | loss: 0.8683231\n",
            "\tspeed: 0.0165s/iter; left time: 71.4212s\n",
            "Epoch: 1 cost time: 7.498338222503662\n",
            "Epoch: 1, Steps: 474 | Train Loss: 0.8418703 Vali Loss: 0.5970142 Test Loss: 0.8376320\n",
            "Validation loss decreased (inf --> 0.597014).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.6152081\n",
            "\tspeed: 0.0386s/iter; left time: 161.0300s\n",
            "\titers: 200, epoch: 2 | loss: 0.8965152\n",
            "\tspeed: 0.0121s/iter; left time: 49.2281s\n",
            "\titers: 300, epoch: 2 | loss: 1.0334511\n",
            "\tspeed: 0.0121s/iter; left time: 47.8791s\n",
            "\titers: 400, epoch: 2 | loss: 0.7127612\n",
            "\tspeed: 0.0123s/iter; left time: 47.7568s\n",
            "Epoch: 2 cost time: 5.908204078674316\n",
            "Epoch: 2, Steps: 474 | Train Loss: 0.7386711 Vali Loss: 0.5848921 Test Loss: 0.8439943\n",
            "Validation loss decreased (0.597014 --> 0.584892).  Saving model ...\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.6876019\n",
            "\tspeed: 0.0380s/iter; left time: 140.5173s\n",
            "\titers: 200, epoch: 3 | loss: 0.8482508\n",
            "\tspeed: 0.0172s/iter; left time: 61.6942s\n",
            "\titers: 300, epoch: 3 | loss: 0.6879387\n",
            "\tspeed: 0.0133s/iter; left time: 46.4988s\n",
            "\titers: 400, epoch: 3 | loss: 0.7448775\n",
            "\tspeed: 0.0120s/iter; left time: 40.6317s\n",
            "Epoch: 3 cost time: 6.714787721633911\n",
            "Epoch: 3, Steps: 474 | Train Loss: 0.7059464 Vali Loss: 0.5583524 Test Loss: 0.8101672\n",
            "Validation loss decreased (0.584892 --> 0.558352).  Saving model ...\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.5323097\n",
            "\tspeed: 0.0361s/iter; left time: 116.2284s\n",
            "\titers: 200, epoch: 4 | loss: 0.5034283\n",
            "\tspeed: 0.0123s/iter; left time: 38.4357s\n",
            "\titers: 300, epoch: 4 | loss: 0.7995054\n",
            "\tspeed: 0.0119s/iter; left time: 36.0010s\n",
            "\titers: 400, epoch: 4 | loss: 0.6930919\n",
            "\tspeed: 0.0120s/iter; left time: 35.0280s\n",
            "Epoch: 4 cost time: 6.067165374755859\n",
            "Epoch: 4, Steps: 474 | Train Loss: 0.7001871 Vali Loss: 0.5560755 Test Loss: 0.8055485\n",
            "Validation loss decreased (0.558352 --> 0.556075).  Saving model ...\n",
            "Updating learning rate to 0.000125\n",
            "\titers: 100, epoch: 5 | loss: 0.7098677\n",
            "\tspeed: 0.0430s/iter; left time: 117.9986s\n",
            "\titers: 200, epoch: 5 | loss: 0.7677120\n",
            "\tspeed: 0.0123s/iter; left time: 32.5386s\n",
            "\titers: 300, epoch: 5 | loss: 0.9715056\n",
            "\tspeed: 0.0120s/iter; left time: 30.6513s\n",
            "\titers: 400, epoch: 5 | loss: 0.3958356\n",
            "\tspeed: 0.0121s/iter; left time: 29.5751s\n",
            "Epoch: 5 cost time: 5.870355129241943\n",
            "Epoch: 5, Steps: 474 | Train Loss: 0.6963931 Vali Loss: 0.5564423 Test Loss: 0.8064325\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 6.25e-05\n",
            "\titers: 100, epoch: 6 | loss: 0.9399847\n",
            "\tspeed: 0.0356s/iter; left time: 80.8188s\n",
            "\titers: 200, epoch: 6 | loss: 0.7906875\n",
            "\tspeed: 0.0120s/iter; left time: 26.0279s\n",
            "\titers: 300, epoch: 6 | loss: 0.5389717\n",
            "\tspeed: 0.0178s/iter; left time: 36.7641s\n",
            "\titers: 400, epoch: 6 | loss: 0.8566431\n",
            "\tspeed: 0.0140s/iter; left time: 27.5122s\n",
            "Epoch: 6 cost time: 6.597764253616333\n",
            "Epoch: 6, Steps: 474 | Train Loss: 0.6967404 Vali Loss: 0.5571210 Test Loss: 0.8070213\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_QLD_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4364\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "mse:0.8080854415893555, mae:0.4750818908214569, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_QLD_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_QLD_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.8081, MAE=0.4751\n",
            "âœ… å®Œæˆ | MAE: 0.4751 | ç”¨æ—¶: 0.9åˆ†é’Ÿ\n",
            "\n",
            "[7/20] ðŸš€ QLD | 15min | TimesNet\n",
            "--------------------------------------------------------------------------------\n",
            "  âš ï¸  TimesNetå…³é—­AMP (é¿å…cuFFT FP16é”™è¯¯)ï¼Œä½¿ç”¨FP32è®­ç»ƒ\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_QLD_15min_TimesNetModel:              TimesNet            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          QLD_15min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            384                 Label Len:          192                 \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              3                   Num Kernels:        4                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            8                   e layers:           1                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         16                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            0                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_QLD_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 11890\n",
            "val 1735\n",
            "test 3490\n",
            "\titers: 100, epoch: 1 | loss: 0.6175854\n",
            "\tspeed: 0.1350s/iter; left time: 991.1427s\n",
            "\titers: 200, epoch: 1 | loss: 0.4328891\n",
            "\tspeed: 0.1197s/iter; left time: 866.8264s\n",
            "\titers: 300, epoch: 1 | loss: 0.5667351\n",
            "\tspeed: 0.1194s/iter; left time: 852.4209s\n",
            "\titers: 400, epoch: 1 | loss: 0.4712421\n",
            "\tspeed: 0.1197s/iter; left time: 842.5827s\n",
            "\titers: 500, epoch: 1 | loss: 0.5811146\n",
            "\tspeed: 0.1242s/iter; left time: 862.4032s\n",
            "\titers: 600, epoch: 1 | loss: 0.4431768\n",
            "\tspeed: 0.1376s/iter; left time: 941.0133s\n",
            "\titers: 700, epoch: 1 | loss: 0.7771664\n",
            "\tspeed: 0.1379s/iter; left time: 929.3443s\n",
            "Epoch: 1 cost time: 97.19439029693604\n",
            "Epoch: 1, Steps: 744 | Train Loss: 0.5508080 Vali Loss: 0.4826787 Test Loss: 0.4445384\n",
            "Validation loss decreased (inf --> 0.482679).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.6423131\n",
            "\tspeed: 0.4660s/iter; left time: 3074.1162s\n",
            "\titers: 200, epoch: 2 | loss: 0.4571044\n",
            "\tspeed: 0.1535s/iter; left time: 997.2917s\n",
            "\titers: 300, epoch: 2 | loss: 0.6396377\n",
            "\tspeed: 0.1516s/iter; left time: 969.6202s\n",
            "\titers: 400, epoch: 2 | loss: 0.4051296\n",
            "\tspeed: 0.1578s/iter; left time: 993.5551s\n",
            "\titers: 500, epoch: 2 | loss: 0.4578750\n",
            "\tspeed: 0.1617s/iter; left time: 1001.8794s\n",
            "\titers: 600, epoch: 2 | loss: 0.5681505\n",
            "\tspeed: 0.1627s/iter; left time: 992.1520s\n",
            "\titers: 700, epoch: 2 | loss: 0.7366654\n",
            "\tspeed: 0.1684s/iter; left time: 1010.0072s\n",
            "Epoch: 2 cost time: 119.591237783432\n",
            "Epoch: 2, Steps: 744 | Train Loss: 0.5290370 Vali Loss: 0.4781933 Test Loss: 0.4417077\n",
            "Validation loss decreased (0.482679 --> 0.478193).  Saving model ...\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.7402976\n",
            "\tspeed: 0.5123s/iter; left time: 2998.2317s\n",
            "\titers: 200, epoch: 3 | loss: 0.4202739\n",
            "\tspeed: 0.1698s/iter; left time: 976.9350s\n",
            "\titers: 300, epoch: 3 | loss: 0.5005043\n",
            "\tspeed: 0.1706s/iter; left time: 964.6332s\n",
            "\titers: 400, epoch: 3 | loss: 0.6462970\n",
            "\tspeed: 0.1712s/iter; left time: 950.5669s\n",
            "\titers: 500, epoch: 3 | loss: 0.6758552\n",
            "\tspeed: 0.1731s/iter; left time: 944.0073s\n",
            "\titers: 600, epoch: 3 | loss: 0.4824652\n",
            "\tspeed: 0.1729s/iter; left time: 925.4930s\n",
            "\titers: 700, epoch: 3 | loss: 0.4888232\n",
            "\tspeed: 0.1731s/iter; left time: 909.4660s\n",
            "Epoch: 3 cost time: 128.26397562026978\n",
            "Epoch: 3, Steps: 744 | Train Loss: 0.5228834 Vali Loss: 0.4778135 Test Loss: 0.4416960\n",
            "Validation loss decreased (0.478193 --> 0.477814).  Saving model ...\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.6596258\n",
            "\tspeed: 0.5186s/iter; left time: 2649.7314s\n",
            "\titers: 200, epoch: 4 | loss: 0.3501580\n",
            "\tspeed: 0.1732s/iter; left time: 867.5090s\n",
            "\titers: 300, epoch: 4 | loss: 0.7043021\n",
            "\tspeed: 0.1738s/iter; left time: 853.0036s\n",
            "\titers: 400, epoch: 4 | loss: 0.4687800\n",
            "\tspeed: 0.1741s/iter; left time: 837.3931s\n",
            "\titers: 500, epoch: 4 | loss: 0.4706850\n",
            "\tspeed: 0.1735s/iter; left time: 817.0830s\n",
            "\titers: 600, epoch: 4 | loss: 0.3976467\n",
            "\tspeed: 0.1734s/iter; left time: 799.2322s\n",
            "\titers: 700, epoch: 4 | loss: 0.7372444\n",
            "\tspeed: 0.1744s/iter; left time: 786.5384s\n",
            "Epoch: 4 cost time: 130.35249972343445\n",
            "Epoch: 4, Steps: 744 | Train Loss: 0.5179742 Vali Loss: 0.4771175 Test Loss: 0.4400291\n",
            "Validation loss decreased (0.477814 --> 0.477117).  Saving model ...\n",
            "Updating learning rate to 0.000125\n",
            "\titers: 100, epoch: 5 | loss: 0.4971043\n",
            "\tspeed: 0.5331s/iter; left time: 2326.9960s\n",
            "\titers: 200, epoch: 5 | loss: 0.3796700\n",
            "\tspeed: 0.1769s/iter; left time: 754.4104s\n",
            "\titers: 300, epoch: 5 | loss: 0.7510214\n",
            "\tspeed: 0.1748s/iter; left time: 728.1208s\n",
            "\titers: 400, epoch: 5 | loss: 0.6028760\n",
            "\tspeed: 0.1740s/iter; left time: 707.3480s\n",
            "\titers: 500, epoch: 5 | loss: 0.4599046\n",
            "\tspeed: 0.1747s/iter; left time: 692.7245s\n",
            "\titers: 600, epoch: 5 | loss: 0.5510604\n",
            "\tspeed: 0.1736s/iter; left time: 671.0294s\n",
            "\titers: 700, epoch: 5 | loss: 0.4590301\n",
            "\tspeed: 0.1743s/iter; left time: 656.3470s\n",
            "Epoch: 5 cost time: 130.68595576286316\n",
            "Epoch: 5, Steps: 744 | Train Loss: 0.5147461 Vali Loss: 0.4748467 Test Loss: 0.4412744\n",
            "Validation loss decreased (0.477117 --> 0.474847).  Saving model ...\n",
            "Updating learning rate to 6.25e-05\n",
            "\titers: 100, epoch: 6 | loss: 0.4569742\n",
            "\tspeed: 0.5271s/iter; left time: 1908.6388s\n",
            "\titers: 200, epoch: 6 | loss: 0.8034098\n",
            "\tspeed: 0.1748s/iter; left time: 615.5263s\n",
            "\titers: 300, epoch: 6 | loss: 0.3269382\n",
            "\tspeed: 0.1763s/iter; left time: 603.2035s\n",
            "\titers: 400, epoch: 6 | loss: 0.5647228\n",
            "\tspeed: 0.1753s/iter; left time: 582.1978s\n",
            "\titers: 500, epoch: 6 | loss: 0.3312055\n",
            "\tspeed: 0.1746s/iter; left time: 562.3418s\n",
            "\titers: 600, epoch: 6 | loss: 0.4171121\n",
            "\tspeed: 0.1760s/iter; left time: 549.2364s\n",
            "\titers: 700, epoch: 6 | loss: 0.5625114\n",
            "\tspeed: 0.1742s/iter; left time: 526.3342s\n",
            "Epoch: 6 cost time: 130.98257613182068\n",
            "Epoch: 6, Steps: 744 | Train Loss: 0.5120969 Vali Loss: 0.4745986 Test Loss: 0.4397029\n",
            "Validation loss decreased (0.474847 --> 0.474599).  Saving model ...\n",
            "Updating learning rate to 3.125e-05\n",
            "\titers: 100, epoch: 7 | loss: 0.3989969\n",
            "\tspeed: 0.5272s/iter; left time: 1516.6261s\n",
            "\titers: 200, epoch: 7 | loss: 0.4869038\n",
            "\tspeed: 0.1755s/iter; left time: 487.3783s\n",
            "\titers: 300, epoch: 7 | loss: 0.5021911\n",
            "\tspeed: 0.1750s/iter; left time: 468.4555s\n",
            "\titers: 400, epoch: 7 | loss: 0.5983703\n",
            "\tspeed: 0.1753s/iter; left time: 451.7757s\n",
            "\titers: 500, epoch: 7 | loss: 0.3776834\n",
            "\tspeed: 0.1746s/iter; left time: 432.4317s\n",
            "\titers: 600, epoch: 7 | loss: 0.5764586\n",
            "\tspeed: 0.1736s/iter; left time: 412.6597s\n",
            "\titers: 700, epoch: 7 | loss: 0.3936022\n",
            "\tspeed: 0.1745s/iter; left time: 397.2816s\n",
            "Epoch: 7 cost time: 130.59020113945007\n",
            "Epoch: 7, Steps: 744 | Train Loss: 0.5108178 Vali Loss: 0.4750967 Test Loss: 0.4418961\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 1.5625e-05\n",
            "\titers: 100, epoch: 8 | loss: 0.6019543\n",
            "\tspeed: 0.5254s/iter; left time: 1120.7355s\n",
            "\titers: 200, epoch: 8 | loss: 0.4384668\n",
            "\tspeed: 0.1757s/iter; left time: 357.2156s\n",
            "\titers: 300, epoch: 8 | loss: 0.5327032\n",
            "\tspeed: 0.1741s/iter; left time: 336.5702s\n",
            "\titers: 400, epoch: 8 | loss: 0.4900366\n",
            "\tspeed: 0.1733s/iter; left time: 317.6032s\n",
            "\titers: 500, epoch: 8 | loss: 0.5819812\n",
            "\tspeed: 0.1725s/iter; left time: 298.9791s\n",
            "\titers: 600, epoch: 8 | loss: 0.4998881\n",
            "\tspeed: 0.1743s/iter; left time: 284.7094s\n",
            "\titers: 700, epoch: 8 | loss: 0.5578268\n",
            "\tspeed: 0.1737s/iter; left time: 266.3298s\n",
            "Epoch: 8 cost time: 130.33034944534302\n",
            "Epoch: 8, Steps: 744 | Train Loss: 0.5097097 Vali Loss: 0.4752215 Test Loss: 0.4404012\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_QLD_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 3490\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "mse:0.43900299072265625, mae:0.41866517066955566, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_QLD_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_QLD_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.4390, MAE=0.4187\n",
            "âœ… å®Œæˆ | MAE: 0.4187 | ç”¨æ—¶: 20.6åˆ†é’Ÿ\n",
            "\n",
            "[8/20] ðŸš€ QLD | 15min | PatchTST\n",
            "--------------------------------------------------------------------------------\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_QLD_15min_PatchTSTModel:              PatchTST            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          QLD_15min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            384                 Label Len:          192                 \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              5                   Num Kernels:        6                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            4                   e layers:           2                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         32                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            1                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_QLD_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 11890\n",
            "val 1735\n",
            "test 3490\n",
            "\titers: 100, epoch: 1 | loss: 0.6728802\n",
            "\tspeed: 0.0218s/iter; left time: 78.9134s\n",
            "\titers: 200, epoch: 1 | loss: 0.7670009\n",
            "\tspeed: 0.0127s/iter; left time: 44.8805s\n",
            "\titers: 300, epoch: 1 | loss: 0.7883264\n",
            "\tspeed: 0.0134s/iter; left time: 45.9372s\n",
            "Epoch: 1 cost time: 5.810874938964844\n",
            "Epoch: 1, Steps: 372 | Train Loss: 0.7822645 Vali Loss: 0.4922114 Test Loss: 0.4570295\n",
            "Validation loss decreased (inf --> 0.492211).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.6431639\n",
            "\tspeed: 0.0420s/iter; left time: 136.6107s\n",
            "\titers: 200, epoch: 2 | loss: 0.6674782\n",
            "\tspeed: 0.0126s/iter; left time: 39.7153s\n",
            "\titers: 300, epoch: 2 | loss: 0.6118131\n",
            "\tspeed: 0.0126s/iter; left time: 38.3917s\n",
            "Epoch: 2 cost time: 4.984438180923462\n",
            "Epoch: 2, Steps: 372 | Train Loss: 0.6756813 Vali Loss: 0.5429721 Test Loss: 0.5045288\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.5758522\n",
            "\tspeed: 0.0345s/iter; left time: 99.2526s\n",
            "\titers: 200, epoch: 3 | loss: 0.4673958\n",
            "\tspeed: 0.0126s/iter; left time: 34.9834s\n",
            "\titers: 300, epoch: 3 | loss: 0.5481065\n",
            "\tspeed: 0.0127s/iter; left time: 34.0605s\n",
            "Epoch: 3 cost time: 5.014378547668457\n",
            "Epoch: 3, Steps: 372 | Train Loss: 0.5937832 Vali Loss: 0.5133272 Test Loss: 0.4802991\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_QLD_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 3490\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "mse:0.4557906985282898, mae:0.4362284243106842, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_QLD_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_QLD_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.4558, MAE=0.4362\n",
            "âœ… å®Œæˆ | MAE: 0.4362 | ç”¨æ—¶: 0.5åˆ†é’Ÿ\n",
            "\n",
            "[9/20] ðŸš€ VIC | 30min | TimesNet\n",
            "--------------------------------------------------------------------------------\n",
            "  âš ï¸  TimesNetå…³é—­AMP (é¿å…cuFFT FP16é”™è¯¯)ï¼Œä½¿ç”¨FP32è®­ç»ƒ\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_VIC_30min_TimesNetModel:              TimesNet            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          VIC_30min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              3                   Num Kernels:        4                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            8                   e layers:           1                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         16                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            0                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_VIC_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15140\n",
            "val 2171\n",
            "test 4364\n",
            "\titers: 100, epoch: 1 | loss: 0.5098989\n",
            "\tspeed: 0.1007s/iter; left time: 943.8355s\n",
            "\titers: 200, epoch: 1 | loss: 1.0568920\n",
            "\tspeed: 0.1007s/iter; left time: 933.7771s\n",
            "\titers: 300, epoch: 1 | loss: 0.9488136\n",
            "\tspeed: 0.0882s/iter; left time: 809.0955s\n",
            "\titers: 400, epoch: 1 | loss: 0.5029978\n",
            "\tspeed: 0.0839s/iter; left time: 761.2531s\n",
            "\titers: 500, epoch: 1 | loss: 0.7275535\n",
            "\tspeed: 0.0819s/iter; left time: 735.0306s\n",
            "\titers: 600, epoch: 1 | loss: 0.9378960\n",
            "\tspeed: 0.0822s/iter; left time: 728.9116s\n",
            "\titers: 700, epoch: 1 | loss: 0.5416593\n",
            "\tspeed: 0.0809s/iter; left time: 709.6007s\n",
            "\titers: 800, epoch: 1 | loss: 0.4592842\n",
            "\tspeed: 0.0806s/iter; left time: 699.1105s\n",
            "\titers: 900, epoch: 1 | loss: 0.5498860\n",
            "\tspeed: 0.0806s/iter; left time: 690.6940s\n",
            "Epoch: 1 cost time: 81.96454548835754\n",
            "Epoch: 1, Steps: 947 | Train Loss: 0.6837971 Vali Loss: 0.6538620 Test Loss: 0.7479575\n",
            "Validation loss decreased (inf --> 0.653862).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.9864304\n",
            "\tspeed: 0.2547s/iter; left time: 2145.5070s\n",
            "\titers: 200, epoch: 2 | loss: 1.0197217\n",
            "\tspeed: 0.0810s/iter; left time: 674.5428s\n",
            "\titers: 300, epoch: 2 | loss: 0.9224201\n",
            "\tspeed: 0.0811s/iter; left time: 666.7285s\n",
            "\titers: 400, epoch: 2 | loss: 0.9845885\n",
            "\tspeed: 0.0811s/iter; left time: 658.7426s\n",
            "\titers: 500, epoch: 2 | loss: 0.6296503\n",
            "\tspeed: 0.0808s/iter; left time: 648.3804s\n",
            "\titers: 600, epoch: 2 | loss: 0.3584992\n",
            "\tspeed: 0.0809s/iter; left time: 641.2692s\n",
            "\titers: 700, epoch: 2 | loss: 0.7537612\n",
            "\tspeed: 0.0811s/iter; left time: 634.7657s\n",
            "\titers: 800, epoch: 2 | loss: 0.5060083\n",
            "\tspeed: 0.0810s/iter; left time: 625.7075s\n",
            "\titers: 900, epoch: 2 | loss: 0.8099555\n",
            "\tspeed: 0.0810s/iter; left time: 617.9206s\n",
            "Epoch: 2 cost time: 77.03784155845642\n",
            "Epoch: 2, Steps: 947 | Train Loss: 0.6620396 Vali Loss: 0.6506659 Test Loss: 0.7468737\n",
            "Validation loss decreased (0.653862 --> 0.650666).  Saving model ...\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.6830970\n",
            "\tspeed: 0.2599s/iter; left time: 1942.9730s\n",
            "\titers: 200, epoch: 3 | loss: 0.8187444\n",
            "\tspeed: 0.0812s/iter; left time: 599.1575s\n",
            "\titers: 300, epoch: 3 | loss: 0.3972976\n",
            "\tspeed: 0.0807s/iter; left time: 587.0069s\n",
            "\titers: 400, epoch: 3 | loss: 0.8345821\n",
            "\tspeed: 0.0810s/iter; left time: 581.5585s\n",
            "\titers: 500, epoch: 3 | loss: 0.4038904\n",
            "\tspeed: 0.0809s/iter; left time: 572.8831s\n",
            "\titers: 600, epoch: 3 | loss: 0.5152180\n",
            "\tspeed: 0.0808s/iter; left time: 564.0574s\n",
            "\titers: 700, epoch: 3 | loss: 0.6370538\n",
            "\tspeed: 0.0809s/iter; left time: 556.6610s\n",
            "\titers: 800, epoch: 3 | loss: 0.5672019\n",
            "\tspeed: 0.0812s/iter; left time: 550.0270s\n",
            "\titers: 900, epoch: 3 | loss: 0.5543947\n",
            "\tspeed: 0.0813s/iter; left time: 543.0504s\n",
            "Epoch: 3 cost time: 77.1205084323883\n",
            "Epoch: 3, Steps: 947 | Train Loss: 0.6536439 Vali Loss: 0.6539811 Test Loss: 0.7472574\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.4856378\n",
            "\tspeed: 0.2667s/iter; left time: 1741.5516s\n",
            "\titers: 200, epoch: 4 | loss: 0.3581842\n",
            "\tspeed: 0.0818s/iter; left time: 525.7234s\n",
            "\titers: 300, epoch: 4 | loss: 0.3681323\n",
            "\tspeed: 0.0822s/iter; left time: 520.1018s\n",
            "\titers: 400, epoch: 4 | loss: 0.6027474\n",
            "\tspeed: 0.0816s/iter; left time: 508.6103s\n",
            "\titers: 500, epoch: 4 | loss: 0.5206629\n",
            "\tspeed: 0.0820s/iter; left time: 502.4939s\n",
            "\titers: 600, epoch: 4 | loss: 0.8325070\n",
            "\tspeed: 0.0818s/iter; left time: 493.4099s\n",
            "\titers: 700, epoch: 4 | loss: 0.2858020\n",
            "\tspeed: 0.0814s/iter; left time: 482.9072s\n",
            "\titers: 800, epoch: 4 | loss: 0.6830267\n",
            "\tspeed: 0.0822s/iter; left time: 479.2951s\n",
            "\titers: 900, epoch: 4 | loss: 0.5310043\n",
            "\tspeed: 0.0824s/iter; left time: 471.8699s\n",
            "Epoch: 4 cost time: 77.90134358406067\n",
            "Epoch: 4, Steps: 947 | Train Loss: 0.6484764 Vali Loss: 0.6505909 Test Loss: 0.7454079\n",
            "Validation loss decreased (0.650666 --> 0.650591).  Saving model ...\n",
            "Updating learning rate to 0.000125\n",
            "\titers: 100, epoch: 5 | loss: 1.1178921\n",
            "\tspeed: 0.2718s/iter; left time: 1517.5040s\n",
            "\titers: 200, epoch: 5 | loss: 0.5182797\n",
            "\tspeed: 0.0817s/iter; left time: 447.7142s\n",
            "\titers: 300, epoch: 5 | loss: 0.7501072\n",
            "\tspeed: 0.0820s/iter; left time: 441.6642s\n",
            "\titers: 400, epoch: 5 | loss: 0.8378815\n",
            "\tspeed: 0.0821s/iter; left time: 433.8211s\n",
            "\titers: 500, epoch: 5 | loss: 0.6854717\n",
            "\tspeed: 0.0820s/iter; left time: 425.0562s\n",
            "\titers: 600, epoch: 5 | loss: 0.4383581\n",
            "\tspeed: 0.0814s/iter; left time: 413.9540s\n",
            "\titers: 700, epoch: 5 | loss: 0.3288578\n",
            "\tspeed: 0.0817s/iter; left time: 407.2696s\n",
            "\titers: 800, epoch: 5 | loss: 0.4903302\n",
            "\tspeed: 0.0823s/iter; left time: 401.7909s\n",
            "\titers: 900, epoch: 5 | loss: 0.7232749\n",
            "\tspeed: 0.0820s/iter; left time: 392.1499s\n",
            "Epoch: 5 cost time: 77.91530418395996\n",
            "Epoch: 5, Steps: 947 | Train Loss: 0.6418996 Vali Loss: 0.6524406 Test Loss: 0.7476109\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 6.25e-05\n",
            "\titers: 100, epoch: 6 | loss: 0.6027692\n",
            "\tspeed: 0.2712s/iter; left time: 1257.1225s\n",
            "\titers: 200, epoch: 6 | loss: 0.8387228\n",
            "\tspeed: 0.0820s/iter; left time: 372.0504s\n",
            "\titers: 300, epoch: 6 | loss: 0.5493619\n",
            "\tspeed: 0.0819s/iter; left time: 363.3155s\n",
            "\titers: 400, epoch: 6 | loss: 0.6362131\n",
            "\tspeed: 0.0823s/iter; left time: 356.7256s\n",
            "\titers: 500, epoch: 6 | loss: 0.5319633\n",
            "\tspeed: 0.0824s/iter; left time: 348.8583s\n",
            "\titers: 600, epoch: 6 | loss: 0.7184582\n",
            "\tspeed: 0.0826s/iter; left time: 341.4891s\n",
            "\titers: 700, epoch: 6 | loss: 0.7401859\n",
            "\tspeed: 0.0828s/iter; left time: 334.0959s\n",
            "\titers: 800, epoch: 6 | loss: 0.6097718\n",
            "\tspeed: 0.0825s/iter; left time: 324.5778s\n",
            "\titers: 900, epoch: 6 | loss: 0.9236767\n",
            "\tspeed: 0.0822s/iter; left time: 315.4311s\n",
            "Epoch: 6 cost time: 78.25261306762695\n",
            "Epoch: 6, Steps: 947 | Train Loss: 0.6370229 Vali Loss: 0.6527363 Test Loss: 0.7499132\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_VIC_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4364\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "mse:0.7454962134361267, mae:0.47587621212005615, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_VIC_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_VIC_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.7455, MAE=0.4759\n",
            "âœ… å®Œæˆ | MAE: 0.4759 | ç”¨æ—¶: 9.6åˆ†é’Ÿ\n",
            "\n",
            "[10/20] ðŸš€ VIC | 30min | PatchTST\n",
            "--------------------------------------------------------------------------------\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_VIC_30min_PatchTSTModel:              PatchTST            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          VIC_30min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              5                   Num Kernels:        6                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            4                   e layers:           2                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         32                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            1                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_VIC_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15140\n",
            "val 2171\n",
            "test 4364\n",
            "\titers: 100, epoch: 1 | loss: 0.6291558\n",
            "\tspeed: 0.0283s/iter; left time: 131.3602s\n",
            "\titers: 200, epoch: 1 | loss: 0.6075740\n",
            "\tspeed: 0.0118s/iter; left time: 53.7077s\n",
            "\titers: 300, epoch: 1 | loss: 0.5723572\n",
            "\tspeed: 0.0119s/iter; left time: 52.8683s\n",
            "\titers: 400, epoch: 1 | loss: 0.9213294\n",
            "\tspeed: 0.0122s/iter; left time: 53.0588s\n",
            "Epoch: 1 cost time: 7.354566812515259\n",
            "Epoch: 1, Steps: 474 | Train Loss: 0.8280901 Vali Loss: 0.6952989 Test Loss: 0.7953961\n",
            "Validation loss decreased (inf --> 0.695299).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.5574943\n",
            "\tspeed: 0.0352s/iter; left time: 146.5291s\n",
            "\titers: 200, epoch: 2 | loss: 0.6916366\n",
            "\tspeed: 0.0129s/iter; left time: 52.4477s\n",
            "\titers: 300, epoch: 2 | loss: 0.6384847\n",
            "\tspeed: 0.0120s/iter; left time: 47.4112s\n",
            "\titers: 400, epoch: 2 | loss: 0.5904736\n",
            "\tspeed: 0.0173s/iter; left time: 66.9167s\n",
            "Epoch: 2 cost time: 6.621289968490601\n",
            "Epoch: 2, Steps: 474 | Train Loss: 0.7375333 Vali Loss: 0.7620318 Test Loss: 0.8600755\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.7503055\n",
            "\tspeed: 0.0374s/iter; left time: 138.1912s\n",
            "\titers: 200, epoch: 3 | loss: 0.6275261\n",
            "\tspeed: 0.0119s/iter; left time: 42.7969s\n",
            "\titers: 300, epoch: 3 | loss: 0.6731992\n",
            "\tspeed: 0.0119s/iter; left time: 41.6901s\n",
            "\titers: 400, epoch: 3 | loss: 0.8971357\n",
            "\tspeed: 0.0119s/iter; left time: 40.3387s\n",
            "Epoch: 3 cost time: 5.795636177062988\n",
            "Epoch: 3, Steps: 474 | Train Loss: 0.7009472 Vali Loss: 0.6625430 Test Loss: 0.7632087\n",
            "Validation loss decreased (0.695299 --> 0.662543).  Saving model ...\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.8274052\n",
            "\tspeed: 0.0365s/iter; left time: 117.3575s\n",
            "\titers: 200, epoch: 4 | loss: 0.5695842\n",
            "\tspeed: 0.0168s/iter; left time: 52.4858s\n",
            "\titers: 300, epoch: 4 | loss: 0.4911093\n",
            "\tspeed: 0.0128s/iter; left time: 38.7379s\n",
            "\titers: 400, epoch: 4 | loss: 0.4874497\n",
            "\tspeed: 0.0122s/iter; left time: 35.5620s\n",
            "Epoch: 4 cost time: 6.495100736618042\n",
            "Epoch: 4, Steps: 474 | Train Loss: 0.6947682 Vali Loss: 0.6580445 Test Loss: 0.7549015\n",
            "Validation loss decreased (0.662543 --> 0.658045).  Saving model ...\n",
            "Updating learning rate to 0.000125\n",
            "\titers: 100, epoch: 5 | loss: 1.0020170\n",
            "\tspeed: 0.0353s/iter; left time: 96.7621s\n",
            "\titers: 200, epoch: 5 | loss: 0.7462965\n",
            "\tspeed: 0.0120s/iter; left time: 31.6606s\n",
            "\titers: 300, epoch: 5 | loss: 0.5643337\n",
            "\tspeed: 0.0120s/iter; left time: 30.4415s\n",
            "\titers: 400, epoch: 5 | loss: 0.6377228\n",
            "\tspeed: 0.0122s/iter; left time: 29.8625s\n",
            "Epoch: 5 cost time: 5.967651605606079\n",
            "Epoch: 5, Steps: 474 | Train Loss: 0.6904812 Vali Loss: 0.6547574 Test Loss: 0.7540251\n",
            "Validation loss decreased (0.658045 --> 0.654757).  Saving model ...\n",
            "Updating learning rate to 6.25e-05\n",
            "\titers: 100, epoch: 6 | loss: 0.4694813\n",
            "\tspeed: 0.0428s/iter; left time: 97.2787s\n",
            "\titers: 200, epoch: 6 | loss: 0.4912721\n",
            "\tspeed: 0.0127s/iter; left time: 27.5606s\n",
            "\titers: 300, epoch: 6 | loss: 0.9558185\n",
            "\tspeed: 0.0118s/iter; left time: 24.5272s\n",
            "\titers: 400, epoch: 6 | loss: 0.7539603\n",
            "\tspeed: 0.0119s/iter; left time: 23.3909s\n",
            "Epoch: 6 cost time: 5.816346168518066\n",
            "Epoch: 6, Steps: 474 | Train Loss: 0.6882091 Vali Loss: 0.6559803 Test Loss: 0.7542644\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 3.125e-05\n",
            "\titers: 100, epoch: 7 | loss: 0.7276584\n",
            "\tspeed: 0.0343s/iter; left time: 61.7252s\n",
            "\titers: 200, epoch: 7 | loss: 0.7716594\n",
            "\tspeed: 0.0118s/iter; left time: 19.9964s\n",
            "\titers: 300, epoch: 7 | loss: 0.8358365\n",
            "\tspeed: 0.0156s/iter; left time: 24.9877s\n",
            "\titers: 400, epoch: 7 | loss: 0.9936884\n",
            "\tspeed: 0.0152s/iter; left time: 22.7201s\n",
            "Epoch: 7 cost time: 6.418241739273071\n",
            "Epoch: 7, Steps: 474 | Train Loss: 0.6875870 Vali Loss: 0.6550643 Test Loss: 0.7544079\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_VIC_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4364\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "mse:0.754492998123169, mae:0.4772300720214844, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_VIC_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_VIC_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.7545, MAE=0.4772\n",
            "âœ… å®Œæˆ | MAE: 0.4772 | ç”¨æ—¶: 1.0åˆ†é’Ÿ\n",
            "\n",
            "[11/20] ðŸš€ VIC | 15min | TimesNet\n",
            "--------------------------------------------------------------------------------\n",
            "  âš ï¸  TimesNetå…³é—­AMP (é¿å…cuFFT FP16é”™è¯¯)ï¼Œä½¿ç”¨FP32è®­ç»ƒ\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_VIC_15min_TimesNetModel:              TimesNet            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          VIC_15min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            384                 Label Len:          192                 \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              3                   Num Kernels:        4                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            8                   e layers:           1                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         16                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            0                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_VIC_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 11890\n",
            "val 1735\n",
            "test 3490\n",
            "\titers: 100, epoch: 1 | loss: 0.5257840\n",
            "\tspeed: 0.1856s/iter; left time: 1362.7260s\n",
            "\titers: 200, epoch: 1 | loss: 0.4491107\n",
            "\tspeed: 0.1709s/iter; left time: 1237.2717s\n",
            "\titers: 300, epoch: 1 | loss: 0.8424166\n",
            "\tspeed: 0.1571s/iter; left time: 1121.6441s\n",
            "\titers: 400, epoch: 1 | loss: 0.4793261\n",
            "\tspeed: 0.1442s/iter; left time: 1015.3976s\n",
            "\titers: 500, epoch: 1 | loss: 0.4436892\n",
            "\tspeed: 0.1523s/iter; left time: 1057.2849s\n",
            "\titers: 600, epoch: 1 | loss: 0.5525556\n",
            "\tspeed: 0.1493s/iter; left time: 1021.3501s\n",
            "\titers: 700, epoch: 1 | loss: 0.6364535\n",
            "\tspeed: 0.1488s/iter; left time: 1003.0670s\n",
            "Epoch: 1 cost time: 118.77359294891357\n",
            "Epoch: 1, Steps: 744 | Train Loss: 0.5577932 Vali Loss: 0.5130860 Test Loss: 0.4103364\n",
            "Validation loss decreased (inf --> 0.513086).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.5147142\n",
            "\tspeed: 0.4385s/iter; left time: 2892.5705s\n",
            "\titers: 200, epoch: 2 | loss: 0.3697414\n",
            "\tspeed: 0.1515s/iter; left time: 984.3874s\n",
            "\titers: 300, epoch: 2 | loss: 0.8452098\n",
            "\tspeed: 0.1563s/iter; left time: 1000.0860s\n",
            "\titers: 400, epoch: 2 | loss: 0.4984133\n",
            "\tspeed: 0.1530s/iter; left time: 963.1885s\n",
            "\titers: 500, epoch: 2 | loss: 0.7408282\n",
            "\tspeed: 0.1530s/iter; left time: 948.0086s\n",
            "\titers: 600, epoch: 2 | loss: 0.6378008\n",
            "\tspeed: 0.1531s/iter; left time: 933.4967s\n",
            "\titers: 700, epoch: 2 | loss: 0.6808782\n",
            "\tspeed: 0.1551s/iter; left time: 929.9919s\n",
            "Epoch: 2 cost time: 115.05863690376282\n",
            "Epoch: 2, Steps: 744 | Train Loss: 0.5389523 Vali Loss: 0.5156473 Test Loss: 0.4104695\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.6718962\n",
            "\tspeed: 0.4676s/iter; left time: 2736.9921s\n",
            "\titers: 200, epoch: 3 | loss: 0.5516879\n",
            "\tspeed: 0.1600s/iter; left time: 920.5709s\n",
            "\titers: 300, epoch: 3 | loss: 0.7526340\n",
            "\tspeed: 0.1577s/iter; left time: 891.4569s\n",
            "\titers: 400, epoch: 3 | loss: 0.6150983\n",
            "\tspeed: 0.1607s/iter; left time: 892.4844s\n",
            "\titers: 500, epoch: 3 | loss: 0.6386103\n",
            "\tspeed: 0.1598s/iter; left time: 871.5005s\n",
            "\titers: 600, epoch: 3 | loss: 0.6086969\n",
            "\tspeed: 0.1594s/iter; left time: 853.3780s\n",
            "\titers: 700, epoch: 3 | loss: 0.3738106\n",
            "\tspeed: 0.1529s/iter; left time: 802.9295s\n",
            "Epoch: 3 cost time: 118.61925673484802\n",
            "Epoch: 3, Steps: 744 | Train Loss: 0.5327947 Vali Loss: 0.5138555 Test Loss: 0.4094434\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_VIC_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 3490\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "mse:0.41071388125419617, mae:0.4080028235912323, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_VIC_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_VIC_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.4107, MAE=0.4080\n",
            "âœ… å®Œæˆ | MAE: 0.4080 | ç”¨æ—¶: 7.4åˆ†é’Ÿ\n",
            "\n",
            "[12/20] ðŸš€ VIC | 15min | PatchTST\n",
            "--------------------------------------------------------------------------------\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_VIC_15min_PatchTSTModel:              PatchTST            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          VIC_15min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            384                 Label Len:          192                 \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              5                   Num Kernels:        6                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            4                   e layers:           2                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         32                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            1                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_VIC_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 11890\n",
            "val 1735\n",
            "test 3490\n",
            "\titers: 100, epoch: 1 | loss: 0.8832759\n",
            "\tspeed: 0.0220s/iter; left time: 79.5127s\n",
            "\titers: 200, epoch: 1 | loss: 0.8484269\n",
            "\tspeed: 0.0124s/iter; left time: 43.5709s\n",
            "\titers: 300, epoch: 1 | loss: 0.9380663\n",
            "\tspeed: 0.0125s/iter; left time: 42.6268s\n",
            "Epoch: 1 cost time: 5.62398362159729\n",
            "Epoch: 1, Steps: 372 | Train Loss: 0.7932473 Vali Loss: 0.5335775 Test Loss: 0.4231358\n",
            "Validation loss decreased (inf --> 0.533577).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.7290397\n",
            "\tspeed: 0.0383s/iter; left time: 124.2970s\n",
            "\titers: 200, epoch: 2 | loss: 0.6696858\n",
            "\tspeed: 0.0154s/iter; left time: 48.5398s\n",
            "\titers: 300, epoch: 2 | loss: 0.5665349\n",
            "\tspeed: 0.0124s/iter; left time: 37.8043s\n",
            "Epoch: 2 cost time: 5.4415059089660645\n",
            "Epoch: 2, Steps: 372 | Train Loss: 0.6869355 Vali Loss: 0.5675722 Test Loss: 0.4507380\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.5825120\n",
            "\tspeed: 0.0341s/iter; left time: 98.0785s\n",
            "\titers: 200, epoch: 3 | loss: 0.4985041\n",
            "\tspeed: 0.0124s/iter; left time: 34.5222s\n",
            "\titers: 300, epoch: 3 | loss: 0.4652734\n",
            "\tspeed: 0.0124s/iter; left time: 33.2648s\n",
            "Epoch: 3 cost time: 4.725646257400513\n",
            "Epoch: 3, Steps: 372 | Train Loss: 0.6064120 Vali Loss: 0.5321378 Test Loss: 0.4155045\n",
            "Validation loss decreased (0.533577 --> 0.532138).  Saving model ...\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.7459116\n",
            "\tspeed: 0.0393s/iter; left time: 98.5154s\n",
            "\titers: 200, epoch: 4 | loss: 0.5408352\n",
            "\tspeed: 0.0142s/iter; left time: 34.0562s\n",
            "\titers: 300, epoch: 4 | loss: 0.4846202\n",
            "\tspeed: 0.0133s/iter; left time: 30.7258s\n",
            "Epoch: 4 cost time: 5.517603635787964\n",
            "Epoch: 4, Steps: 372 | Train Loss: 0.5887416 Vali Loss: 0.5176194 Test Loss: 0.4086730\n",
            "Validation loss decreased (0.532138 --> 0.517619).  Saving model ...\n",
            "Updating learning rate to 0.000125\n",
            "\titers: 100, epoch: 5 | loss: 0.5624055\n",
            "\tspeed: 0.0340s/iter; left time: 72.4546s\n",
            "\titers: 200, epoch: 5 | loss: 0.6497186\n",
            "\tspeed: 0.0124s/iter; left time: 25.2061s\n",
            "\titers: 300, epoch: 5 | loss: 0.4954686\n",
            "\tspeed: 0.0125s/iter; left time: 24.1992s\n",
            "Epoch: 5 cost time: 4.735376834869385\n",
            "Epoch: 5, Steps: 372 | Train Loss: 0.5831710 Vali Loss: 0.5256685 Test Loss: 0.4093297\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 6.25e-05\n",
            "\titers: 100, epoch: 6 | loss: 0.6520576\n",
            "\tspeed: 0.0405s/iter; left time: 71.2446s\n",
            "\titers: 200, epoch: 6 | loss: 0.7438310\n",
            "\tspeed: 0.0128s/iter; left time: 21.2871s\n",
            "\titers: 300, epoch: 6 | loss: 0.4388656\n",
            "\tspeed: 0.0125s/iter; left time: 19.4993s\n",
            "Epoch: 6 cost time: 5.350149631500244\n",
            "Epoch: 6, Steps: 372 | Train Loss: 0.5793823 Vali Loss: 0.5235929 Test Loss: 0.4110352\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_VIC_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 3490\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "mse:0.4096045196056366, mae:0.4056917726993561, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_VIC_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_VIC_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.4096, MAE=0.4057\n",
            "âœ… å®Œæˆ | MAE: 0.4057 | ç”¨æ—¶: 0.8åˆ†é’Ÿ\n",
            "\n",
            "[13/20] ðŸš€ SA | 30min | TimesNet\n",
            "--------------------------------------------------------------------------------\n",
            "  âš ï¸  TimesNetå…³é—­AMP (é¿å…cuFFT FP16é”™è¯¯)ï¼Œä½¿ç”¨FP32è®­ç»ƒ\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_SA_30min_TimesNetModel:              TimesNet            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          SA_30min.csv        Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              3                   Num Kernels:        4                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            8                   e layers:           1                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         16                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            0                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_SA_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15140\n",
            "val 2171\n",
            "test 4364\n",
            "\titers: 100, epoch: 1 | loss: 1.0481727\n",
            "\tspeed: 0.0943s/iter; left time: 884.1457s\n",
            "\titers: 200, epoch: 1 | loss: 0.7710081\n",
            "\tspeed: 0.0901s/iter; left time: 835.7212s\n",
            "\titers: 300, epoch: 1 | loss: 0.4403580\n",
            "\tspeed: 0.0957s/iter; left time: 877.3809s\n",
            "\titers: 400, epoch: 1 | loss: 0.7091135\n",
            "\tspeed: 0.1008s/iter; left time: 914.7087s\n",
            "\titers: 500, epoch: 1 | loss: 0.5236481\n",
            "\tspeed: 0.0989s/iter; left time: 886.7876s\n",
            "\titers: 600, epoch: 1 | loss: 0.4923331\n",
            "\tspeed: 0.0958s/iter; left time: 850.1027s\n",
            "\titers: 700, epoch: 1 | loss: 0.8960114\n",
            "\tspeed: 0.0932s/iter; left time: 817.6926s\n",
            "\titers: 800, epoch: 1 | loss: 0.4117306\n",
            "\tspeed: 0.0893s/iter; left time: 774.0454s\n",
            "\titers: 900, epoch: 1 | loss: 0.6374170\n",
            "\tspeed: 0.0921s/iter; left time: 789.3819s\n",
            "Epoch: 1 cost time: 89.5898928642273\n",
            "Epoch: 1, Steps: 947 | Train Loss: 0.6848042 Vali Loss: 0.4975977 Test Loss: 0.6978753\n",
            "Validation loss decreased (inf --> 0.497598).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.4139673\n",
            "\tspeed: 0.3200s/iter; left time: 2695.8541s\n",
            "\titers: 200, epoch: 2 | loss: 0.4909515\n",
            "\tspeed: 0.0929s/iter; left time: 773.5098s\n",
            "\titers: 300, epoch: 2 | loss: 0.5763419\n",
            "\tspeed: 0.0891s/iter; left time: 733.1003s\n",
            "\titers: 400, epoch: 2 | loss: 0.3261735\n",
            "\tspeed: 0.0898s/iter; left time: 729.2640s\n",
            "\titers: 500, epoch: 2 | loss: 0.5091817\n",
            "\tspeed: 0.0870s/iter; left time: 698.4792s\n",
            "\titers: 600, epoch: 2 | loss: 1.0512713\n",
            "\tspeed: 0.0875s/iter; left time: 693.0442s\n",
            "\titers: 700, epoch: 2 | loss: 0.5826251\n",
            "\tspeed: 0.0919s/iter; left time: 719.3524s\n",
            "\titers: 800, epoch: 2 | loss: 0.8738584\n",
            "\tspeed: 0.0903s/iter; left time: 697.2139s\n",
            "\titers: 900, epoch: 2 | loss: 0.4256022\n",
            "\tspeed: 0.0864s/iter; left time: 658.3653s\n",
            "Epoch: 2 cost time: 84.77384996414185\n",
            "Epoch: 2, Steps: 947 | Train Loss: 0.6619159 Vali Loss: 0.4877309 Test Loss: 0.6859706\n",
            "Validation loss decreased (0.497598 --> 0.487731).  Saving model ...\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.5160171\n",
            "\tspeed: 0.2986s/iter; left time: 2232.7280s\n",
            "\titers: 200, epoch: 3 | loss: 0.6459520\n",
            "\tspeed: 0.0876s/iter; left time: 646.1244s\n",
            "\titers: 300, epoch: 3 | loss: 0.3803503\n",
            "\tspeed: 0.0856s/iter; left time: 622.6693s\n",
            "\titers: 400, epoch: 3 | loss: 0.4952408\n",
            "\tspeed: 0.0870s/iter; left time: 624.0579s\n",
            "\titers: 500, epoch: 3 | loss: 0.7042315\n",
            "\tspeed: 0.0877s/iter; left time: 620.5147s\n",
            "\titers: 600, epoch: 3 | loss: 0.5521548\n",
            "\tspeed: 0.0880s/iter; left time: 613.8185s\n",
            "\titers: 700, epoch: 3 | loss: 0.7344654\n",
            "\tspeed: 0.0881s/iter; left time: 605.7337s\n",
            "\titers: 800, epoch: 3 | loss: 0.4225049\n",
            "\tspeed: 0.0900s/iter; left time: 609.6645s\n",
            "\titers: 900, epoch: 3 | loss: 0.5560730\n",
            "\tspeed: 0.0893s/iter; left time: 596.1708s\n",
            "Epoch: 3 cost time: 83.52949523925781\n",
            "Epoch: 3, Steps: 947 | Train Loss: 0.6544822 Vali Loss: 0.4916894 Test Loss: 0.6853012\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.8592821\n",
            "\tspeed: 0.3031s/iter; left time: 1979.2926s\n",
            "\titers: 200, epoch: 4 | loss: 1.0308951\n",
            "\tspeed: 0.0903s/iter; left time: 580.3835s\n",
            "\titers: 300, epoch: 4 | loss: 0.8805972\n",
            "\tspeed: 0.0861s/iter; left time: 544.7640s\n",
            "\titers: 400, epoch: 4 | loss: 0.6456084\n",
            "\tspeed: 0.0867s/iter; left time: 540.0493s\n",
            "\titers: 500, epoch: 4 | loss: 0.6529049\n",
            "\tspeed: 0.0896s/iter; left time: 549.4063s\n",
            "\titers: 600, epoch: 4 | loss: 0.7239377\n",
            "\tspeed: 0.0892s/iter; left time: 538.0041s\n",
            "\titers: 700, epoch: 4 | loss: 0.7248690\n",
            "\tspeed: 0.0842s/iter; left time: 499.5402s\n",
            "\titers: 800, epoch: 4 | loss: 0.7146304\n",
            "\tspeed: 0.0885s/iter; left time: 515.7390s\n",
            "\titers: 900, epoch: 4 | loss: 0.5922862\n",
            "\tspeed: 0.0896s/iter; left time: 513.1681s\n",
            "Epoch: 4 cost time: 84.35797929763794\n",
            "Epoch: 4, Steps: 947 | Train Loss: 0.6492260 Vali Loss: 0.4931761 Test Loss: 0.6855642\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_SA_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4364\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "mse:0.6862038969993591, mae:0.44797372817993164, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_SA_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_SA_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.6862, MAE=0.4480\n",
            "âœ… å®Œæˆ | MAE: 0.4480 | ç”¨æ—¶: 7.2åˆ†é’Ÿ\n",
            "\n",
            "[14/20] ðŸš€ SA | 30min | PatchTST\n",
            "--------------------------------------------------------------------------------\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_SA_30min_PatchTSTModel:              PatchTST            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          SA_30min.csv        Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              5                   Num Kernels:        6                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            4                   e layers:           2                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         32                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            1                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_SA_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15140\n",
            "val 2171\n",
            "test 4364\n",
            "\titers: 100, epoch: 1 | loss: 0.8938267\n",
            "\tspeed: 0.0219s/iter; left time: 101.7064s\n",
            "\titers: 200, epoch: 1 | loss: 0.7484723\n",
            "\tspeed: 0.0120s/iter; left time: 54.4069s\n",
            "\titers: 300, epoch: 1 | loss: 0.9847490\n",
            "\tspeed: 0.0117s/iter; left time: 52.0212s\n",
            "\titers: 400, epoch: 1 | loss: 1.0398964\n",
            "\tspeed: 0.0150s/iter; left time: 64.9838s\n",
            "Epoch: 1 cost time: 7.39290452003479\n",
            "Epoch: 1, Steps: 474 | Train Loss: 0.8327862 Vali Loss: 0.5191633 Test Loss: 0.7192679\n",
            "Validation loss decreased (inf --> 0.519163).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.6260517\n",
            "\tspeed: 0.0390s/iter; left time: 162.3609s\n",
            "\titers: 200, epoch: 2 | loss: 0.6577675\n",
            "\tspeed: 0.0118s/iter; left time: 48.0169s\n",
            "\titers: 300, epoch: 2 | loss: 0.8811281\n",
            "\tspeed: 0.0119s/iter; left time: 47.2378s\n",
            "\titers: 400, epoch: 2 | loss: 0.8279282\n",
            "\tspeed: 0.0120s/iter; left time: 46.5695s\n",
            "Epoch: 2 cost time: 5.7533440589904785\n",
            "Epoch: 2, Steps: 474 | Train Loss: 0.7357711 Vali Loss: 0.5605809 Test Loss: 0.7711073\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.9451919\n",
            "\tspeed: 0.0351s/iter; left time: 129.4840s\n",
            "\titers: 200, epoch: 3 | loss: 0.5743068\n",
            "\tspeed: 0.0159s/iter; left time: 56.9892s\n",
            "\titers: 300, epoch: 3 | loss: 0.5472028\n",
            "\tspeed: 0.0152s/iter; left time: 53.0962s\n",
            "\titers: 400, epoch: 3 | loss: 0.6357971\n",
            "\tspeed: 0.0120s/iter; left time: 40.5483s\n",
            "Epoch: 3 cost time: 6.509138822555542\n",
            "Epoch: 3, Steps: 474 | Train Loss: 0.6984938 Vali Loss: 0.5035692 Test Loss: 0.7007008\n",
            "Validation loss decreased (0.519163 --> 0.503569).  Saving model ...\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.5373618\n",
            "\tspeed: 0.0354s/iter; left time: 113.9203s\n",
            "\titers: 200, epoch: 4 | loss: 0.8106908\n",
            "\tspeed: 0.0119s/iter; left time: 37.1172s\n",
            "\titers: 300, epoch: 4 | loss: 0.5769361\n",
            "\tspeed: 0.0119s/iter; left time: 35.9343s\n",
            "\titers: 400, epoch: 4 | loss: 0.4161735\n",
            "\tspeed: 0.0119s/iter; left time: 34.6082s\n",
            "Epoch: 4 cost time: 5.762166738510132\n",
            "Epoch: 4, Steps: 474 | Train Loss: 0.6942594 Vali Loss: 0.5013273 Test Loss: 0.6973082\n",
            "Validation loss decreased (0.503569 --> 0.501327).  Saving model ...\n",
            "Updating learning rate to 0.000125\n",
            "\titers: 100, epoch: 5 | loss: 0.9721665\n",
            "\tspeed: 0.0433s/iter; left time: 118.8093s\n",
            "\titers: 200, epoch: 5 | loss: 0.8132781\n",
            "\tspeed: 0.0122s/iter; left time: 32.2821s\n",
            "\titers: 300, epoch: 5 | loss: 0.4869266\n",
            "\tspeed: 0.0120s/iter; left time: 30.6211s\n",
            "\titers: 400, epoch: 5 | loss: 0.6385915\n",
            "\tspeed: 0.0119s/iter; left time: 29.2122s\n",
            "Epoch: 5 cost time: 6.075756311416626\n",
            "Epoch: 5, Steps: 474 | Train Loss: 0.6917379 Vali Loss: 0.4985974 Test Loss: 0.6950191\n",
            "Validation loss decreased (0.501327 --> 0.498597).  Saving model ...\n",
            "Updating learning rate to 6.25e-05\n",
            "\titers: 100, epoch: 6 | loss: 0.5195424\n",
            "\tspeed: 0.0351s/iter; left time: 79.8217s\n",
            "\titers: 200, epoch: 6 | loss: 0.6928685\n",
            "\tspeed: 0.0120s/iter; left time: 25.9914s\n",
            "\titers: 300, epoch: 6 | loss: 0.8221325\n",
            "\tspeed: 0.0145s/iter; left time: 30.0628s\n",
            "\titers: 400, epoch: 6 | loss: 0.7350601\n",
            "\tspeed: 0.0168s/iter; left time: 33.1719s\n",
            "Epoch: 6 cost time: 6.525654077529907\n",
            "Epoch: 6, Steps: 474 | Train Loss: 0.6877620 Vali Loss: 0.4997698 Test Loss: 0.6956680\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 3.125e-05\n",
            "\titers: 100, epoch: 7 | loss: 0.7625011\n",
            "\tspeed: 0.0348s/iter; left time: 62.5777s\n",
            "\titers: 200, epoch: 7 | loss: 0.3894763\n",
            "\tspeed: 0.0118s/iter; left time: 20.0773s\n",
            "\titers: 300, epoch: 7 | loss: 0.5293640\n",
            "\tspeed: 0.0119s/iter; left time: 18.9999s\n",
            "\titers: 400, epoch: 7 | loss: 0.6427903\n",
            "\tspeed: 0.0120s/iter; left time: 17.9116s\n",
            "Epoch: 7 cost time: 5.741791248321533\n",
            "Epoch: 7, Steps: 474 | Train Loss: 0.6870089 Vali Loss: 0.4993586 Test Loss: 0.6962607\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_SA_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4364\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "mse:0.6964569091796875, mae:0.4583885967731476, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_SA_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_SA_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.6965, MAE=0.4584\n",
            "âœ… å®Œæˆ | MAE: 0.4584 | ç”¨æ—¶: 1.0åˆ†é’Ÿ\n",
            "\n",
            "[15/20] ðŸš€ SA | 15min | TimesNet\n",
            "--------------------------------------------------------------------------------\n",
            "  âš ï¸  TimesNetå…³é—­AMP (é¿å…cuFFT FP16é”™è¯¯)ï¼Œä½¿ç”¨FP32è®­ç»ƒ\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_SA_15min_TimesNetModel:              TimesNet            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          SA_15min.csv        Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            384                 Label Len:          192                 \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              3                   Num Kernels:        4                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            8                   e layers:           1                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         16                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            0                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_SA_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 11890\n",
            "val 1735\n",
            "test 3490\n",
            "\titers: 100, epoch: 1 | loss: 0.4606945\n",
            "\tspeed: 0.1333s/iter; left time: 978.6802s\n",
            "\titers: 200, epoch: 1 | loss: 0.4614888\n",
            "\tspeed: 0.1202s/iter; left time: 870.5015s\n",
            "\titers: 300, epoch: 1 | loss: 0.7915195\n",
            "\tspeed: 0.1194s/iter; left time: 852.4646s\n",
            "\titers: 400, epoch: 1 | loss: 0.7500834\n",
            "\tspeed: 0.1185s/iter; left time: 834.3870s\n",
            "\titers: 500, epoch: 1 | loss: 0.7576807\n",
            "\tspeed: 0.1170s/iter; left time: 811.9084s\n",
            "\titers: 600, epoch: 1 | loss: 0.4773708\n",
            "\tspeed: 0.1228s/iter; left time: 840.1199s\n",
            "\titers: 700, epoch: 1 | loss: 0.5833448\n",
            "\tspeed: 0.1273s/iter; left time: 858.4253s\n",
            "Epoch: 1 cost time: 93.39720344543457\n",
            "Epoch: 1, Steps: 744 | Train Loss: 0.5572081 Vali Loss: 0.4753279 Test Loss: 0.5155632\n",
            "Validation loss decreased (inf --> 0.475328).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.4811563\n",
            "\tspeed: 0.4110s/iter; left time: 2711.5985s\n",
            "\titers: 200, epoch: 2 | loss: 0.6218247\n",
            "\tspeed: 0.1518s/iter; left time: 986.2853s\n",
            "\titers: 300, epoch: 2 | loss: 0.5904057\n",
            "\tspeed: 0.1538s/iter; left time: 984.0905s\n",
            "\titers: 400, epoch: 2 | loss: 0.4669722\n",
            "\tspeed: 0.1558s/iter; left time: 981.1010s\n",
            "\titers: 500, epoch: 2 | loss: 0.4631123\n",
            "\tspeed: 0.1601s/iter; left time: 991.9243s\n",
            "\titers: 600, epoch: 2 | loss: 0.7088280\n",
            "\tspeed: 0.1652s/iter; left time: 1007.5148s\n",
            "\titers: 700, epoch: 2 | loss: 0.5990682\n",
            "\tspeed: 0.1694s/iter; left time: 1015.6999s\n",
            "Epoch: 2 cost time: 118.86904239654541\n",
            "Epoch: 2, Steps: 744 | Train Loss: 0.5366122 Vali Loss: 0.4723045 Test Loss: 0.5147012\n",
            "Validation loss decreased (0.475328 --> 0.472305).  Saving model ...\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.6263403\n",
            "\tspeed: 0.5013s/iter; left time: 2934.0245s\n",
            "\titers: 200, epoch: 3 | loss: 0.5662029\n",
            "\tspeed: 0.1732s/iter; left time: 996.6247s\n",
            "\titers: 300, epoch: 3 | loss: 0.5027451\n",
            "\tspeed: 0.1707s/iter; left time: 965.1469s\n",
            "\titers: 400, epoch: 3 | loss: 0.7466304\n",
            "\tspeed: 0.1769s/iter; left time: 982.0542s\n",
            "\titers: 500, epoch: 3 | loss: 0.4785063\n",
            "\tspeed: 0.1761s/iter; left time: 960.1081s\n",
            "\titers: 600, epoch: 3 | loss: 0.4222043\n",
            "\tspeed: 0.1761s/iter; left time: 942.5961s\n",
            "\titers: 700, epoch: 3 | loss: 0.4209901\n",
            "\tspeed: 0.1754s/iter; left time: 921.2177s\n",
            "Epoch: 3 cost time: 130.41145038604736\n",
            "Epoch: 3, Steps: 744 | Train Loss: 0.5312740 Vali Loss: 0.4724607 Test Loss: 0.5149166\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.4841701\n",
            "\tspeed: 0.5154s/iter; left time: 2633.1862s\n",
            "\titers: 200, epoch: 4 | loss: 0.5358264\n",
            "\tspeed: 0.1766s/iter; left time: 884.7509s\n",
            "\titers: 300, epoch: 4 | loss: 0.5248803\n",
            "\tspeed: 0.1772s/iter; left time: 869.7810s\n",
            "\titers: 400, epoch: 4 | loss: 0.4541674\n",
            "\tspeed: 0.1760s/iter; left time: 846.5020s\n",
            "\titers: 500, epoch: 4 | loss: 0.4915276\n",
            "\tspeed: 0.1776s/iter; left time: 836.3931s\n",
            "\titers: 600, epoch: 4 | loss: 0.6877200\n",
            "\tspeed: 0.1759s/iter; left time: 810.7158s\n",
            "\titers: 700, epoch: 4 | loss: 0.6949633\n",
            "\tspeed: 0.1761s/iter; left time: 794.0327s\n",
            "Epoch: 4 cost time: 131.88104152679443\n",
            "Epoch: 4, Steps: 744 | Train Loss: 0.5285536 Vali Loss: 0.4748110 Test Loss: 0.5175500\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_SA_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 3490\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "mse:0.5159779191017151, mae:0.4520266652107239, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_SA_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_SA_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.5160, MAE=0.4520\n",
            "âœ… å®Œæˆ | MAE: 0.4520 | ç”¨æ—¶: 9.9åˆ†é’Ÿ\n",
            "\n",
            "[16/20] ðŸš€ SA | 15min | PatchTST\n",
            "--------------------------------------------------------------------------------\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_SA_15min_PatchTSTModel:              PatchTST            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          SA_15min.csv        Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            384                 Label Len:          192                 \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              5                   Num Kernels:        6                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            4                   e layers:           2                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         32                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            1                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_SA_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 11890\n",
            "val 1735\n",
            "test 3490\n",
            "\titers: 100, epoch: 1 | loss: 0.8319359\n",
            "\tspeed: 0.0217s/iter; left time: 78.4782s\n",
            "\titers: 200, epoch: 1 | loss: 0.6780115\n",
            "\tspeed: 0.0124s/iter; left time: 43.8363s\n",
            "\titers: 300, epoch: 1 | loss: 0.7964711\n",
            "\tspeed: 0.0124s/iter; left time: 42.3838s\n",
            "Epoch: 1 cost time: 5.570145845413208\n",
            "Epoch: 1, Steps: 372 | Train Loss: 0.7914515 Vali Loss: 0.4882589 Test Loss: 0.5211700\n",
            "Validation loss decreased (inf --> 0.488259).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.7334224\n",
            "\tspeed: 0.0379s/iter; left time: 123.2395s\n",
            "\titers: 200, epoch: 2 | loss: 0.6783458\n",
            "\tspeed: 0.0156s/iter; left time: 49.2803s\n",
            "\titers: 300, epoch: 2 | loss: 0.6917980\n",
            "\tspeed: 0.0125s/iter; left time: 38.1728s\n",
            "Epoch: 2 cost time: 5.468201398849487\n",
            "Epoch: 2, Steps: 372 | Train Loss: 0.6846296 Vali Loss: 0.5867100 Test Loss: 0.6223561\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.5002949\n",
            "\tspeed: 0.0338s/iter; left time: 97.2893s\n",
            "\titers: 200, epoch: 3 | loss: 0.5039856\n",
            "\tspeed: 0.0130s/iter; left time: 36.1884s\n",
            "\titers: 300, epoch: 3 | loss: 0.5853206\n",
            "\tspeed: 0.0127s/iter; left time: 33.9840s\n",
            "Epoch: 3 cost time: 4.806284666061401\n",
            "Epoch: 3, Steps: 372 | Train Loss: 0.6048087 Vali Loss: 0.4868951 Test Loss: 0.5209972\n",
            "Validation loss decreased (0.488259 --> 0.486895).  Saving model ...\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.6589274\n",
            "\tspeed: 0.0401s/iter; left time: 100.4661s\n",
            "\titers: 200, epoch: 4 | loss: 0.5954820\n",
            "\tspeed: 0.0137s/iter; left time: 33.0481s\n",
            "\titers: 300, epoch: 4 | loss: 0.6213046\n",
            "\tspeed: 0.0125s/iter; left time: 28.8334s\n",
            "Epoch: 4 cost time: 5.477488040924072\n",
            "Epoch: 4, Steps: 372 | Train Loss: 0.5890558 Vali Loss: 0.4836399 Test Loss: 0.5071779\n",
            "Validation loss decreased (0.486895 --> 0.483640).  Saving model ...\n",
            "Updating learning rate to 0.000125\n",
            "\titers: 100, epoch: 5 | loss: 0.6468139\n",
            "\tspeed: 0.0343s/iter; left time: 73.2256s\n",
            "\titers: 200, epoch: 5 | loss: 0.4987267\n",
            "\tspeed: 0.0128s/iter; left time: 26.0641s\n",
            "\titers: 300, epoch: 5 | loss: 0.5143559\n",
            "\tspeed: 0.0125s/iter; left time: 24.1359s\n",
            "Epoch: 5 cost time: 4.786390781402588\n",
            "Epoch: 5, Steps: 372 | Train Loss: 0.5840543 Vali Loss: 0.4734134 Test Loss: 0.5061071\n",
            "Validation loss decreased (0.483640 --> 0.473413).  Saving model ...\n",
            "Updating learning rate to 6.25e-05\n",
            "\titers: 100, epoch: 6 | loss: 0.5996549\n",
            "\tspeed: 0.0417s/iter; left time: 73.3812s\n",
            "\titers: 200, epoch: 6 | loss: 0.5621154\n",
            "\tspeed: 0.0124s/iter; left time: 20.5547s\n",
            "\titers: 300, epoch: 6 | loss: 0.6934638\n",
            "\tspeed: 0.0124s/iter; left time: 19.3921s\n",
            "Epoch: 6 cost time: 5.289482593536377\n",
            "Epoch: 6, Steps: 372 | Train Loss: 0.5797502 Vali Loss: 0.4757351 Test Loss: 0.5071380\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 3.125e-05\n",
            "\titers: 100, epoch: 7 | loss: 0.5615500\n",
            "\tspeed: 0.0342s/iter; left time: 47.4821s\n",
            "\titers: 200, epoch: 7 | loss: 0.6920157\n",
            "\tspeed: 0.0127s/iter; left time: 16.4253s\n",
            "\titers: 300, epoch: 7 | loss: 0.5115260\n",
            "\tspeed: 0.0124s/iter; left time: 14.7711s\n",
            "Epoch: 7 cost time: 4.7819437980651855\n",
            "Epoch: 7, Steps: 372 | Train Loss: 0.5782451 Vali Loss: 0.4767789 Test Loss: 0.5097252\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_SA_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 3490\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "mse:0.5087738633155823, mae:0.4351261854171753, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_SA_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_SA_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.5088, MAE=0.4351\n",
            "âœ… å®Œæˆ | MAE: 0.4351 | ç”¨æ—¶: 0.9åˆ†é’Ÿ\n",
            "\n",
            "[17/20] ðŸš€ TAS | 30min | TimesNet\n",
            "--------------------------------------------------------------------------------\n",
            "  âš ï¸  TimesNetå…³é—­AMP (é¿å…cuFFT FP16é”™è¯¯)ï¼Œä½¿ç”¨FP32è®­ç»ƒ\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_TAS_30min_TimesNetModel:              TimesNet            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          TAS_30min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              3                   Num Kernels:        4                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            8                   e layers:           1                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         16                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            0                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_TAS_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15140\n",
            "val 2171\n",
            "test 4364\n",
            "\titers: 100, epoch: 1 | loss: 0.7523901\n",
            "\tspeed: 0.1009s/iter; left time: 945.0803s\n",
            "\titers: 200, epoch: 1 | loss: 0.5913188\n",
            "\tspeed: 0.0992s/iter; left time: 920.1105s\n",
            "\titers: 300, epoch: 1 | loss: 0.5518274\n",
            "\tspeed: 0.0998s/iter; left time: 915.1531s\n",
            "\titers: 400, epoch: 1 | loss: 0.5875056\n",
            "\tspeed: 0.0974s/iter; left time: 883.7162s\n",
            "\titers: 500, epoch: 1 | loss: 0.6300780\n",
            "\tspeed: 0.0809s/iter; left time: 725.6481s\n",
            "\titers: 600, epoch: 1 | loss: 0.5907685\n",
            "\tspeed: 0.0796s/iter; left time: 705.7939s\n",
            "\titers: 700, epoch: 1 | loss: 0.6859160\n",
            "\tspeed: 0.0786s/iter; left time: 689.5884s\n",
            "\titers: 800, epoch: 1 | loss: 0.6948103\n",
            "\tspeed: 0.0781s/iter; left time: 676.8256s\n",
            "\titers: 900, epoch: 1 | loss: 0.6683190\n",
            "\tspeed: 0.0779s/iter; left time: 667.8286s\n",
            "Epoch: 1 cost time: 83.36582827568054\n",
            "Epoch: 1, Steps: 947 | Train Loss: 0.6893648 Vali Loss: 0.5462651 Test Loss: 1.0033459\n",
            "Validation loss decreased (inf --> 0.546265).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.6204028\n",
            "\tspeed: 0.2530s/iter; left time: 2131.3580s\n",
            "\titers: 200, epoch: 2 | loss: 0.3895605\n",
            "\tspeed: 0.0779s/iter; left time: 648.8547s\n",
            "\titers: 300, epoch: 2 | loss: 0.4703654\n",
            "\tspeed: 0.0784s/iter; left time: 644.3569s\n",
            "\titers: 400, epoch: 2 | loss: 1.2363238\n",
            "\tspeed: 0.0784s/iter; left time: 637.0261s\n",
            "\titers: 500, epoch: 2 | loss: 0.5563818\n",
            "\tspeed: 0.0780s/iter; left time: 625.7547s\n",
            "\titers: 600, epoch: 2 | loss: 0.5664856\n",
            "\tspeed: 0.0780s/iter; left time: 618.1018s\n",
            "\titers: 700, epoch: 2 | loss: 0.9746131\n",
            "\tspeed: 0.0778s/iter; left time: 608.8310s\n",
            "\titers: 800, epoch: 2 | loss: 0.8948953\n",
            "\tspeed: 0.0777s/iter; left time: 600.3536s\n",
            "\titers: 900, epoch: 2 | loss: 0.5329717\n",
            "\tspeed: 0.0778s/iter; left time: 593.3291s\n",
            "Epoch: 2 cost time: 74.32949209213257\n",
            "Epoch: 2, Steps: 947 | Train Loss: 0.6657073 Vali Loss: 0.5321029 Test Loss: 0.9851734\n",
            "Validation loss decreased (0.546265 --> 0.532103).  Saving model ...\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.4009136\n",
            "\tspeed: 0.2506s/iter; left time: 1873.5785s\n",
            "\titers: 200, epoch: 3 | loss: 0.7049162\n",
            "\tspeed: 0.0779s/iter; left time: 574.8783s\n",
            "\titers: 300, epoch: 3 | loss: 0.5907055\n",
            "\tspeed: 0.0779s/iter; left time: 566.7738s\n",
            "\titers: 400, epoch: 3 | loss: 0.4403365\n",
            "\tspeed: 0.0779s/iter; left time: 559.0958s\n",
            "\titers: 500, epoch: 3 | loss: 0.4379657\n",
            "\tspeed: 0.0778s/iter; left time: 550.6528s\n",
            "\titers: 600, epoch: 3 | loss: 0.7810743\n",
            "\tspeed: 0.0781s/iter; left time: 544.9976s\n",
            "\titers: 700, epoch: 3 | loss: 0.4117867\n",
            "\tspeed: 0.0783s/iter; left time: 538.8014s\n",
            "\titers: 800, epoch: 3 | loss: 0.7755855\n",
            "\tspeed: 0.0782s/iter; left time: 530.0641s\n",
            "\titers: 900, epoch: 3 | loss: 0.8041701\n",
            "\tspeed: 0.0783s/iter; left time: 522.7066s\n",
            "Epoch: 3 cost time: 74.40548157691956\n",
            "Epoch: 3, Steps: 947 | Train Loss: 0.6589216 Vali Loss: 0.5366022 Test Loss: 0.9834344\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.5646250\n",
            "\tspeed: 0.2516s/iter; left time: 1642.9365s\n",
            "\titers: 200, epoch: 4 | loss: 0.7563887\n",
            "\tspeed: 0.0780s/iter; left time: 501.5571s\n",
            "\titers: 300, epoch: 4 | loss: 0.5311513\n",
            "\tspeed: 0.0778s/iter; left time: 492.7375s\n",
            "\titers: 400, epoch: 4 | loss: 0.7794939\n",
            "\tspeed: 0.0779s/iter; left time: 485.3952s\n",
            "\titers: 500, epoch: 4 | loss: 0.4865369\n",
            "\tspeed: 0.0780s/iter; left time: 478.1500s\n",
            "\titers: 600, epoch: 4 | loss: 0.8136169\n",
            "\tspeed: 0.0777s/iter; left time: 468.4946s\n",
            "\titers: 700, epoch: 4 | loss: 0.4544258\n",
            "\tspeed: 0.0779s/iter; left time: 461.8212s\n",
            "\titers: 800, epoch: 4 | loss: 0.5679946\n",
            "\tspeed: 0.0781s/iter; left time: 455.0442s\n",
            "\titers: 900, epoch: 4 | loss: 0.6845917\n",
            "\tspeed: 0.0777s/iter; left time: 445.0699s\n",
            "Epoch: 4 cost time: 74.27846598625183\n",
            "Epoch: 4, Steps: 947 | Train Loss: 0.6521754 Vali Loss: 0.5366545 Test Loss: 0.9931814\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_TAS_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4364\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "mse:0.9839499592781067, mae:0.49909868836402893, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_TAS_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_TAS_30min_TimesNet_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.9839, MAE=0.4991\n",
            "âœ… å®Œæˆ | MAE: 0.4991 | ç”¨æ—¶: 6.3åˆ†é’Ÿ\n",
            "\n",
            "[18/20] ðŸš€ TAS | 30min | PatchTST\n",
            "--------------------------------------------------------------------------------\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_TAS_30min_PatchTSTModel:              PatchTST            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          TAS_30min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              5                   Num Kernels:        6                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            4                   e layers:           2                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         32                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            1                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_TAS_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15140\n",
            "val 2171\n",
            "test 4364\n",
            "\titers: 100, epoch: 1 | loss: 0.8212943\n",
            "\tspeed: 0.0211s/iter; left time: 98.0828s\n",
            "\titers: 200, epoch: 1 | loss: 0.8388217\n",
            "\tspeed: 0.0119s/iter; left time: 53.9847s\n",
            "\titers: 300, epoch: 1 | loss: 0.8139169\n",
            "\tspeed: 0.0120s/iter; left time: 53.1718s\n",
            "\titers: 400, epoch: 1 | loss: 0.9082974\n",
            "\tspeed: 0.0154s/iter; left time: 66.9011s\n",
            "Epoch: 1 cost time: 7.377047300338745\n",
            "Epoch: 1, Steps: 474 | Train Loss: 0.8313824 Vali Loss: 0.5840738 Test Loss: 1.0530438\n",
            "Validation loss decreased (inf --> 0.584074).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.6745852\n",
            "\tspeed: 0.0392s/iter; left time: 163.2817s\n",
            "\titers: 200, epoch: 2 | loss: 0.9456739\n",
            "\tspeed: 0.0120s/iter; left time: 48.9889s\n",
            "\titers: 300, epoch: 2 | loss: 0.6028655\n",
            "\tspeed: 0.0119s/iter; left time: 47.1257s\n",
            "\titers: 400, epoch: 2 | loss: 0.8532612\n",
            "\tspeed: 0.0129s/iter; left time: 49.9721s\n",
            "Epoch: 2 cost time: 5.874521017074585\n",
            "Epoch: 2, Steps: 474 | Train Loss: 0.7386140 Vali Loss: 0.5659210 Test Loss: 1.0318139\n",
            "Validation loss decreased (0.584074 --> 0.565921).  Saving model ...\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.5983123\n",
            "\tspeed: 0.0357s/iter; left time: 131.9861s\n",
            "\titers: 200, epoch: 3 | loss: 0.6818002\n",
            "\tspeed: 0.0175s/iter; left time: 62.8465s\n",
            "\titers: 300, epoch: 3 | loss: 0.8094141\n",
            "\tspeed: 0.0138s/iter; left time: 48.3426s\n",
            "\titers: 400, epoch: 3 | loss: 0.6793096\n",
            "\tspeed: 0.0118s/iter; left time: 40.1707s\n",
            "Epoch: 3 cost time: 6.558797359466553\n",
            "Epoch: 3, Steps: 474 | Train Loss: 0.7029346 Vali Loss: 0.5495353 Test Loss: 0.9985996\n",
            "Validation loss decreased (0.565921 --> 0.549535).  Saving model ...\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.5724742\n",
            "\tspeed: 0.0349s/iter; left time: 112.3885s\n",
            "\titers: 200, epoch: 4 | loss: 0.5033380\n",
            "\tspeed: 0.0120s/iter; left time: 37.2775s\n",
            "\titers: 300, epoch: 4 | loss: 0.8231645\n",
            "\tspeed: 0.0120s/iter; left time: 36.2591s\n",
            "\titers: 400, epoch: 4 | loss: 0.6008545\n",
            "\tspeed: 0.0123s/iter; left time: 35.8923s\n",
            "Epoch: 4 cost time: 5.934282064437866\n",
            "Epoch: 4, Steps: 474 | Train Loss: 0.6971646 Vali Loss: 0.5480879 Test Loss: 0.9955921\n",
            "Validation loss decreased (0.549535 --> 0.548088).  Saving model ...\n",
            "Updating learning rate to 0.000125\n",
            "\titers: 100, epoch: 5 | loss: 0.9951211\n",
            "\tspeed: 0.0433s/iter; left time: 118.8428s\n",
            "\titers: 200, epoch: 5 | loss: 1.3919872\n",
            "\tspeed: 0.0118s/iter; left time: 31.1365s\n",
            "\titers: 300, epoch: 5 | loss: 0.6446191\n",
            "\tspeed: 0.0122s/iter; left time: 30.9741s\n",
            "\titers: 400, epoch: 5 | loss: 0.5851194\n",
            "\tspeed: 0.0119s/iter; left time: 29.0338s\n",
            "Epoch: 5 cost time: 5.792729616165161\n",
            "Epoch: 5, Steps: 474 | Train Loss: 0.6934864 Vali Loss: 0.5482230 Test Loss: 1.0006789\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 6.25e-05\n",
            "\titers: 100, epoch: 6 | loss: 0.8307257\n",
            "\tspeed: 0.0352s/iter; left time: 79.9379s\n",
            "\titers: 200, epoch: 6 | loss: 0.5412693\n",
            "\tspeed: 0.0122s/iter; left time: 26.5415s\n",
            "\titers: 300, epoch: 6 | loss: 0.6888755\n",
            "\tspeed: 0.0157s/iter; left time: 32.5426s\n",
            "\titers: 400, epoch: 6 | loss: 0.5725111\n",
            "\tspeed: 0.0164s/iter; left time: 32.2719s\n",
            "Epoch: 6 cost time: 6.642765522003174\n",
            "Epoch: 6, Steps: 474 | Train Loss: 0.6929614 Vali Loss: 0.5484908 Test Loss: 0.9961877\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_TAS_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4364\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "mse:0.9894773364067078, mae:0.4999890625476837, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_TAS_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_TAS_30min_PatchTST_PatchTST_custom_ftM_sl192_ll96_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.9895, MAE=0.5000\n",
            "âœ… å®Œæˆ | MAE: 0.5000 | ç”¨æ—¶: 0.9åˆ†é’Ÿ\n",
            "\n",
            "[19/20] ðŸš€ TAS | 15min | TimesNet\n",
            "--------------------------------------------------------------------------------\n",
            "  âš ï¸  TimesNetå…³é—­AMP (é¿å…cuFFT FP16é”™è¯¯)ï¼Œä½¿ç”¨FP32è®­ç»ƒ\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_TAS_15min_TimesNetModel:              TimesNet            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          TAS_15min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            384                 Label Len:          192                 \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              3                   Num Kernels:        4                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            8                   e layers:           1                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         16                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            0                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_TAS_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 11890\n",
            "val 1735\n",
            "test 3490\n",
            "\titers: 100, epoch: 1 | loss: 0.5161855\n",
            "\tspeed: 0.1373s/iter; left time: 1007.9818s\n",
            "\titers: 200, epoch: 1 | loss: 0.5453071\n",
            "\tspeed: 0.1197s/iter; left time: 866.4740s\n",
            "\titers: 300, epoch: 1 | loss: 0.4679768\n",
            "\tspeed: 0.1208s/iter; left time: 862.6230s\n",
            "\titers: 400, epoch: 1 | loss: 0.4769582\n",
            "\tspeed: 0.1284s/iter; left time: 903.9461s\n",
            "\titers: 500, epoch: 1 | loss: 0.5377734\n",
            "\tspeed: 0.1316s/iter; left time: 913.4720s\n",
            "\titers: 600, epoch: 1 | loss: 0.5174398\n",
            "\tspeed: 0.1434s/iter; left time: 980.8752s\n",
            "\titers: 700, epoch: 1 | loss: 0.5298713\n",
            "\tspeed: 0.1470s/iter; left time: 990.6446s\n",
            "Epoch: 1 cost time: 101.00103282928467\n",
            "Epoch: 1, Steps: 744 | Train Loss: 0.5411041 Vali Loss: 0.4862772 Test Loss: 0.4839053\n",
            "Validation loss decreased (inf --> 0.486277).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.5042971\n",
            "\tspeed: 0.4506s/iter; left time: 2972.6928s\n",
            "\titers: 200, epoch: 2 | loss: 0.5198144\n",
            "\tspeed: 0.1622s/iter; left time: 1054.0280s\n",
            "\titers: 300, epoch: 2 | loss: 0.4329916\n",
            "\tspeed: 0.1627s/iter; left time: 1040.8355s\n",
            "\titers: 400, epoch: 2 | loss: 0.4311377\n",
            "\tspeed: 0.1613s/iter; left time: 1015.9174s\n",
            "\titers: 500, epoch: 2 | loss: 0.5327337\n",
            "\tspeed: 0.1619s/iter; left time: 1003.1030s\n",
            "\titers: 600, epoch: 2 | loss: 0.4789495\n",
            "\tspeed: 0.1636s/iter; left time: 997.6657s\n",
            "\titers: 700, epoch: 2 | loss: 0.4983868\n",
            "\tspeed: 0.1664s/iter; left time: 998.1884s\n",
            "Epoch: 2 cost time: 122.49236178398132\n",
            "Epoch: 2, Steps: 744 | Train Loss: 0.5210669 Vali Loss: 0.4947351 Test Loss: 0.4881392\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.6029122\n",
            "\tspeed: 0.5133s/iter; left time: 3004.1151s\n",
            "\titers: 200, epoch: 3 | loss: 0.5647203\n",
            "\tspeed: 0.1680s/iter; left time: 966.3140s\n",
            "\titers: 300, epoch: 3 | loss: 0.4978853\n",
            "\tspeed: 0.1683s/iter; left time: 951.3321s\n",
            "\titers: 400, epoch: 3 | loss: 0.4657721\n",
            "\tspeed: 0.1711s/iter; left time: 949.8478s\n",
            "\titers: 500, epoch: 3 | loss: 0.6538065\n",
            "\tspeed: 0.1688s/iter; left time: 920.6400s\n",
            "\titers: 600, epoch: 3 | loss: 0.5056425\n",
            "\tspeed: 0.1710s/iter; left time: 915.2770s\n",
            "\titers: 700, epoch: 3 | loss: 0.4188595\n",
            "\tspeed: 0.1698s/iter; left time: 891.9872s\n",
            "Epoch: 3 cost time: 126.70152497291565\n",
            "Epoch: 3, Steps: 744 | Train Loss: 0.5156990 Vali Loss: 0.4902078 Test Loss: 0.4854664\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_TAS_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 3490\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "mse:0.4844377636909485, mae:0.42544206976890564, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_TAS_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_TAS_15min_TimesNet_TimesNet_custom_ftM_sl384_ll192_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.4844, MAE=0.4254\n",
            "âœ… å®Œæˆ | MAE: 0.4254 | ç”¨æ—¶: 7.4åˆ†é’Ÿ\n",
            "\n",
            "[20/20] ðŸš€ TAS | 15min | PatchTST\n",
            "--------------------------------------------------------------------------------\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage2_TAS_15min_PatchTSTModel:              PatchTST            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          TAS_15min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            384                 Label Len:          192                 \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              5                   Num Kernels:        6                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            4                   e layers:           2                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       10                  Batch Size:         32                  \n",
            "  Patience:           2                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            1                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage2_TAS_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 11890\n",
            "val 1735\n",
            "test 3490\n",
            "\titers: 100, epoch: 1 | loss: 0.7314171\n",
            "\tspeed: 0.0231s/iter; left time: 83.7490s\n",
            "\titers: 200, epoch: 1 | loss: 0.9334996\n",
            "\tspeed: 0.0124s/iter; left time: 43.4938s\n",
            "\titers: 300, epoch: 1 | loss: 0.7551064\n",
            "\tspeed: 0.0132s/iter; left time: 45.2238s\n",
            "Epoch: 1 cost time: 6.138375282287598\n",
            "Epoch: 1, Steps: 372 | Train Loss: 0.7721291 Vali Loss: 0.5071431 Test Loss: 0.5005793\n",
            "Validation loss decreased (inf --> 0.507143).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.6546747\n",
            "\tspeed: 0.0404s/iter; left time: 131.3705s\n",
            "\titers: 200, epoch: 2 | loss: 0.6673153\n",
            "\tspeed: 0.0123s/iter; left time: 38.8201s\n",
            "\titers: 300, epoch: 2 | loss: 0.6535350\n",
            "\tspeed: 0.0123s/iter; left time: 37.5206s\n",
            "Epoch: 2 cost time: 4.692168474197388\n",
            "Epoch: 2, Steps: 372 | Train Loss: 0.6675071 Vali Loss: 0.5642822 Test Loss: 0.5535981\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.4155360\n",
            "\tspeed: 0.0339s/iter; left time: 97.5093s\n",
            "\titers: 200, epoch: 3 | loss: 0.5438665\n",
            "\tspeed: 0.0126s/iter; left time: 34.9110s\n",
            "\titers: 300, epoch: 3 | loss: 0.4422190\n",
            "\tspeed: 0.0136s/iter; left time: 36.3873s\n",
            "Epoch: 3 cost time: 5.225535869598389\n",
            "Epoch: 3, Steps: 372 | Train Loss: 0.5907145 Vali Loss: 0.5008558 Test Loss: 0.4934858\n",
            "Validation loss decreased (0.507143 --> 0.500856).  Saving model ...\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.5409049\n",
            "\tspeed: 0.0403s/iter; left time: 100.8308s\n",
            "\titers: 200, epoch: 4 | loss: 0.5184453\n",
            "\tspeed: 0.0123s/iter; left time: 29.6817s\n",
            "\titers: 300, epoch: 4 | loss: 0.5064632\n",
            "\tspeed: 0.0123s/iter; left time: 28.3205s\n",
            "Epoch: 4 cost time: 4.731293678283691\n",
            "Epoch: 4, Steps: 372 | Train Loss: 0.5731609 Vali Loss: 0.4938793 Test Loss: 0.4854377\n",
            "Validation loss decreased (0.500856 --> 0.493879).  Saving model ...\n",
            "Updating learning rate to 0.000125\n",
            "\titers: 100, epoch: 5 | loss: 0.5259241\n",
            "\tspeed: 0.0343s/iter; left time: 73.2076s\n",
            "\titers: 200, epoch: 5 | loss: 0.5314894\n",
            "\tspeed: 0.0126s/iter; left time: 25.6223s\n",
            "\titers: 300, epoch: 5 | loss: 0.4576884\n",
            "\tspeed: 0.0150s/iter; left time: 28.9411s\n",
            "Epoch: 5 cost time: 5.5326690673828125\n",
            "Epoch: 5, Steps: 372 | Train Loss: 0.5662409 Vali Loss: 0.4906725 Test Loss: 0.4836852\n",
            "Validation loss decreased (0.493879 --> 0.490672).  Saving model ...\n",
            "Updating learning rate to 6.25e-05\n",
            "\titers: 100, epoch: 6 | loss: 0.6620640\n",
            "\tspeed: 0.0391s/iter; left time: 68.8642s\n",
            "\titers: 200, epoch: 6 | loss: 0.5858546\n",
            "\tspeed: 0.0123s/iter; left time: 20.3879s\n",
            "\titers: 300, epoch: 6 | loss: 0.5491723\n",
            "\tspeed: 0.0123s/iter; left time: 19.1540s\n",
            "Epoch: 6 cost time: 4.6847615242004395\n",
            "Epoch: 6, Steps: 372 | Train Loss: 0.5625268 Vali Loss: 0.4935724 Test Loss: 0.4830494\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 3.125e-05\n",
            "\titers: 100, epoch: 7 | loss: 0.5553813\n",
            "\tspeed: 0.0339s/iter; left time: 47.0262s\n",
            "\titers: 200, epoch: 7 | loss: 0.5970950\n",
            "\tspeed: 0.0124s/iter; left time: 16.0013s\n",
            "\titers: 300, epoch: 7 | loss: 0.6909329\n",
            "\tspeed: 0.0155s/iter; left time: 18.4019s\n",
            "Epoch: 7 cost time: 5.4773108959198\n",
            "Epoch: 7, Steps: 372 | Train Loss: 0.5602314 Vali Loss: 0.4890595 Test Loss: 0.4843223\n",
            "Validation loss decreased (0.490672 --> 0.489060).  Saving model ...\n",
            "Updating learning rate to 1.5625e-05\n",
            "\titers: 100, epoch: 8 | loss: 0.5497419\n",
            "\tspeed: 0.0383s/iter; left time: 38.9566s\n",
            "\titers: 200, epoch: 8 | loss: 0.5755686\n",
            "\tspeed: 0.0122s/iter; left time: 11.1579s\n",
            "\titers: 300, epoch: 8 | loss: 0.6350038\n",
            "\tspeed: 0.0124s/iter; left time: 10.1587s\n",
            "Epoch: 8 cost time: 4.703803539276123\n",
            "Epoch: 8, Steps: 372 | Train Loss: 0.5591846 Vali Loss: 0.4942098 Test Loss: 0.4845232\n",
            "EarlyStopping counter: 1 out of 2\n",
            "Updating learning rate to 7.8125e-06\n",
            "\titers: 100, epoch: 9 | loss: 0.6556903\n",
            "\tspeed: 0.0339s/iter; left time: 21.8426s\n",
            "\titers: 200, epoch: 9 | loss: 0.6544705\n",
            "\tspeed: 0.0124s/iter; left time: 6.7535s\n",
            "\titers: 300, epoch: 9 | loss: 0.5322889\n",
            "\tspeed: 0.0160s/iter; left time: 7.1284s\n",
            "Epoch: 9 cost time: 5.456250905990601\n",
            "Epoch: 9, Steps: 372 | Train Loss: 0.5581136 Vali Loss: 0.4974130 Test Loss: 0.4848818\n",
            "EarlyStopping counter: 2 out of 2\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage2_TAS_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 3490\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "test shape: (3490, 24, 5) (3490, 24, 5)\n",
            "mse:0.48524293303489685, mae:0.4335918128490448, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage2_TAS_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage2_TAS_15min_PatchTST_PatchTST_custom_ftM_sl384_ll192_pl24_dm128_nh4_el2_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.4852, MAE=0.4336\n",
            "âœ… å®Œæˆ | MAE: 0.4336 | ç”¨æ—¶: 1.1åˆ†é’Ÿ\n",
            "\n",
            "\n",
            "================================================================================\n",
            "ðŸ“Š é˜¶æ®µ2ç»“æžœæ±‡æ€»\n",
            "================================================================================\n",
            "\n",
            "30min æ•°æ®:\n",
            "state    model      mae      mse\n",
            "   SA TimesNet 0.447974 0.686204\n",
            "   SA PatchTST 0.458389 0.696457\n",
            "  QLD TimesNet 0.470083 0.802304\n",
            "  NSW PatchTST 0.472636 0.801659\n",
            "  QLD PatchTST 0.475082 0.808085\n",
            "  NSW TimesNet 0.475379 0.792249\n",
            "  VIC TimesNet 0.475876 0.745496\n",
            "  VIC PatchTST 0.477230 0.754493\n",
            "  TAS TimesNet 0.499099 0.983950\n",
            "  TAS PatchTST 0.499989 0.989477\n",
            "\n",
            "15min æ•°æ®:\n",
            "state    model      mae      mse\n",
            "  VIC PatchTST 0.405692 0.409605\n",
            "  VIC TimesNet 0.408003 0.410714\n",
            "  QLD TimesNet 0.418665 0.439003\n",
            "  TAS TimesNet 0.425442 0.484438\n",
            "  NSW TimesNet 0.428214 0.451906\n",
            "  NSW PatchTST 0.430281 0.462400\n",
            "  TAS PatchTST 0.433592 0.485243\n",
            "   SA PatchTST 0.435126 0.508774\n",
            "  QLD PatchTST 0.436228 0.455791\n",
            "   SA TimesNet 0.452027 0.515978\n",
            "\n",
            "âœ¨ æœ€ä¼˜æ¨¡åž‹: TimesNet\n",
            "   å¹³å‡MAE: 0.4501\n",
            "\n",
            "================================================================================\n",
            "ðŸŽ¯ é˜¶æ®µ3: é¢„æµ‹æ­¥é•¿æ‰©å±•\n",
            "================================================================================\n",
            "é…ç½®:\n",
            "  - æ¨¡åž‹: TimesNet\n",
            "  - å·ž: å…¨éƒ¨5ä¸ª\n",
            "  - é¢‘çŽ‡: 30min\n",
            "  - é¢„æµ‹æ­¥é•¿: 24, 48, 96\n",
            "  - è®­ç»ƒè½®æ•°: 15 epochs, æ—©åœpatience=3\n",
            "================================================================================\n",
            "\n",
            "[1/15] ðŸš€ NSW | pred_len=24\n",
            "--------------------------------------------------------------------------------\n",
            "  âš ï¸  TimesNetå…³é—­AMP (é¿å…cuFFT FP16é”™è¯¯)ï¼Œä½¿ç”¨FP32è®­ç»ƒ\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage3_NSW_TimesNet_pl24Model:              TimesNet            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          NSW_30min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           24                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              3                   Num Kernels:        4                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            8                   e layers:           1                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       15                  Batch Size:         16                  \n",
            "  Patience:           3                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            0                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage3_NSW_TimesNet_pl24_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15140\n",
            "val 2171\n",
            "test 4364\n",
            "\titers: 100, epoch: 1 | loss: 1.2049651\n",
            "\tspeed: 0.0882s/iter; left time: 1243.8809s\n",
            "\titers: 200, epoch: 1 | loss: 1.0872612\n",
            "\tspeed: 0.0828s/iter; left time: 1159.2286s\n",
            "\titers: 300, epoch: 1 | loss: 0.5841712\n",
            "\tspeed: 0.0875s/iter; left time: 1216.6116s\n",
            "\titers: 400, epoch: 1 | loss: 0.6028912\n",
            "\tspeed: 0.0889s/iter; left time: 1226.7901s\n",
            "\titers: 500, epoch: 1 | loss: 0.7055544\n",
            "\tspeed: 0.0895s/iter; left time: 1226.4203s\n",
            "\titers: 600, epoch: 1 | loss: 0.5016915\n",
            "\tspeed: 0.0911s/iter; left time: 1239.4499s\n",
            "\titers: 700, epoch: 1 | loss: 0.6204432\n",
            "\tspeed: 0.0906s/iter; left time: 1223.8549s\n",
            "\titers: 800, epoch: 1 | loss: 0.6798943\n",
            "\tspeed: 0.1013s/iter; left time: 1357.6313s\n",
            "\titers: 900, epoch: 1 | loss: 0.5601316\n",
            "\tspeed: 0.1012s/iter; left time: 1347.1849s\n",
            "Epoch: 1 cost time: 87.08869981765747\n",
            "Epoch: 1, Steps: 947 | Train Loss: 0.6991678 Vali Loss: 0.4614227 Test Loss: 0.8001683\n",
            "Validation loss decreased (inf --> 0.461423).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.6436665\n",
            "\tspeed: 0.3645s/iter; left time: 4796.5562s\n",
            "\titers: 200, epoch: 2 | loss: 0.6987650\n",
            "\tspeed: 0.1014s/iter; left time: 1323.8830s\n",
            "\titers: 300, epoch: 2 | loss: 0.7901579\n",
            "\tspeed: 0.1012s/iter; left time: 1311.4834s\n",
            "\titers: 400, epoch: 2 | loss: 0.6495169\n",
            "\tspeed: 0.1013s/iter; left time: 1301.9956s\n",
            "\titers: 500, epoch: 2 | loss: 0.7476221\n",
            "\tspeed: 0.1014s/iter; left time: 1293.4914s\n",
            "\titers: 600, epoch: 2 | loss: 0.5140497\n",
            "\tspeed: 0.1014s/iter; left time: 1283.9358s\n",
            "\titers: 700, epoch: 2 | loss: 1.2347958\n",
            "\tspeed: 0.1012s/iter; left time: 1271.2740s\n",
            "\titers: 800, epoch: 2 | loss: 0.4556448\n",
            "\tspeed: 0.0982s/iter; left time: 1223.0451s\n",
            "\titers: 900, epoch: 2 | loss: 0.7682181\n",
            "\tspeed: 0.0984s/iter; left time: 1216.2575s\n",
            "Epoch: 2 cost time: 95.32392525672913\n",
            "Epoch: 2, Steps: 947 | Train Loss: 0.6799119 Vali Loss: 0.4548430 Test Loss: 0.7917400\n",
            "Validation loss decreased (0.461423 --> 0.454843).  Saving model ...\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.3623135\n",
            "\tspeed: 0.3149s/iter; left time: 3845.0905s\n",
            "\titers: 200, epoch: 3 | loss: 0.8821055\n",
            "\tspeed: 0.0964s/iter; left time: 1167.7652s\n",
            "\titers: 300, epoch: 3 | loss: 0.6855569\n",
            "\tspeed: 0.0955s/iter; left time: 1146.6381s\n",
            "\titers: 400, epoch: 3 | loss: 0.5663549\n",
            "\tspeed: 0.0952s/iter; left time: 1133.7668s\n",
            "\titers: 500, epoch: 3 | loss: 0.3999396\n",
            "\tspeed: 0.0868s/iter; left time: 1025.8496s\n",
            "\titers: 600, epoch: 3 | loss: 0.7674099\n",
            "\tspeed: 0.0875s/iter; left time: 1025.3780s\n",
            "\titers: 700, epoch: 3 | loss: 1.0093987\n",
            "\tspeed: 0.0875s/iter; left time: 1015.7543s\n",
            "\titers: 800, epoch: 3 | loss: 0.8258815\n",
            "\tspeed: 0.0978s/iter; left time: 1126.2805s\n",
            "\titers: 900, epoch: 3 | loss: 0.3768440\n",
            "\tspeed: 0.0972s/iter; left time: 1108.7142s\n",
            "Epoch: 3 cost time: 88.98301935195923\n",
            "Epoch: 3, Steps: 947 | Train Loss: 0.6723104 Vali Loss: 0.4570430 Test Loss: 0.7901386\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.6311005\n",
            "\tspeed: 0.3200s/iter; left time: 3604.6994s\n",
            "\titers: 200, epoch: 4 | loss: 0.8399162\n",
            "\tspeed: 0.0958s/iter; left time: 1069.3184s\n",
            "\titers: 300, epoch: 4 | loss: 0.7337495\n",
            "\tspeed: 0.0947s/iter; left time: 1047.9692s\n",
            "\titers: 400, epoch: 4 | loss: 0.4869320\n",
            "\tspeed: 0.0960s/iter; left time: 1052.9071s\n",
            "\titers: 500, epoch: 4 | loss: 0.8546733\n",
            "\tspeed: 0.0962s/iter; left time: 1045.7399s\n",
            "\titers: 600, epoch: 4 | loss: 0.5377924\n",
            "\tspeed: 0.0968s/iter; left time: 1041.6878s\n",
            "\titers: 700, epoch: 4 | loss: 0.4278206\n",
            "\tspeed: 0.0944s/iter; left time: 1006.9932s\n",
            "\titers: 800, epoch: 4 | loss: 0.3876700\n",
            "\tspeed: 0.0963s/iter; left time: 1017.4901s\n",
            "\titers: 900, epoch: 4 | loss: 0.3531057\n",
            "\tspeed: 0.0980s/iter; left time: 1025.0950s\n",
            "Epoch: 4 cost time: 91.47852277755737\n",
            "Epoch: 4, Steps: 947 | Train Loss: 0.6679567 Vali Loss: 0.4630109 Test Loss: 0.7930632\n",
            "EarlyStopping counter: 2 out of 3\n",
            "Updating learning rate to 0.000125\n",
            "\titers: 100, epoch: 5 | loss: 0.5485081\n",
            "\tspeed: 0.3198s/iter; left time: 3300.1111s\n",
            "\titers: 200, epoch: 5 | loss: 0.7502273\n",
            "\tspeed: 0.0983s/iter; left time: 1004.5378s\n",
            "\titers: 300, epoch: 5 | loss: 0.4049505\n",
            "\tspeed: 0.0951s/iter; left time: 962.1149s\n",
            "\titers: 400, epoch: 5 | loss: 0.6343771\n",
            "\tspeed: 0.0956s/iter; left time: 957.5671s\n",
            "\titers: 500, epoch: 5 | loss: 1.3680960\n",
            "\tspeed: 0.0958s/iter; left time: 950.3532s\n",
            "\titers: 600, epoch: 5 | loss: 0.8907673\n",
            "\tspeed: 0.0957s/iter; left time: 939.8474s\n",
            "\titers: 700, epoch: 5 | loss: 0.3098354\n",
            "\tspeed: 0.0948s/iter; left time: 921.4095s\n",
            "\titers: 800, epoch: 5 | loss: 0.3666690\n",
            "\tspeed: 0.0964s/iter; left time: 926.9093s\n",
            "\titers: 900, epoch: 5 | loss: 1.0969931\n",
            "\tspeed: 0.0962s/iter; left time: 915.2161s\n",
            "Epoch: 5 cost time: 91.21435546875\n",
            "Epoch: 5, Steps: 947 | Train Loss: 0.6632458 Vali Loss: 0.4576686 Test Loss: 0.7916362\n",
            "EarlyStopping counter: 3 out of 3\n",
            "Early stopping\n",
            ">>>>>>>testing : long_term_forecast_stage3_NSW_TimesNet_pl24_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
            "test 4364\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "test shape: (4364, 24, 5) (4364, 24, 5)\n",
            "mse:0.7922492623329163, mae:0.4753793179988861, dtw:Not calculated\n",
            "Results saved to: ./results/long_term_forecast_stage3_NSW_TimesNet_pl24_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      [è°ƒè¯•] è¯»å–æ–‡ä»¶: ./results/long_term_forecast_stage3_NSW_TimesNet_pl24_TimesNet_custom_ftM_sl192_ll96_pl24_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0/result_long_term_forecast.txt\n",
            "      âœ… æå–åˆ°æŒ‡æ ‡: MSE=0.7922, MAE=0.4754\n",
            "âœ… å®Œæˆ | MAE: 0.4754 | ç”¨æ—¶: 9.4åˆ†é’Ÿ\n",
            "\n",
            "[2/15] ðŸš€ NSW | pred_len=48\n",
            "--------------------------------------------------------------------------------\n",
            "  âš ï¸  TimesNetå…³é—­AMP (é¿å…cuFFT FP16é”™è¯¯)ï¼Œä½¿ç”¨FP32è®­ç»ƒ\n",
            "Using GPU\n",
            "Args in experiment:\n",
            "\u001b[1mBasic Config\u001b[0m\n",
            "  Task Name:          long_term_forecast  Is Training:        1                   \n",
            "  Model ID:           stage3_NSW_TimesNet_pl48Model:              TimesNet            \n",
            "\n",
            "\u001b[1mData Loader\u001b[0m\n",
            "  Data:               custom              Root Path:          ./data/AEMO_optimized/\n",
            "  Data Path:          NSW_30min.csv       Features:           M                   \n",
            "  Target:             Price               Freq:               h                   \n",
            "  Checkpoints:        ./checkpoints/      \n",
            "\n",
            "\u001b[1mForecasting Task\u001b[0m\n",
            "  Seq Len:            192                 Label Len:          96                  \n",
            "  Pred Len:           48                  Seasonal Patterns:  Monthly             \n",
            "  Inverse:            0                   \n",
            "\n",
            "\u001b[1mModel Parameters\u001b[0m\n",
            "  Top k:              3                   Num Kernels:        4                   \n",
            "  Enc In:             5                   Dec In:             5                   \n",
            "  C Out:              5                   d model:            128                 \n",
            "  n heads:            8                   e layers:           1                   \n",
            "  d layers:           1                   d FF:               128                 \n",
            "  Moving Avg:         25                  Factor:             1                   \n",
            "  Distil:             1                   Dropout:            0.1                 \n",
            "  Embed:              timeF               Activation:         gelu                \n",
            "\n",
            "\u001b[1mRun Parameters\u001b[0m\n",
            "  Num Workers:        2                   Itr:                1                   \n",
            "  Train Epochs:       15                  Batch Size:         16                  \n",
            "  Patience:           3                   Learning Rate:      0.001               \n",
            "  Des:                test                Loss:               MSE                 \n",
            "  Lradj:              type1               Use Amp:            0                   \n",
            "\n",
            "\u001b[1mGPU\u001b[0m\n",
            "  Use GPU:            1                   GPU:                0                   \n",
            "  Use Multi GPU:      0                   Devices:            0,1,2,3             \n",
            "\n",
            "\u001b[1mDe-stationary Projector Params\u001b[0m\n",
            "  P Hidden Dims:      128, 128            P Hidden Layers:    2                   \n",
            "\n",
            "Use GPU: cuda:0\n",
            ">>>>>>>start training : long_term_forecast_stage3_NSW_TimesNet_pl48_TimesNet_custom_ftM_sl192_ll96_pl48_dm128_nh8_el1_dl1_df128_expand2_dc4_fc1_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
            "train 15116\n",
            "val 2147\n",
            "test 4340\n",
            "\titers: 100, epoch: 1 | loss: 0.5893197\n",
            "\tspeed: 0.1867s/iter; left time: 2627.7880s\n",
            "\titers: 200, epoch: 1 | loss: 0.6917465\n",
            "\tspeed: 0.1798s/iter; left time: 2512.3245s\n",
            "\titers: 300, epoch: 1 | loss: 0.8696317\n",
            "\tspeed: 0.1780s/iter; left time: 2470.5615s\n",
            "\titers: 400, epoch: 1 | loss: 0.7840326\n",
            "\tspeed: 0.1728s/iter; left time: 2380.7894s\n",
            "\titers: 500, epoch: 1 | loss: 0.9067861\n",
            "\tspeed: 0.1722s/iter; left time: 2354.6341s\n",
            "\titers: 600, epoch: 1 | loss: 0.8308517\n",
            "\tspeed: 0.1671s/iter; left time: 2267.9445s\n",
            "\titers: 700, epoch: 1 | loss: 0.9594401\n",
            "\tspeed: 0.1620s/iter; left time: 2183.2886s\n",
            "\titers: 800, epoch: 1 | loss: 0.7435099\n",
            "\tspeed: 0.1603s/iter; left time: 2144.1510s\n",
            "\titers: 900, epoch: 1 | loss: 0.5151523\n",
            "\tspeed: 0.2029s/iter; left time: 2694.1729s\n",
            "Epoch: 1 cost time: 167.57597160339355\n",
            "Epoch: 1, Steps: 945 | Train Loss: 0.7040542 Vali Loss: 0.4531873 Test Loss: 0.7927306\n",
            "Validation loss decreased (inf --> 0.453187).  Saving model ...\n",
            "Updating learning rate to 0.001\n",
            "\titers: 100, epoch: 2 | loss: 0.5834477\n",
            "\tspeed: 0.9492s/iter; left time: 12463.4065s\n",
            "\titers: 200, epoch: 2 | loss: 0.9054797\n",
            "\tspeed: 0.2220s/iter; left time: 2893.4820s\n",
            "\titers: 300, epoch: 2 | loss: 0.8696966\n",
            "\tspeed: 0.2368s/iter; left time: 3062.2248s\n",
            "\titers: 400, epoch: 2 | loss: 0.8403264\n",
            "\tspeed: 0.2422s/iter; left time: 3108.1407s\n",
            "\titers: 500, epoch: 2 | loss: 0.6389172\n",
            "\tspeed: 0.2557s/iter; left time: 3255.7566s\n",
            "\titers: 600, epoch: 2 | loss: 0.7982079\n",
            "\tspeed: 0.2696s/iter; left time: 3405.4847s\n",
            "\titers: 700, epoch: 2 | loss: 0.7124435\n",
            "\tspeed: 0.2708s/iter; left time: 3393.3641s\n",
            "\titers: 800, epoch: 2 | loss: 0.5461888\n",
            "\tspeed: 0.2298s/iter; left time: 2856.4070s\n",
            "\titers: 900, epoch: 2 | loss: 0.5087961\n",
            "\tspeed: 0.2306s/iter; left time: 2843.7649s\n",
            "Epoch: 2 cost time: 227.53388381004333\n",
            "Epoch: 2, Steps: 945 | Train Loss: 0.6764854 Vali Loss: 0.4492334 Test Loss: 0.7981861\n",
            "Validation loss decreased (0.453187 --> 0.449233).  Saving model ...\n",
            "Updating learning rate to 0.0005\n",
            "\titers: 100, epoch: 3 | loss: 0.5699450\n",
            "\tspeed: 1.0542s/iter; left time: 12846.1051s\n",
            "\titers: 200, epoch: 3 | loss: 0.5312477\n",
            "\tspeed: 0.2306s/iter; left time: 2787.5882s\n",
            "\titers: 300, epoch: 3 | loss: 0.6659617\n",
            "\tspeed: 0.2314s/iter; left time: 2774.0783s\n",
            "\titers: 400, epoch: 3 | loss: 0.7091686\n",
            "\tspeed: 0.2255s/iter; left time: 2680.0370s\n",
            "\titers: 500, epoch: 3 | loss: 0.8068503\n",
            "\tspeed: 0.2379s/iter; left time: 2803.4782s\n",
            "\titers: 600, epoch: 3 | loss: 0.7903739\n",
            "\tspeed: 0.2288s/iter; left time: 2674.0167s\n",
            "\titers: 700, epoch: 3 | loss: 1.0052159\n",
            "\tspeed: 0.2383s/iter; left time: 2761.4641s\n",
            "\titers: 800, epoch: 3 | loss: 0.8473744\n",
            "\tspeed: 0.2483s/iter; left time: 2851.4682s\n",
            "\titers: 900, epoch: 3 | loss: 0.7540476\n",
            "\tspeed: 0.2463s/iter; left time: 2804.3104s\n",
            "Epoch: 3 cost time: 222.64858412742615\n",
            "Epoch: 3, Steps: 945 | Train Loss: 0.6683131 Vali Loss: 0.4527647 Test Loss: 0.7957295\n",
            "EarlyStopping counter: 1 out of 3\n",
            "Updating learning rate to 0.00025\n",
            "\titers: 100, epoch: 4 | loss: 0.6194116\n",
            "\tspeed: 1.0750s/iter; left time: 12084.4101s\n",
            "\titers: 200, epoch: 4 | loss: 0.5390269\n",
            "\tspeed: 0.2455s/iter; left time: 2735.4744s\n",
            "\titers: 300, epoch: 4 | loss: 0.6781248\n",
            "\tspeed: 0.2497s/iter; left time: 2757.1285s\n",
            "\titers: 400, epoch: 4 | loss: 0.7879028\n",
            "\tspeed: 0.2522s/iter; left time: 2759.5625s\n",
            "\titers: 500, epoch: 4 | loss: 0.7236483\n",
            "\tspeed: 0.2535s/iter; left time: 2748.1376s\n",
            "\titers: 600, epoch: 4 | loss: 0.5426570\n",
            "\tspeed: 0.2620s/iter; left time: 2814.2314s\n",
            "\titers: 700, epoch: 4 | loss: 0.5558557\n",
            "\tspeed: 0.2624s/iter; left time: 2791.9392s\n",
            "\titers: 800, epoch: 4 | loss: 0.5976118\n",
            "\tspeed: 0.2633s/iter; left time: 2775.3492s\n",
            "\titers: 900, epoch: 4 | loss: 0.7448244\n",
            "\tspeed: 0.2669s/iter; left time: 2786.9125s\n",
            "Epoch: 4 cost time: 242.27138018608093\n",
            "Epoch: 4, Steps: 945 | Train Loss: 0.6604265 Vali Loss: 0.4537137 Test Loss: 0.8009486\n",
            "EarlyStopping counter: 2 out of 3\n",
            "Updating learning rate to 0.000125\n",
            "\titers: 100, epoch: 5 | loss: 0.4664674\n",
            "\tspeed: 1.1571s/iter; left time: 11913.5723s\n",
            "\titers: 200, epoch: 5 | loss: 0.7450596\n",
            "\tspeed: 0.2686s/iter; left time: 2738.3597s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "os.chdir('/content/TimeSeriesForecast')\n",
        "\n",
        "# è¯»å–ç»“æžœ\n",
        "if os.path.exists('./three_stage_results/all_results.csv'):\n",
        "    df = pd.read_csv('./three_stage_results/all_results.csv')\n",
        "    df_success = df[df['success'] == True]\n",
        "\n",
        "    print(f\"ðŸ“Š å®Œæˆ {len(df_success)}/{len(df)} ä¸ªå®žéªŒ\")\n",
        "\n",
        "    if len(df_success) > 0 and 'mae' in df_success.columns:\n",
        "        df_success = df_success.sort_values('mae')\n",
        "        print(\"\\nðŸ† Top 5 æœ€ä½³ç»“æžœ:\")\n",
        "        print(df_success[['model', 'state', 'freq', 'pred_len', 'mae']].head().to_string(index=False))\n",
        "else:\n",
        "    print(\"âš ï¸  ç»“æžœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè®­ç»ƒå¯èƒ½è¿˜æœªå®Œæˆ\")"
      ],
      "metadata": {
        "id": "DDSQCpRw6t4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "os.chdir('/content/TimeSeriesForecast')\n",
        "\n",
        "!zip -r results.zip ./three_stage_results/ ./results/ ./checkpoints/ -x \"*.pyc\"\n",
        "\n",
        "print(\"ðŸ“¥ ä¸‹è½½ç»“æžœ...\")\n",
        "files.download('results.zip')"
      ],
      "metadata": {
        "id": "TOgnItim6rZ4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}